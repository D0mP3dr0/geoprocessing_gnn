{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D0mP3dr0/geoprocessing_gnn/blob/main/geoprocessing_gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z7e7-1lZSbr"
      },
      "source": [
        "CRIACAO DO GRAFO INTRACAMADA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrRMRDsyZSHz",
        "outputId": "529b9ca4-7b04-4459-cc50-f69807c0d346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: me de o comando para carregar o drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIS70xouqJR-"
      },
      "source": [
        "📓 1_Configuracao_Ambiente/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH2ghAPRqJR-",
        "outputId": "0d93e4e3-5fa9-428f-abc8-f6dff7cc833f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Apr 13 20:35:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   39C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Verificar o tipo de GPU disponível\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qCBmkGUqJR-",
        "outputId": "adb08d05-37a6-4c9f-9396-3ef2d72d6566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versão do Python: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n"
          ]
        }
      ],
      "source": [
        "# Verificar a versão do Python e ambiente atual\n",
        "import sys\n",
        "print(f\"Versão do Python: {sys.version}\")\n",
        "!pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_oX6eBxqJR-",
        "outputId": "04c122ae-2287-4810-9506-b268b15144f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (3.7.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rtree\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pycrs\n",
            "  Downloading PyCRS-1.0.2.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mapclassify\n",
            "  Downloading mapclassify-2.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: pyogrio in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/dist-packages (from mapclassify) (3.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from mapclassify) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from mapclassify) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->mapclassify) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->mapclassify) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pycrs\n",
            "  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycrs: filename=PyCRS-1.0.2-py3-none-any.whl size=32686 sha256=fba5d2566f08a883db1bf559016854e4263800ee89988169e4cbebb40fd708fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/ad/a3/183ed754d7698fc15a2eb153705e05d05a0d97f3331293ce48\n",
            "Successfully built pycrs\n",
            "Installing collected packages: pycrs, rtree, cligj, click-plugins, affine, rasterio, fiona, mapclassify\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 fiona-1.10.1 mapclassify-2.8.1 pycrs-1.0.2 rasterio-1.4.3 rtree-1.4.0\n",
            "Collecting osmnx\n",
            "  Downloading osmnx-2.0.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Collecting keplergl\n",
            "  Downloading keplergl-0.3.7.tar.gz (18.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.4/18.4 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: geopandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.32.3)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.1.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.1.0)\n",
            "Collecting ipywidgets>=8.1.5 (from keplergl)\n",
            "  Using cached ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from keplergl) (0.2.1)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.11/dist-packages (from keplergl) (5.7.1)\n",
            "Collecting jupyter_packaging>=0.12.3 (from keplergl)\n",
            "  Using cached jupyter_packaging-0.12.3-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting jupyter>=1.0.0 (from keplergl)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting jupyterlab>=4.1.6 (from keplergl)\n",
            "  Downloading jupyterlab-4.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: notebook>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from keplergl) (6.5.7)\n",
            "Requirement already satisfied: pyarrow>=16.0.0 in /usr/local/lib/python3.11/dist-packages (from keplergl) (18.1.0)\n",
            "Collecting geoarrow-pyarrow>=0.1.2 (from keplergl)\n",
            "  Downloading geoarrow_pyarrow-0.1.2-py3-none-any.whl.metadata (613 bytes)\n",
            "Collecting geoarrow-pandas>=0.1.1 (from keplergl)\n",
            "  Downloading geoarrow_pandas-0.1.1-py3-none-any.whl.metadata (493 bytes)\n",
            "Collecting geoarrow-c (from geoarrow-pyarrow>=0.1.2->keplergl)\n",
            "  Downloading geoarrow_c-0.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (400 bytes)\n",
            "Collecting pyarrow-hotfix (from geoarrow-pyarrow>=0.1.2->keplergl)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (3.7.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.5->keplergl) (7.34.0)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->keplergl) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->keplergl) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->keplergl) (6.17.1)\n",
            "Collecting deprecation (from jupyter_packaging>=0.12.3->keplergl)\n",
            "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: setuptools>=60.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyter_packaging>=0.12.3->keplergl) (75.2.0)\n",
            "Collecting tomlkit (from jupyter_packaging>=0.12.3->keplergl)\n",
            "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from jupyter_packaging>=0.12.3->keplergl) (0.45.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (6.4.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (5.10.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->keplergl) (1.8.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->keplergl) (0.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->keplergl) (5.9.5)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=4.1.6->keplergl) (4.3.7)\n",
            "Collecting jupyter-client<8,>=5.3.4 (from notebook>=6.0.1->keplergl)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=6.0.1->keplergl) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8,>=5.3.4->notebook>=6.0.1->keplergl) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (4.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->keplergl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=6.0.1->keplergl) (2.21.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook>=6.0.1->keplergl) (0.7.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (4.13.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->keplergl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->keplergl) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=6.0.1->keplergl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->keplergl) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=6.0.1->keplergl) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading osmnx-2.0.2-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geoarrow_pandas-0.1.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading geoarrow_pyarrow-0.1.2-py3-none-any.whl (26 kB)\n",
            "Using cached ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Using cached jupyter_packaging-0.12.3-py3-none-any.whl (15 kB)\n",
            "Downloading jupyterlab-4.4.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "Using cached jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "Using cached jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
            "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading geoarrow_c-0.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Using cached json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Using cached types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: keplergl\n",
            "  Building wheel for keplergl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keplergl: filename=keplergl-0.3.7-py2.py3-none-any.whl size=35080504 sha256=03c886cb5fc1af0dd7cc627b6e2d42291fdc6d04e2736f277ebcd759e868f7c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/15/4b/f54140da2477a3d3d74bab2fccfc495849a1b3f2ca391f7c18\n",
            "Successfully built keplergl\n",
            "Installing collected packages: widgetsnbextension, uri-template, types-python-dateutil, tomlkit, rfc3986-validator, rfc3339-validator, python-json-logger, pyarrow-hotfix, overrides, jupyterlab_widgets, json5, jedi, geoarrow-c, fqdn, deprecation, comm, async-lru, jupyter-server-terminals, jupyter_packaging, jupyter-client, geoarrow-pyarrow, arrow, isoduration, ipywidgets, geoarrow-pandas, osmnx, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, keplergl\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: jupyterlab_widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed arrow-1.3.0 async-lru-2.0.5 comm-0.2.2 deprecation-2.1.0 fqdn-1.5.1 geoarrow-c-0.1.2 geoarrow-pandas-0.1.1 geoarrow-pyarrow-0.1.2 ipywidgets-8.1.6 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyter_packaging-0.12.3 jupyterlab-4.4.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.14 keplergl-0.3.7 osmnx-2.0.2 overrides-7.7.0 pyarrow-hotfix-0.6 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 tomlkit-0.13.2 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 widgetsnbextension-4.0.14\n",
            "Collecting rasterstats\n",
            "  Downloading rasterstats-0.20.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.1.2)\n",
            "Collecting xarray\n",
            "  Downloading xarray-2025.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.18.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterstats) (2.4.0)\n",
            "Requirement already satisfied: click>7.1 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.4 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (0.7.2)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.11/dist-packages (from rasterstats) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (2.0.2)\n",
            "Requirement already satisfied: rasterio>=1.0 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (1.4.3)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from rasterstats) (3.20.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from rasterstats) (2.1.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.0->rasterstats) (25.3.0)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.0->rasterstats) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.0->rasterstats) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray) (1.17.0)\n",
            "Downloading rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
            "Downloading xarray-2025.3.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rioxarray-0.18.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4, xarray, rasterstats, rioxarray\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2025.1.2\n",
            "    Uninstalling xarray-2025.1.2:\n",
            "      Successfully uninstalled xarray-2025.1.2\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2 rasterstats-0.20.0 rioxarray-0.18.2 xarray-2025.3.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from plotly) (1.33.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, plotly, matplotlib\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "Successfully installed matplotlib-3.10.1 plotly-6.0.1 scipy-1.15.2\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (6.5.7)\n",
            "Collecting notebook\n",
            "  Downloading notebook-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.6)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.0.5)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.1)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.14)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (24.0.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (4.13.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.24.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.8.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
            "Downloading notebook-7.4.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: notebook\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.5.7\n",
            "    Uninstalling notebook-6.5.7:\n",
            "      Successfully uninstalled notebook-6.5.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed notebook-7.4.0\n",
            "Collecting pygeos\n",
            "  Downloading pygeos-0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting contextily\n",
            "  Downloading contextily-1.6.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pysal\n",
            "  Downloading pysal-25.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting momepy\n",
            "  Downloading momepy-0.9.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from pygeos) (2.0.2)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (from contextily) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from contextily) (3.10.1)\n",
            "Collecting mercantile (from contextily)\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from contextily) (11.1.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from contextily) (1.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from contextily) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from contextily) (1.4.2)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from contextily) (2025.1.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.11/dist-packages (from pysal) (4.13.3)\n",
            "Requirement already satisfied: geopandas>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.0.1)\n",
            "Requirement already satisfied: packaging>=22 in /usr/local/lib/python3.11/dist-packages (from pysal) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.2.2)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pysal) (4.3.7)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.15.2)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.1.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.6.1)\n",
            "Collecting libpysal>=4.12.1 (from pysal)\n",
            "  Downloading libpysal-4.13.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting access>=1.1.9 (from pysal)\n",
            "  Downloading access-1.1.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting esda>=2.6.0 (from pysal)\n",
            "  Downloading esda-2.7.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting giddy>=2.3.6 (from pysal)\n",
            "  Downloading giddy-2.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inequality>=1.1.1 (from pysal)\n",
            "  Downloading inequality-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pointpats>=2.5.1 (from pysal)\n",
            "  Downloading pointpats-2.5.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting segregation>=2.5.1 (from pysal)\n",
            "  Downloading segregation-2.5.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting spaghetti>=1.7.6 (from pysal)\n",
            "  Downloading spaghetti-1.7.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mgwr>=2.2.1 (from pysal)\n",
            "  Downloading mgwr-2.2.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting spglm>=1.1.0 (from pysal)\n",
            "  Downloading spglm-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting spint>=1.0.7 (from pysal)\n",
            "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spreg>=1.8.1 (from pysal)\n",
            "  Downloading spreg-1.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tobler>=0.12.1 (from pysal)\n",
            "  Downloading tobler-0.12.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: mapclassify>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.8.1)\n",
            "Collecting splot>=1.1.7 (from pysal)\n",
            "  Downloading splot-1.1.7-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting spopt>=0.6.1 (from pysal)\n",
            "  Downloading spopt-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from momepy) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from momepy) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal) (4.13.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.10.0->pysal) (0.10.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.10.0->pysal) (3.7.1)\n",
            "Collecting quantecon>=0.7 (from giddy>=2.3.6->pysal)\n",
            "  Downloading quantecon-0.8.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->pysal) (3.6.0)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (2.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (0.13.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (0.60.0)\n",
            "Requirement already satisfied: rtree>=1.0 in /usr/local/lib/python3.11/dist-packages (from spaghetti>=1.7.6->pysal) (1.4.0)\n",
            "Collecting pulp>=2.7 (from spopt>=0.6.1->pysal)\n",
            "  Downloading pulp-3.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal) (0.14.4)\n",
            "Requirement already satisfied: rasterstats in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal) (0.20.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy->contextily) (2.0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.11/dist-packages (from mercantile->contextily) (8.1.8)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (25.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->contextily) (1.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from quantecon>=0.7->giddy>=2.3.6->pysal) (1.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->segregation>=2.5.1->pysal) (0.43.0)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.11/dist-packages (from rasterstats->tobler>=0.12.1->pysal) (1.10.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from rasterstats->tobler>=0.12.1->pysal) (3.20.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->tobler>=0.12.1->pysal) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal) (1.3.0)\n",
            "Downloading pygeos-0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextily-1.6.2-py3-none-any.whl (17 kB)\n",
            "Downloading pysal-25.1-py3-none-any.whl (17 kB)\n",
            "Downloading momepy-0.9.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading access-1.1.9-py3-none-any.whl (21 kB)\n",
            "Downloading esda-2.7.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading giddy-2.3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inequality-1.1.1-py3-none-any.whl (29 kB)\n",
            "Downloading libpysal-4.13.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mgwr-2.2.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pointpats-2.5.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segregation-2.5.2-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaghetti-1.7.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglm-1.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading splot-1.1.7-py3-none-any.whl (39 kB)\n",
            "Downloading spopt-0.6.1-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spreg-1.8.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tobler-0.12.1-py3-none-any.whl (28 kB)\n",
            "Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading pulp-3.1.1-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantecon-0.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.7/322.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spint\n",
            "  Building wheel for spint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31354 sha256=a00be8f3c30dc7e772b3e79aaffbf31a4b7e544689d18f8da5e03a6e7d980635\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/dc/2e/400caaa67e697355772a82b77b8c2ac7cd61633f595c477fd8\n",
            "Successfully built spint\n",
            "Installing collected packages: pygeos, pulp, mercantile, quantecon, contextily, libpysal, access, tobler, spreg, segregation, pointpats, momepy, inequality, esda, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal\n",
            "Successfully installed access-1.1.9 contextily-1.6.2 esda-2.7.0 giddy-2.3.6 inequality-1.1.1 libpysal-4.13.0 mercantile-1.2.1 mgwr-2.2.1 momepy-0.9.1 pointpats-2.5.1 pulp-3.1.1 pygeos-0.14 pysal-25.1 quantecon-0.8.0 segregation-2.5.2 spaghetti-1.7.6 spglm-1.1.0 spint-1.0.7 splot-1.1.7 spopt-0.6.1 spreg-1.8.2 tobler-0.12.1\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Collecting geoalchemy2\n",
            "  Downloading GeoAlchemy2-0.17.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geoalchemy2) (24.2)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GeoAlchemy2-0.17.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary, geoalchemy2\n",
            "Successfully installed geoalchemy2-0.17.1 psycopg2-binary-2.9.10\n"
          ]
        }
      ],
      "source": [
        "# Instalação de bibliotecas essenciais para processamento geoespacial\n",
        "!pip install -U geopandas rasterio pyproj shapely fiona rtree pycrs mapclassify pyogrio\n",
        "!pip install -U osmnx networkx folium keplergl\n",
        "!pip install -U rasterstats xarray rioxarray netCDF4\n",
        "!pip install -U scipy scikit-learn statsmodels plotly matplotlib seaborn\n",
        "!pip install -U tqdm jupyterlab notebook ipywidgets\n",
        "!pip install -U pygeos contextily pysal momepy\n",
        "!pip install -U psycopg2-binary sqlalchemy geoalchemy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsvh2ClZqJR_",
        "outputId": "1f5cfbc1-4aec-4169-8776-d15a4271e1bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cudf\n",
            "  Downloading cudf-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cuml\n",
            "  Downloading cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cuspatial\n",
            "  Downloading cuspatial-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cupy\n",
            "  Downloading cupy-13.4.1.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy) (0.8.3)\n",
            "Building wheels for collected packages: cudf, cuml, cuspatial, cupy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cudf (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cudf\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cudf\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cuml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cuml\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cuml\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cuspatial (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cuspatial\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cuspatial\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "# Instalação das bibliotecas RAPIDS para processamento acelerado por GPU\n",
        "# O L4 é compatível com RAPIDS, que acelera significativamente operações geoespaciais\n",
        "!pip install -U cudf cuml cuspatial cupy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8umVbJztqJR_",
        "outputId": "3eb91324-8e71-43cc-aade-2893c5b9abc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: xlwt in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.11/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Requirement already satisfied: pyshp in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: geojson in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: topojson in /usr/local/lib/python3.11/dist-packages (1.9)\n",
            "Requirement already satisfied: geobuf in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: mapbox-vector-tile in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from topojson) (2.2.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from topojson) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from topojson) (24.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geobuf) (8.1.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from geobuf) (5.29.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geobuf) (1.17.0)\n",
            "Requirement already satisfied: pyclipper<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from mapbox-vector-tile) (1.3.0.post6)\n",
            "Requirement already satisfied: geoviews in /usr/local/lib/python3.11/dist-packages (1.14.0)\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.11/dist-packages (1.20.2)\n",
            "Requirement already satisfied: datashader in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: hvplot in /usr/local/lib/python3.11/dist-packages (0.11.2)\n",
            "Requirement already satisfied: bokeh>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from geoviews) (3.6.3)\n",
            "Requirement already satisfied: cartopy>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from geoviews) (0.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geoviews) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geoviews) (24.2)\n",
            "Requirement already satisfied: param<3.0,>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from geoviews) (2.2.0)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (from geoviews) (3.7.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from geoviews) (2.1.0)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from geoviews) (2025.1.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from holoviews) (3.1.0)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.11/dist-packages (from holoviews) (2.2.3)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews) (3.0.4)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from datashader) (1.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from datashader) (0.60.0)\n",
            "Requirement already satisfied: pyct in /usr/local/lib/python3.11/dist-packages (from datashader) (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from datashader) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from datashader) (1.15.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from datashader) (0.12.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from datashader) (2025.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel) (0.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from panel) (4.13.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (6.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy>=0.18.0->geoviews) (3.10.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy>=0.18.0->geoviews) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->holoviews) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->holoviews) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->holoviews) (2025.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj->geoviews) (2025.1.31)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->datashader) (0.43.0)\n",
            "Collecting numpy (from geoviews)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->datashader) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->datashader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->datashader) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=3.6.0->geoviews) (3.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3->holoviews) (1.17.0)\n",
            "Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n",
            "Collecting dask\n",
            "  Using cached dask-2025.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: distributed in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n",
            "Collecting distributed\n",
            "  Using cached distributed-2025.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement hdf5 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for hdf5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Bibliotecas específicas para manipulação de dados tabulares e leitura de arquivos\n",
        "!pip install -U pandas numpy openpyxl xlrd xlwt xlsxwriter\n",
        "!pip install -U pyshp geojson topojson geobuf mapbox-vector-tile\n",
        "!pip install -U geoviews holoviews datashader panel hvplot\n",
        "!pip install -U dask distributed h5py hdf5 zarr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgA0y3sBqJR_",
        "outputId": "f9115779-27af-4d4f-8be7-f6583970d265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verificação de configuração básica concluída. Bibliotecas principais carregadas com sucesso.\n"
          ]
        }
      ],
      "source": [
        "# Verificar importações essenciais e configurações básicas\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import networkx as nx\n",
        "\n",
        "print(\"Verificação de configuração básica concluída. Bibliotecas principais carregadas com sucesso.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j162HTdJqJR_",
        "outputId": "d0c1ffff-e078-4669-bf3b-9a15da65c0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variáveis de ambiente configuradas para otimização com GPU L4\n"
          ]
        }
      ],
      "source": [
        "# Configurar ambiente para trabalhar com o L4 GPU\n",
        "import os\n",
        "\n",
        "# Definir variáveis de ambiente para otimização de bibliotecas geoespaciais\n",
        "os.environ['USE_PYGEOS'] = '0'  # Usar GeoPandas com GEOS (mais estável)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Utilizar GPU 0\n",
        "\n",
        "# Configurações para utilizar memória de GPU de forma eficiente\n",
        "os.environ['RAPIDS_NO_INITIALIZE'] = '1'  # Inicialização manual do RAPIDS\n",
        "\n",
        "print(\"Variáveis de ambiente configuradas para otimização com GPU L4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY6a0yOqqJR_",
        "outputId": "26fc176b-9bcc-4afc-fb52-6fe88cddf733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configurações de visualização otimizadas\n"
          ]
        }
      ],
      "source": [
        "# Configuração para visualização interativa\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Aumentar limite de exibição para melhor visualização de dados geoespaciais\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Configurar matplotlib para visualizações de alta qualidade\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"Configurações de visualização otimizadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE04pXRJqJR_",
        "outputId": "3a20ac36-0cea-4b88-f098-3d73cdfa8d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uso de memória RAM:\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            52Gi       1.5Gi        38Gi        24Mi        13Gi        50Gi\n",
            "Swap:             0B          0B          0B\n",
            "\n",
            "Uso de memória GPU:\n",
            "memory.used [MiB], memory.total [MiB]\n",
            "0 MiB, 23034 MiB\n"
          ]
        }
      ],
      "source": [
        "# Função utilitária para verificar consumo de memória\n",
        "def check_memory_usage():\n",
        "    \"\"\"Exibe o uso atual de memória RAM e GPU.\"\"\"\n",
        "    print(\"Uso de memória RAM:\")\n",
        "    !free -h\n",
        "\n",
        "    print(\"\\nUso de memória GPU:\")\n",
        "    !nvidia-smi --query-gpu=memory.used,memory.total --format=csv\n",
        "\n",
        "check_memory_usage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "VhB9F3MZqJSA",
        "outputId": "86eab4e0-b654-40f5-c1e4-d9f22e807eec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teste de funcionalidade geoespacial concluído com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Testar leitura básica de dados geoespaciais\n",
        "try:\n",
        "    # Criar um GeoDataFrame simples para teste\n",
        "    from shapely.geometry import Point\n",
        "\n",
        "    # Criar alguns pontos de teste\n",
        "    geometry = [Point(0, 0), Point(1, 1), Point(2, 2)]\n",
        "    gdf = gpd.GeoDataFrame(geometry=geometry)\n",
        "\n",
        "    # Plotar para verificar funcionamento\n",
        "    gdf.plot()\n",
        "    plt.title(\"Teste de Plotagem Geoespacial\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Teste de funcionalidade geoespacial concluído com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao testar funcionalidade geoespacial: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiRTZwhpqJSA",
        "outputId": "9b34eb57-e09b-4649-edea-e31ce573195d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CONFIGURAÇÃO DO AMBIENTE CONCLUÍDA COM SUCESSO\n",
            "================================================================================\n",
            "\n",
            "Bibliotecas instaladas e configuradas:\n",
            "- Processamento geoespacial: GeoPandas, Rasterio, Shapely, Fiona\n",
            "- Análise de redes: NetworkX, OSMnx\n",
            "- Processamento de dados: Pandas, NumPy, SciPy, Scikit-learn\n",
            "- Visualização: Matplotlib, Folium, Plotly, Kepler.gl\n",
            "- Aceleração GPU: RAPIDS (cuDF, cuSpatial)\n",
            "\n",
            "Próximos passos:\n",
            "1. Execute 1.2_Carregamento_Datasets.ipynb para carregar os dados\n",
            "2. Execute 1.3_Configuracao_Sistema_Coordenadas.ipynb para configurar os sistemas de referência\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Resumo da configuração do ambiente\n",
        "print(\"=\"*80)\n",
        "print(\"CONFIGURAÇÃO DO AMBIENTE CONCLUÍDA COM SUCESSO\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nBibliotecas instaladas e configuradas:\")\n",
        "print(\"- Processamento geoespacial: GeoPandas, Rasterio, Shapely, Fiona\")\n",
        "print(\"- Análise de redes: NetworkX, OSMnx\")\n",
        "print(\"- Processamento de dados: Pandas, NumPy, SciPy, Scikit-learn\")\n",
        "print(\"- Visualização: Matplotlib, Folium, Plotly, Kepler.gl\")\n",
        "print(\"- Aceleração GPU: RAPIDS (cuDF, cuSpatial)\")\n",
        "print(\"\\nPróximos passos:\")\n",
        "print(\"1. Execute 1.2_Carregamento_Datasets.ipynb para carregar os dados\")\n",
        "print(\"2. Execute 1.3_Configuracao_Sistema_Coordenadas.ipynb para configurar os sistemas de referência\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MblDidi8qJSA"
      },
      "source": [
        "1.2_Carregamento_Datasets.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo1Nh4nRqJSA",
        "outputId": "98855af8-6e47-4ffc-c668-d18b287222cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Carregamento de Datasets para Integração Geoespacial\n",
        "# Este notebook carrega os datasets GPKG necessários para o projeto\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "from shapely.geometry import box\n",
        "\n",
        "# Montando o Google Drive para acessar os dados\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29g8zplqJSA",
        "outputId": "5a96ecae-d1a0-4090-b8e5-b40852414205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diretório de dados encontrado: /content/drive/MyDrive/geoprocessamento_gnn/DATA\n"
          ]
        }
      ],
      "source": [
        "# Definição do diretório onde estão os datasets\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "\n",
        "# Verificando se o diretório existe\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(f\"O diretório {data_dir} não foi encontrado. Verifique o caminho.\")\n",
        "\n",
        "print(f\"Diretório de dados encontrado: {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eONoPkfCqJSA",
        "outputId": "02ad33d1-4ede-4e4a-d88a-744d56580e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encontrados 9 arquivos GPKG:\n",
            "1. inmet_processed.gpkg\n",
            "2. setores_censitarios_enriched.gpkg\n",
            "3. hidrografia_enriched_20250412_233008.gpkg\n",
            "4. buildings_enriched_20250413_131208.gpkg\n",
            "5. railways_enriched_20250413_134853.gpkg\n",
            "6. natural_areas_enriched_20250413_144444.gpkg\n",
            "7. roads_enriched_20250412_230707.gpkg\n",
            "8. landuse_enriched_20250413_105344.gpkg\n",
            "9. rbs_enriched_20250413_153946.gpkg\n"
          ]
        }
      ],
      "source": [
        "# Listando todos os arquivos GPKG no diretório de dados\n",
        "gpkg_files = glob.glob(os.path.join(data_dir, \"*.gpkg\"))\n",
        "print(f\"Encontrados {len(gpkg_files)} arquivos GPKG:\")\n",
        "for i, file in enumerate(gpkg_files):\n",
        "    print(f\"{i+1}. {os.path.basename(file)}\")\n",
        "\n",
        "if len(gpkg_files) == 0:\n",
        "    print(\"Nenhum arquivo GPKG encontrado. Verifique o caminho ou extensão dos arquivos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "f99TmMILB7Bx",
        "outputId": "df4330c4-facf-4878-d049-421f04561300"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "explore_gpkg() missing 1 required positional argument: 'gpkg_path'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-bed126f3c434>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using the default path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexplore_gpkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Specifying a different path if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexplore_gpkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/geoprocessamento_gnn/DATA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: explore_gpkg() missing 1 required positional argument: 'gpkg_path'"
          ]
        }
      ],
      "source": [
        "# Using the default path\n",
        "explore_gpkg()\n",
        "\n",
        "# Specifying a different path if needed\n",
        "explore_gpkg('/content/drive/MyDrive/geoprocessamento_gnn/DATA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "goGxfEc5qJSA",
        "outputId": "9314d526-0da8-498d-8009-6ef8465ef2f0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-55-3114e8a9e133>, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-3114e8a9e133>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    layers = fiona.listlayers(gpkg_path)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "#def explore_gpkg(gpkg_path='/content/drive/MyDrive/geoprocessamento_gnn/DATA'):\n",
        "    # Listar todas as camadas no arquivo\n",
        "    layers = fiona.listlayers(gpkg_path)\n",
        "\n",
        "    # Coletar informações sobre cada camada\n",
        "    layer_info = []\n",
        "    for layer in layers:\n",
        "        try:\n",
        "            # Abrir a camada para obter informações\n",
        "            with fiona.open(gpkg_path, layer=layer) as src:\n",
        "                # Obter a contagem de feições\n",
        "                count = len(src)\n",
        "                # Obter o tipo de geometria\n",
        "                if count > 0:\n",
        "                    geometry_type = src.schema['geometry']\n",
        "                else:\n",
        "                    geometry_type = \"Desconhecido\"\n",
        "                # Obter o CRS\n",
        "                crs = src.crs\n",
        "                # Obter os campos de atributos\n",
        "                fields = list(src.schema['properties'].keys())\n",
        "\n",
        "                layer_info.append({\n",
        "                    'Layer': layer,\n",
        "                    'Feature Count': count,\n",
        "                    'Geometry Type': geometry_type,\n",
        "                    'CRS': crs,\n",
        "                    'Fields': fields[:5] + ['...'] if len(fields) > 5 else fields\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar camada {layer}: {e}\")\n",
        "            layer_info.append({\n",
        "                'Layer': layer,\n",
        "                'Error': str(e)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(layer_info)\n",
        "\n",
        "# Importamos fiona aqui para listar as camadas\n",
        "import fiona\n",
        "\n",
        "# Explorando cada arquivo GPKG\n",
        "for gpkg_file in gpkg_files:\n",
        "    file_name = os.path.basename(gpkg_file)\n",
        "    print(f\"\\n{'='*80}\\nExplorando arquivo: {file_name}\\n{'='*80}\")\n",
        "\n",
        "    layers_info = explore_gpkg(gpkg_file)\n",
        "    display(layers_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651,
          "referenced_widgets": [
            "8b78089f74154151a2b7589978d14963",
            "a73455c14a1244888389dfa9c0b8dfe1",
            "a113fff2f6114caa9e8221ffddaeb12c",
            "17188148bd854eb89e0f61acf242d7bb",
            "8e6e321e23ab4d5f8028f6e2a9d66ca2",
            "8b066468064f4cd4a668528cfaf1fd4f",
            "fc8efe577f5a4ce4b919037badd406cf",
            "cc833ad3e9e54ec6adbce3033fd839e7",
            "f4a7c0f07888431e97d8c6c275c5e662",
            "cfa2fb3c5983469bb1fbf54ae9b033b9",
            "d60ee9a724284044a90fff3b1f158d41",
            "655cf9cd39d64c46b46148f4a8bf7fd7",
            "f9952b233b734b459546a4cc82c79440",
            "2c76f7f484374f7683e5af25ccf4eb07",
            "54234ad943de4155987bb7994692e1b6",
            "fe0a3275e4b3400590d860bbb3f99f33",
            "9f2269378cc04fc0b865c11a738f1cc8",
            "ad2422bb71b84313b81380767388d2e3",
            "4093e2ad6186493ba9290c878eab1758",
            "19db4ff634f54c39bb1ce3b1155cbf8a",
            "522231ed2fe14bfea5356b522cf08375",
            "1b2254247fbf4fad903828370d9f2fca"
          ]
        },
        "id": "zBbrUayOqJSA",
        "outputId": "c2264801-ceb5-467f-e531-bda2d38173f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b78089f74154151a2b7589978d14963",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Carregando arquivos GPKG:   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "655cf9cd39d64c46b46148f4a8bf7fd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Camadas em inmet_processed.gpkg:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregado: inmet_processed.gpkg - inmet_processed - 8784 registros\n"
          ]
        },
        {
          "ename": "DriverError",
          "evalue": "Failed to open dataset (flags=68): /content/drive/MyDrive/geoprocessamento_gnn/DATA/setores_censitarios_enriched.gpkg",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.StackChecker.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: `/content/drive/MyDrive/geoprocessamento_gnn/DATA/setores_censitarios_enriched.gpkg' not recognized as being in a supported file format.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-23a663360ac7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Carregando todos os datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpkg_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Salvando em uma variável global para acesso posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-23a663360ac7>\u001b[0m in \u001b[0;36mload_all_datasets\u001b[0;34m(gpkg_files)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Listar camadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Camadas em {file_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mlistlayers\u001b[0;34m(fp, opener, vfs, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mpobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_listlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_vsi_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext._listlayers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDriverError\u001b[0m: Failed to open dataset (flags=68): /content/drive/MyDrive/geoprocessamento_gnn/DATA/setores_censitarios_enriched.gpkg"
          ]
        }
      ],
      "source": [
        "# Função para carregar e armazenar todos os datasets em um dicionário\n",
        "def load_all_datasets(gpkg_files):\n",
        "    \"\"\"\n",
        "    Carrega todos os arquivos GPKG e suas camadas em um dicionário.\n",
        "\n",
        "    Args:\n",
        "        gpkg_files: Lista de caminhos para arquivos GPKG\n",
        "\n",
        "    Returns:\n",
        "        Um dicionário de GeoDataFrames organizados por nome de arquivo e camada\n",
        "    \"\"\"\n",
        "    datasets = {}\n",
        "\n",
        "    for gpkg_file in tqdm(gpkg_files, desc=\"Carregando arquivos GPKG\"):\n",
        "        file_name = os.path.basename(gpkg_file)\n",
        "        datasets[file_name] = {}\n",
        "\n",
        "        # Listar camadas\n",
        "        layers = fiona.listlayers(gpkg_file)\n",
        "\n",
        "        for layer in tqdm(layers, desc=f\"Camadas em {file_name}\", leave=False):\n",
        "            try:\n",
        "                # Carregar o GeoDataFrame\n",
        "                gdf = gpd.read_file(gpkg_file, layer=layer)\n",
        "\n",
        "                # Armazenar no dicionário\n",
        "                datasets[file_name][layer] = gdf\n",
        "\n",
        "                print(f\"Carregado: {file_name} - {layer} - {len(gdf)} registros\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao carregar camada {layer} de {file_name}: {e}\")\n",
        "\n",
        "    return datasets\n",
        "\n",
        "# Carregando todos os datasets\n",
        "datasets = load_all_datasets(gpkg_files)\n",
        "\n",
        "# Salvando em uma variável global para acesso posterior\n",
        "import builtins\n",
        "builtins.datasets = datasets\n",
        "\n",
        "print(\"\\nCarregamento completo. Todos os datasets estão armazenados na variável global 'datasets'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa7_zA81z8_Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LHmyVfoz8_R"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn_DxGVhz8_R"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twh9YC7bqJSA"
      },
      "outputs": [],
      "source": [
        "# Função para visualizar a extensão geográfica de todos os datasets em um mapa\n",
        "def plot_dataset_extents(datasets):\n",
        "    \"\"\"\n",
        "    Visualiza a extensão geográfica de todos os datasets carregados.\n",
        "\n",
        "    Args:\n",
        "        datasets: Dicionário de datasets carregados\n",
        "    \"\"\"\n",
        "    # Criar um gráfico vazio\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
        "\n",
        "    # Cores para diferentes datasets\n",
        "    colors = plt.cm.tab20.colors\n",
        "    color_idx = 0\n",
        "\n",
        "    # Legenda\n",
        "    legend_items = []\n",
        "\n",
        "    # Iterar através dos datasets\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            # Verificar se o GeoDataFrame tem geometria\n",
        "            if gdf.geometry.is_empty.all():\n",
        "                print(f\"Geometria vazia em {file_name} - {layer_name}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Obter a extensão do dataset\n",
        "                minx, miny, maxx, maxy = gdf.total_bounds\n",
        "                extent_box = box(minx, miny, maxx, maxy)\n",
        "\n",
        "                # Criar um GeoDataFrame com a extensão\n",
        "                extent_gdf = gpd.GeoDataFrame(geometry=[extent_box], crs=gdf.crs)\n",
        "\n",
        "                # Plotar no mapa\n",
        "                color = colors[color_idx % len(colors)]\n",
        "                extent_gdf.boundary.plot(ax=ax, color=color, linewidth=2,\n",
        "                                        label=f\"{file_name} - {layer_name}\")\n",
        "\n",
        "                # Adicionar à legenda\n",
        "                legend_items.append(f\"{file_name} - {layer_name}\")\n",
        "\n",
        "                # Incrementar índice de cor\n",
        "                color_idx += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao plotar extensão de {file_name} - {layer_name}: {e}\")\n",
        "\n",
        "    # Configurar o gráfico\n",
        "    ax.set_title(\"Extensão geográfica dos datasets carregados\", fontsize=16)\n",
        "    ax.legend(legend_items, fontsize=10, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizando a extensão dos datasets\n",
        "plot_dataset_extents(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTtnv5LjqJSA"
      },
      "outputs": [],
      "source": [
        "# Salvando o estado dos datasets para uso no próximo notebook\n",
        "import pickle\n",
        "\n",
        "# Criando pasta de estado se não existir\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "os.makedirs(state_dir, exist_ok=True)\n",
        "\n",
        "# Caminho para o arquivo de estado\n",
        "state_file = os.path.join(state_dir, 'datasets_state.pkl')\n",
        "\n",
        "# Salvando o dicionário de datasets\n",
        "with open(state_file, 'wb') as f:\n",
        "    pickle.dump(datasets, f)\n",
        "\n",
        "print(f\"Estado dos datasets salvo em: {state_file}\")\n",
        "print(\"Os datasets estão prontos para o próximo notebook de configuração do sistema de coordenadas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5G8mL8fqJSB"
      },
      "outputs": [],
      "source": [
        "# Resumo do carregamento de dados\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMO DE CARREGAMENTO DE DADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Contabilizar totais\n",
        "total_layers = 0\n",
        "total_features = 0\n",
        "\n",
        "# Exibir estatísticas por arquivo\n",
        "for file_name, layers in datasets.items():\n",
        "    layer_count = len(layers)\n",
        "    total_layers += layer_count\n",
        "\n",
        "    feature_counts = [len(gdf) for gdf in layers.values()]\n",
        "    total_file_features = sum(feature_counts)\n",
        "    total_features += total_file_features\n",
        "\n",
        "    print(f\"\\nArquivo: {file_name}\")\n",
        "    print(f\"  Número de camadas: {layer_count}\")\n",
        "    print(f\"  Total de feições: {total_file_features:,}\")\n",
        "\n",
        "    # Listar cada camada com contagem\n",
        "    for layer_name, gdf in layers.items():\n",
        "        print(f\"    - {layer_name}: {len(gdf):,} feições\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"TOTAL GERAL: {total_layers} camadas, {total_features:,} feições\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thiGS2DRqJSB"
      },
      "source": [
        "1.3_Configuracao_Sistema_Coordenadas.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J00J9ODqJSB"
      },
      "outputs": [],
      "source": [
        "# Configuração do Sistema de Coordenadas para Integração Geoespacial\n",
        "# Este notebook padroniza todos os datasets para o sistema SIRGAS 2000 23S (EPSG:31983)\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "\n",
        "# Montando o Google Drive para acessar os dados\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmQ4vsvtqJSB"
      },
      "outputs": [],
      "source": [
        "# Diretório de dados\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "state_file = os.path.join(state_dir, 'datasets_state.pkl')\n",
        "\n",
        "# Verificando se o arquivo de estado existe\n",
        "if not os.path.exists(state_file):\n",
        "    raise FileNotFoundError(f\"Arquivo de estado não encontrado: {state_file}\")\n",
        "\n",
        "# Carregando o estado dos datasets do notebook anterior\n",
        "with open(state_file, 'rb') as f:\n",
        "    datasets = pickle.load(f)\n",
        "\n",
        "# Definindo globalmente para uso posterior\n",
        "import builtins\n",
        "builtins.datasets = datasets\n",
        "\n",
        "print(f\"Datasets carregados com sucesso do arquivo: {state_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps2Xyn0IqJSB"
      },
      "outputs": [],
      "source": [
        "# Definição do sistema de coordenadas alvo: SIRGAS 2000 / UTM zone 23S (EPSG:31983)\n",
        "TARGET_CRS = \"EPSG:31983\"\n",
        "\n",
        "# Informações sobre o sistema de coordenadas alvo\n",
        "sirgas_info = {\n",
        "    'EPSG': 31983,\n",
        "    'Nome': 'SIRGAS 2000 / UTM zone 23S',\n",
        "    'Projeção': 'Transverse Mercator',\n",
        "    'Datum': 'SIRGAS 2000',\n",
        "    'Unidade': 'metros',\n",
        "    'Zona UTM': '23S',\n",
        "    'Meridiano Central': '-45',\n",
        "    'Latitude de Origem': '0',\n",
        "    'Falso Leste': '500000',\n",
        "    'Falso Norte': '10000000',\n",
        "    'Fator de Escala': '0.9996'\n",
        "}\n",
        "\n",
        "print(\"Sistema de coordenadas alvo:\")\n",
        "for key, value in sirgas_info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\nEste sistema de coordenadas é ideal para o nosso projeto porque:\")\n",
        "print(\"1. Mantém a precisão das medições em metros para a área de estudo\")\n",
        "print(\"2. É o sistema padrão para projetos geoespaciais no Brasil, especialmente na zona 23S\")\n",
        "print(\"3. Permite calcular áreas, distâncias e análises espaciais com precisão\")\n",
        "print(\"4. Minimiza distorções para a região de estudo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfjZ4LlSqJSB"
      },
      "outputs": [],
      "source": [
        "# Função para verificar e tabular os sistemas de coordenadas atuais de todos os datasets\n",
        "def check_crs(datasets):\n",
        "    \"\"\"\n",
        "    Verifica os sistemas de coordenadas de todos os datasets.\n",
        "\n",
        "    Args:\n",
        "        datasets: Dicionário de datasets carregados\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com informações sobre os sistemas de coordenadas\n",
        "    \"\"\"\n",
        "    crs_info = []\n",
        "\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            try:\n",
        "                # Obter informações do CRS\n",
        "                if gdf.crs is None:\n",
        "                    crs_code = None\n",
        "                    crs_name = \"Não definido\"\n",
        "                    is_projected = False\n",
        "                    units = \"Desconhecido\"\n",
        "                else:\n",
        "                    crs_code = gdf.crs.to_epsg()\n",
        "                    crs_name = gdf.crs.name if hasattr(gdf.crs, 'name') else str(gdf.crs)\n",
        "                    is_projected = gdf.crs.is_projected\n",
        "                    units = gdf.crs.axis_info[0].unit_name if hasattr(gdf.crs, 'axis_info') else \"Desconhecido\"\n",
        "\n",
        "                needs_transformation = crs_code != 31983 and crs_code is not None\n",
        "\n",
        "                crs_info.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG': crs_code,\n",
        "                    'CRS Nome': crs_name,\n",
        "                    'Projetado': is_projected,\n",
        "                    'Unidades': units,\n",
        "                    'Requer Transformação': needs_transformation\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao verificar CRS de {file_name} - {layer_name}: {e}\")\n",
        "                crs_info.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG': None,\n",
        "                    'CRS Nome': f\"ERRO: {str(e)}\",\n",
        "                    'Projetado': None,\n",
        "                    'Unidades': None,\n",
        "                    'Requer Transformação': None\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(crs_info)\n",
        "\n",
        "# Analisando os sistemas de coordenadas atuais\n",
        "crs_status = check_crs(datasets)\n",
        "display(crs_status)\n",
        "\n",
        "# Contabilizando quantos datasets precisam de transformação\n",
        "requires_transformation = crs_status['Requer Transformação'].sum()\n",
        "total_layers = len(crs_status)\n",
        "\n",
        "print(f\"\\nStatus de transformação: {requires_transformation} de {total_layers} camadas precisam ser transformadas para SIRGAS 2000 / UTM zone 23S (EPSG:31983)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6pPzMw3qJSB"
      },
      "outputs": [],
      "source": [
        "# Função para transformar datasets para o CRS alvo\n",
        "def transform_datasets(datasets, target_crs=TARGET_CRS):\n",
        "    \"\"\"\n",
        "    Transforma todos os datasets para o sistema de coordenadas alvo.\n",
        "\n",
        "    Args:\n",
        "        datasets: Dicionário de datasets carregados\n",
        "        target_crs: Sistema de coordenadas alvo\n",
        "\n",
        "    Returns:\n",
        "        Dicionário de datasets transformados\n",
        "    \"\"\"\n",
        "    transformed_datasets = {}\n",
        "    transformation_report = []\n",
        "\n",
        "    # Para cada arquivo\n",
        "    for file_name, layers in tqdm(datasets.items(), desc=\"Transformando arquivos\"):\n",
        "        transformed_datasets[file_name] = {}\n",
        "\n",
        "        # Para cada camada\n",
        "        for layer_name, gdf in tqdm(layers.items(), desc=f\"Camadas em {file_name}\", leave=False):\n",
        "            try:\n",
        "                # Verificar se o CRS atual é None\n",
        "                if gdf.crs is None:\n",
        "                    print(f\"AVISO: {file_name} - {layer_name} não possui CRS definido. Atribuindo o CRS alvo sem transformação.\")\n",
        "                    gdf.crs = target_crs\n",
        "                    transformed_gdf = gdf\n",
        "                    status = \"Atribuído CRS (sem transformação)\"\n",
        "\n",
        "                # Verificar se já está no CRS alvo\n",
        "                elif gdf.crs.to_epsg() == 31983:\n",
        "                    print(f\"{file_name} - {layer_name} já está no CRS alvo. Nenhuma transformação necessária.\")\n",
        "                    transformed_gdf = gdf\n",
        "                    status = \"Já no CRS alvo\"\n",
        "\n",
        "                # Realizar a transformação\n",
        "                else:\n",
        "                    # Registrar informações antes da transformação\n",
        "                    if 'geometry' in gdf.columns and len(gdf) > 0 and not gdf.geometry.is_empty.all():\n",
        "                        pre_bounds = gdf.total_bounds\n",
        "                    else:\n",
        "                        pre_bounds = None\n",
        "\n",
        "                    # Executar a transformação\n",
        "                    with warnings.catch_warnings():\n",
        "                        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "                        transformed_gdf = gdf.to_crs(target_crs)\n",
        "\n",
        "                    # Registrar informações após a transformação\n",
        "                    if pre_bounds is not None and len(transformed_gdf) > 0 and not transformed_gdf.geometry.is_empty.all():\n",
        "                        post_bounds = transformed_gdf.total_bounds\n",
        "                        status = \"Transformado com sucesso\"\n",
        "                    else:\n",
        "                        post_bounds = None\n",
        "                        status = \"Transformado (sem geometria para validar)\"\n",
        "\n",
        "                # Armazenar o GeoDataFrame transformado\n",
        "                transformed_datasets[file_name][layer_name] = transformed_gdf\n",
        "\n",
        "                # Registrar no relatório\n",
        "                transformation_report.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'CRS Original': str(gdf.crs),\n",
        "                    'CRS Final': str(transformed_gdf.crs),\n",
        "                    'Status': status,\n",
        "                    'Registros': len(gdf)\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ERRO ao transformar {file_name} - {layer_name}: {e}\")\n",
        "                # Manter o dataset original em caso de erro\n",
        "                transformed_datasets[file_name][layer_name] = gdf\n",
        "                transformation_report.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'CRS Original': str(gdf.crs) if hasattr(gdf, 'crs') else \"Desconhecido\",\n",
        "                    'CRS Final': \"ERRO\",\n",
        "                    'Status': f\"Erro: {str(e)}\",\n",
        "                    'Registros': len(gdf) if hasattr(gdf, 'len') else \"Desconhecido\"\n",
        "                })\n",
        "\n",
        "    return transformed_datasets, pd.DataFrame(transformation_report)\n",
        "\n",
        "# Executando a transformação\n",
        "transformed_datasets, transformation_report = transform_datasets(datasets)\n",
        "\n",
        "# Atualizando a variável global com os datasets transformados\n",
        "builtins.datasets = transformed_datasets\n",
        "\n",
        "# Exibindo o relatório de transformação\n",
        "display(transformation_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj10Z5y3qJSB"
      },
      "outputs": [],
      "source": [
        "# Validação final: verificando se todos os datasets estão no sistema de coordenadas correto\n",
        "def validate_transformations(datasets, target_crs=TARGET_CRS):\n",
        "    \"\"\"\n",
        "    Verifica se todos os datasets estão no sistema de coordenadas alvo.\n",
        "\n",
        "    Args:\n",
        "        datasets: Dicionário de datasets transformados\n",
        "        target_crs: Sistema de coordenadas alvo\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com resultados da validação\n",
        "    \"\"\"\n",
        "    validation_results = []\n",
        "    target_epsg = 31983  # EPSG para SIRGAS 2000 / UTM zone 23S\n",
        "\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            try:\n",
        "                current_epsg = gdf.crs.to_epsg()\n",
        "                is_valid = current_epsg == target_epsg\n",
        "\n",
        "                validation_results.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG Atual': current_epsg,\n",
        "                    'EPSG Alvo': target_epsg,\n",
        "                    'Validação': \"Sucesso\" if is_valid else \"Falha\",\n",
        "                    'CRS': str(gdf.crs)\n",
        "                })\n",
        "            except Exception as e:\n",
        "                validation_results.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG Atual': None,\n",
        "                    'EPSG Alvo': target_epsg,\n",
        "                    'Validação': f\"Erro: {str(e)}\",\n",
        "                    'CRS': str(gdf.crs) if hasattr(gdf, 'crs') else \"Desconhecido\"\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(validation_results)\n",
        "\n",
        "# Validando todas as transformações\n",
        "validation_results = validate_transformations(transformed_datasets)\n",
        "display(validation_results)\n",
        "\n",
        "# Verificando sucesso geral\n",
        "success_count = (validation_results['Validação'] == \"Sucesso\").sum()\n",
        "total_count = len(validation_results)\n",
        "success_rate = success_count / total_count * 100\n",
        "\n",
        "print(f\"\\nValidação concluída: {success_count} de {total_count} camadas ({success_rate:.2f}%) estão no sistema de coordenadas SIRGAS 2000 / UTM zone 23S (EPSG:31983)\")\n",
        "\n",
        "if success_count < total_count:\n",
        "    print(\"\\nATENÇÃO: Algumas camadas não foram transformadas corretamente. Verifique o relatório acima.\")\n",
        "else:\n",
        "    print(\"\\nTodos os datasets foram transformados com sucesso para o sistema de coordenadas alvo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNnq0rCBqJSB"
      },
      "outputs": [],
      "source": [
        "# Salvando os datasets transformados\n",
        "import pickle\n",
        "\n",
        "# Criando pasta de estado se não existir\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "os.makedirs(state_dir, exist_ok=True)\n",
        "\n",
        "# Caminho para o arquivo de estado\n",
        "transformed_state_file = os.path.join(state_dir, 'datasets_transformed_state.pkl')\n",
        "\n",
        "# Salvando o dicionário de datasets transformados\n",
        "with open(transformed_state_file, 'wb') as f:\n",
        "    pickle.dump(transformed_datasets, f)\n",
        "\n",
        "print(f\"Estado dos datasets transformados salvo em: {transformed_state_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVcgBqHpqJSC"
      },
      "outputs": [],
      "source": [
        "# Visualizando algumas feições para verificar visualmente a transformação\n",
        "def plot_sample_geometries(datasets):\n",
        "    \"\"\"\n",
        "    Plota amostras de geometrias para verificação visual.\n",
        "\n",
        "    Args:\n",
        "        datasets: Dicionário de datasets transformados\n",
        "    \"\"\"\n",
        "    # Criar um layout de 2x2 para visualização\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Contador para controlar quantas camadas plotar\n",
        "    plot_count = 0\n",
        "    max_plots = 4\n",
        "\n",
        "    # Cores para diferentes datasets\n",
        "    colors = plt.cm.tab10.colors\n",
        "\n",
        "    # Para cada arquivo e camada\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            if plot_count >= max_plots:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                # Verificar se há geometrias para plotar\n",
        "                if 'geometry' not in gdf.columns or len(gdf) == 0 or gdf.geometry.is_empty.all():\n",
        "                    continue\n",
        "\n",
        "                # Plotar apenas uma amostra (máximo 100 feições)\n",
        "                sample_size = min(100, len(gdf))\n",
        "                ax = axes[plot_count]\n",
        "\n",
        "                # Plotar a amostra\n",
        "                gdf.sample(sample_size).plot(\n",
        "                    ax=ax,\n",
        "                    color=colors[plot_count % len(colors)],\n",
        "                    alpha=0.7,\n",
        "                    edgecolor='black',\n",
        "                    linewidth=0.5\n",
        "                )\n",
        "\n",
        "                # Configurar o título e rótulos\n",
        "                ax.set_title(f\"{file_name}\\n{layer_name}\", fontsize=12)\n",
        "                ax.set_xlabel(\"Coordenada X (metros)\")\n",
        "                ax.set_ylabel(\"Coordenada Y (metros)\")\n",
        "                ax.grid(True)\n",
        "\n",
        "                # Adicionar informações de CRS\n",
        "                ax.text(0.5, -0.1, f\"CRS: {gdf.crs.name if hasattr(gdf.crs, 'name') else str(gdf.crs)[:50]}...\",\n",
        "                       horizontalalignment='center', verticalalignment='center',\n",
        "                       transform=ax.transAxes, fontsize=10)\n",
        "\n",
        "                plot_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao plotar {file_name} - {layer_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "    if plot_count == 0:\n",
        "        print(\"Nenhuma geometria disponível para visualização.\")\n",
        "        plt.close(fig)\n",
        "        return\n",
        "\n",
        "    # Ocultar eixos não utilizados\n",
        "    for i in range(plot_count, max_plots):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizando amostras das geometrias transformadas\n",
        "plot_sample_geometries(transformed_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3kdKmxuqJSC"
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusão\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA CONFIGURAÇÃO DE SISTEMA DE COORDENADAS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSistema de coordenadas alvo: SIRGAS 2000 / UTM zone 23S (EPSG:31983)\")\n",
        "print(f\"Total de arquivos processados: {len(transformed_datasets)}\")\n",
        "print(f\"Total de camadas processadas: {total_count}\")\n",
        "print(f\"Camadas transformadas com sucesso: {success_count} ({success_rate:.2f}%)\")\n",
        "\n",
        "print(\"\\nBenefícios da padronização:\")\n",
        "print(\"1. Todas as análises espaciais agora usarão o mesmo sistema de referência\")\n",
        "print(\"2. Cálculos de área, distância e proximidade serão precisos e consistentes\")\n",
        "print(\"3. Visualizações de mapas estarão corretamente alinhadas\")\n",
        "print(\"4. Operações de sobreposição espacial funcionarão corretamente\")\n",
        "\n",
        "print(\"\\nPróximos passos:\")\n",
        "print(\"1. Prosseguir para a integração de Edifícios e Uso do Solo\")\n",
        "print(\"2. Criar análises demográficas usando os datasets transformados\")\n",
        "print(\"3. Realizar as operações hidrográficas com os dados padronizados\")\n",
        "\n",
        "print(\"\\nOs datasets transformados estão disponíveis na variável global 'datasets'\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdfoWU8mwlc1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a75fdbe7",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "2_Integracao_Edificios_UsoSolo/\n",
        "│   ├── 2.1_Sobreposicao_Espacial.ipynb\n",
        "│   ├── 2.2_Categorizacao_Funcional_Edificios.ipynb\n",
        "│   └── 2.3_Analise_Conformidade_Uso.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74f307b4"
      },
      "source": [
        "2.1_Sobreposicao_Espacial.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b75065d",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Sobreposição Espacial: Edifícios x Uso do Solo\n",
        "# Este notebook realiza a sobreposição espacial entre as camadas de edifícios e uso do solo\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import contextily as cx\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "\n",
        "# Ignorar avisos específicos para operações espaciais\n",
        "warnings.filterwarnings('ignore', category=UserWarning, message='.*CRS mismatch.*')\n",
        "\n",
        "# Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definição dos diretórios\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "state_file = os.path.join(state_dir, 'datasets_transformed_state.pkl')\n",
        "\n",
        "# Carregando os datasets transformados\n",
        "with open(state_file, 'rb') as f:\n",
        "    datasets = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95169ed6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Extraindo as camadas de edifícios e uso do solo dos datasets carregados\n",
        "def extract_layers(datasets, target_names):\n",
        "    \"\"\"\n",
        "    Extrai camadas específicas do dicionário de datasets.\n",
        "\n",
        "    Args:\n",
        "        datasets: Dicionário de datasets carregados\n",
        "        target_names: Lista de nomes de camadas a serem buscados (parcial)\n",
        "\n",
        "    Returns:\n",
        "        Dicionário com as camadas encontradas\n",
        "    \"\"\"\n",
        "    extracted = {}\n",
        "\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            # Verificar se o nome da camada ou arquivo contém algum dos alvos\n",
        "            for target in target_names:\n",
        "                if target.lower() in file_name.lower() or target.lower() in layer_name.lower():\n",
        "                    key = f\"{file_name}:{layer_name}\"\n",
        "                    extracted[key] = gdf\n",
        "                    print(f\"Encontrada camada: {key} ({len(gdf)} feições)\")\n",
        "                    break\n",
        "\n",
        "    return extracted\n",
        "\n",
        "# Extraindo as camadas relevantes\n",
        "building_keys = ['building', 'edificio', 'edif']\n",
        "landuse_keys = ['land', 'uso', 'landuse']\n",
        "\n",
        "building_layers = extract_layers(datasets, building_keys)\n",
        "landuse_layers = extract_layers(datasets, landuse_keys)\n",
        "\n",
        "# Verificando se encontramos as camadas necessárias\n",
        "if not building_layers:\n",
        "    raise ValueError(\"Nenhuma camada de edifícios encontrada. Verifique os nomes das camadas ou arquivos.\")\n",
        "\n",
        "if not landuse_layers:\n",
        "    raise ValueError(\"Nenhuma camada de uso do solo encontrada. Verifique os nomes das camadas ou arquivos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19851bb",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Selecionar as camadas específicas para trabalhar\n",
        "# Em um ambiente real, você pode querer pedir ao usuário para selecionar\n",
        "# Neste caso, vamos pegar a primeira de cada tipo\n",
        "\n",
        "# Função para mostrar informações detalhadas sobre as camadas\n",
        "def show_layer_details(layers_dict):\n",
        "    \"\"\"\n",
        "    Exibe informações detalhadas sobre as camadas para ajudar na seleção.\n",
        "\n",
        "    Args:\n",
        "        layers_dict: Dicionário contendo as camadas encontradas\n",
        "    \"\"\"\n",
        "    details = []\n",
        "\n",
        "    for key, gdf in layers_dict.items():\n",
        "        # Colunas de interesse específicas para cada tipo\n",
        "        if 'building' in key.lower():\n",
        "            special_cols = ['building', 'building_class', 'type', 'amenity', 'landuse']\n",
        "        else:  # uso do solo\n",
        "            special_cols = ['landuse', 'land_category', 'type', 'natural']\n",
        "\n",
        "        # Buscar valores únicos nas colunas de interesse\n",
        "        sample_values = {}\n",
        "        for col in special_cols:\n",
        "            if col in gdf.columns:\n",
        "                unique_vals = gdf[col].dropna().unique()\n",
        "                sample_values[col] = unique_vals[:5] if len(unique_vals) > 5 else unique_vals\n",
        "\n",
        "        # Adicionar à lista de detalhes\n",
        "        details.append({\n",
        "            'Camada': key,\n",
        "            'Feições': len(gdf),\n",
        "            'Colunas': len(gdf.columns),\n",
        "            'Geometria': gdf.geometry.geom_type.unique(),\n",
        "            'CRS': gdf.crs,\n",
        "            'Atributos Importantes': sample_values\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(details)\n",
        "\n",
        "# Exibir detalhes para ajudar na seleção\n",
        "print(\"\\nDetalhes das camadas de edifícios:\")\n",
        "display(show_layer_details(building_layers))\n",
        "\n",
        "print(\"\\nDetalhes das camadas de uso do solo:\")\n",
        "display(show_layer_details(landuse_layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0995dc59",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Selecionar a primeira camada de cada tipo para este exemplo\n",
        "# Em um ambiente real, você pode substituir isso por uma interface de seleção\n",
        "building_key = list(building_layers.keys())[0]\n",
        "landuse_key = list(landuse_layers.keys())[0]\n",
        "\n",
        "buildings_gdf = building_layers[building_key]\n",
        "landuse_gdf = landuse_layers[landuse_key]\n",
        "\n",
        "print(f\"Camada de edifícios selecionada: {building_key}\")\n",
        "print(f\"Camada de uso do solo selecionada: {landuse_key}\")\n",
        "\n",
        "# Exibindo informações básicas de cada camada\n",
        "print(\"\\nInformações da camada de edifícios:\")\n",
        "print(f\"- Número de feições: {len(buildings_gdf)}\")\n",
        "print(f\"- Sistema de coordenadas: {buildings_gdf.crs}\")\n",
        "print(f\"- Colunas: {buildings_gdf.columns.tolist()}\")\n",
        "\n",
        "print(\"\\nInformações da camada de uso do solo:\")\n",
        "print(f\"- Número de feições: {len(landuse_gdf)}\")\n",
        "print(f\"- Sistema de coordenadas: {landuse_gdf.crs}\")\n",
        "print(f\"- Colunas: {landuse_gdf.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60b2790f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar os dados para verificar a sobreposição\n",
        "def plot_overlap(buildings, landuse, sample_size=1000, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Visualiza a sobreposição entre edifícios e uso do solo.\n",
        "\n",
        "    Args:\n",
        "        buildings: GeoDataFrame com os edifícios\n",
        "        landuse: GeoDataFrame com o uso do solo\n",
        "        sample_size: Número de edifícios a mostrar (para não sobrecarregar a visualização)\n",
        "        figsize: Tamanho da figura\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Plotar uso do solo com transparência\n",
        "    if 'land_category' in landuse.columns:\n",
        "        # Usar categorias de uso do solo se disponíveis\n",
        "        landuse.plot(ax=ax, column='land_category', alpha=0.5,\n",
        "                     legend=True, categorical=True,\n",
        "                     legend_kwds={'loc': 'upper left'})\n",
        "    else:\n",
        "        # Caso contrário, tentar outras colunas comuns\n",
        "        for col in ['landuse', 'type', 'class']:\n",
        "            if col in landuse.columns and landuse[col].notna().any():\n",
        "                landuse.plot(ax=ax, column=col, alpha=0.5,\n",
        "                             legend=True, categorical=True,\n",
        "                             legend_kwds={'loc': 'upper left'})\n",
        "                break\n",
        "        else:\n",
        "            # Se nenhuma coluna for adequada, plotar sem classificação\n",
        "            landuse.plot(ax=ax, alpha=0.5)\n",
        "\n",
        "    # Amostrar edifícios para não sobrecarregar a visualização\n",
        "    sample_buildings = buildings.sample(min(sample_size, len(buildings)))\n",
        "\n",
        "    # Plotar edifícios\n",
        "    if 'building_class' in buildings.columns:\n",
        "        sample_buildings.plot(ax=ax, column='building_class',\n",
        "                              categorical=True, alpha=0.8,\n",
        "                              markersize=5, legend=True,\n",
        "                              legend_kwds={'loc': 'upper right'})\n",
        "    else:\n",
        "        sample_buildings.plot(ax=ax, color='blue', alpha=0.8, markersize=5)\n",
        "\n",
        "    # Adicionar basemap para contexto\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=buildings.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar o gráfico\n",
        "    ax.set_title(\"Sobreposição entre Edifícios e Uso do Solo\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Visualizar a sobreposição (amostra de até 1000 edifícios para não sobrecarregar)\n",
        "fig, ax = plot_overlap(buildings_gdf, landuse_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "102640f4",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Verificar e preparar as geometrias antes da sobreposição espacial\n",
        "def prepare_for_overlay(buildings_gdf, landuse_gdf):\n",
        "    \"\"\"\n",
        "    Prepara os GeoDataFrames para a sobreposição espacial.\n",
        "\n",
        "    Args:\n",
        "        buildings_gdf: GeoDataFrame dos edifícios\n",
        "        landuse_gdf: GeoDataFrame do uso do solo\n",
        "\n",
        "    Returns:\n",
        "        Tuple de GeoDataFrames preparados\n",
        "    \"\"\"\n",
        "    print(\"Preparando GeoDataFrames para sobreposição espacial...\")\n",
        "\n",
        "    # Verificar validade das geometrias\n",
        "    invalid_buildings = ~buildings_gdf.geometry.is_valid\n",
        "    invalid_landuse = ~landuse_gdf.geometry.is_valid\n",
        "\n",
        "    if invalid_buildings.any():\n",
        "        print(f\"Corrigindo {invalid_buildings.sum()} geometrias inválidas em edifícios...\")\n",
        "        buildings_gdf.geometry = buildings_gdf.geometry.buffer(0)\n",
        "\n",
        "    if invalid_landuse.any():\n",
        "        print(f\"Corrigindo {invalid_landuse.sum()} geometrias inválidas em uso do solo...\")\n",
        "        landuse_gdf.geometry = landuse_gdf.geometry.buffer(0)\n",
        "\n",
        "    # Verificar se os sistemas de coordenadas são iguais\n",
        "    if buildings_gdf.crs != landuse_gdf.crs:\n",
        "        print(f\"Os sistemas de coordenadas são diferentes. Transformando uso do solo para {buildings_gdf.crs}\")\n",
        "        landuse_gdf = landuse_gdf.to_crs(buildings_gdf.crs)\n",
        "\n",
        "    # Verificar se há edifícios fora da área de cobertura do uso do solo\n",
        "    landuse_bounds = box(*landuse_gdf.total_bounds)\n",
        "    buildings_within = buildings_gdf.intersects(landuse_bounds)\n",
        "\n",
        "    if not buildings_within.all():\n",
        "        outside_count = (~buildings_within).sum()\n",
        "        print(f\"AVISO: {outside_count} edifícios ({outside_count/len(buildings_gdf)*100:.2f}%) estão fora da área coberta pelos dados de uso do solo.\")\n",
        "\n",
        "    return buildings_gdf, landuse_gdf\n",
        "\n",
        "# Preparar os dados para a sobreposição\n",
        "buildings_clean, landuse_clean = prepare_for_overlay(buildings_gdf, landuse_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c4656b0",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Realizar a operação de sobreposição espacial (join espacial)\n",
        "def perform_spatial_join(buildings_gdf, landuse_gdf):\n",
        "    \"\"\"\n",
        "    Realiza a junção espacial entre edifícios e uso do solo.\n",
        "\n",
        "    Args:\n",
        "        buildings_gdf: GeoDataFrame dos edifícios\n",
        "        landuse_gdf: GeoDataFrame do uso do solo\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com a junção espacial\n",
        "    \"\"\"\n",
        "    print(\"Realizando a junção espacial...\", flush=True)\n",
        "\n",
        "    # Selecionar colunas relevantes do uso do solo para não duplicar dados\n",
        "    # Estas são colunas comuns em dados de uso do solo\n",
        "    landuse_cols = ['landuse', 'land_category', 'land_use', 'type', 'class']\n",
        "    landuse_cols = [col for col in landuse_cols if col in landuse_gdf.columns]\n",
        "\n",
        "    # Se land_category não existir, tente identificar uma coluna principal\n",
        "    if 'land_category' not in landuse_cols and landuse_cols:\n",
        "        main_category_col = landuse_cols[0]\n",
        "        # Renomear a coluna principal para land_category para padronização\n",
        "        landuse_gdf = landuse_gdf.copy()\n",
        "        landuse_gdf['land_category'] = landuse_gdf[main_category_col]\n",
        "        landuse_cols.append('land_category')\n",
        "\n",
        "    # Adicionar geometria e um identificador único\n",
        "    selected_cols = landuse_cols + ['geometry']\n",
        "    landuse_for_join = landuse_gdf[selected_cols].copy()\n",
        "    landuse_for_join['landuse_id'] = range(len(landuse_for_join))\n",
        "\n",
        "    # Realizar a junção espacial\n",
        "    print(f\"Juntando {len(buildings_gdf)} edifícios com {len(landuse_gdf)} polígonos de uso do solo...\")\n",
        "    joined = gpd.sjoin(buildings_gdf, landuse_for_join, how='left', predicate='intersects')\n",
        "\n",
        "    # Verificar se há edifícios que não foram associados a nenhum uso do solo\n",
        "    null_landuse = joined['landuse_id'].isna().sum()\n",
        "    if null_landuse > 0:\n",
        "        print(f\"AVISO: {null_landuse} edifícios ({null_landuse/len(joined)*100:.2f}%) não foram associados a nenhum uso do solo.\")\n",
        "\n",
        "    return joined\n",
        "\n",
        "# Realizar a junção espacial\n",
        "buildings_with_landuse = perform_spatial_join(buildings_clean, landuse_clean)\n",
        "\n",
        "# Exibir as primeiras linhas do resultado\n",
        "print(\"\\nAmostra do resultado da sobreposição espacial:\")\n",
        "display(buildings_with_landuse.head())\n",
        "\n",
        "# Exibir estatísticas básicas\n",
        "print(\"\\nDistribuição de edifícios por categoria de uso do solo:\")\n",
        "if 'land_category' in buildings_with_landuse.columns:\n",
        "    display(buildings_with_landuse['land_category'].value_counts())\n",
        "else:\n",
        "    print(\"Coluna 'land_category' não encontrada nos resultados.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cde8c926",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Lidar com casos de edifícios que estão em múltiplas zonas de uso do solo\n",
        "def handle_multiple_zones(joined_gdf, buildings_gdf, landuse_gdf):\n",
        "    \"\"\"\n",
        "    Identifica e resolve casos de edifícios em múltiplas zonas de uso do solo.\n",
        "\n",
        "    Args:\n",
        "        joined_gdf: Resultado da junção espacial\n",
        "        buildings_gdf: GeoDataFrame original dos edifícios\n",
        "        landuse_gdf: GeoDataFrame original do uso do solo\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com casos múltiplos resolvidos\n",
        "    \"\"\"\n",
        "    # Identificar edifícios duplicados (que caíram em mais de uma zona)\n",
        "    if 'index_right' in joined_gdf.columns:\n",
        "        duplicated_indices = joined_gdf.index.duplicated(keep=False)\n",
        "        duplicate_count = duplicated_indices.sum()\n",
        "\n",
        "        if duplicate_count > 0:\n",
        "            print(f\"Encontrados {duplicate_count} edifícios ({duplicate_count/len(buildings_gdf)*100:.2f}%) em múltiplas zonas de uso do solo.\")\n",
        "\n",
        "            # Identificar quais edifícios estão duplicados\n",
        "            duplicated_buildings = joined_gdf[duplicated_indices].copy()\n",
        "\n",
        "            # Estratégia 1: Usar a área de interseção para determinar o uso do solo predominante\n",
        "            print(\"Resolvendo conflitos com base na área de interseção...\")\n",
        "\n",
        "            # Criar um GeoDataFrame para armazenar o resultado final\n",
        "            resolved_gdf = joined_gdf[~duplicated_indices].copy()\n",
        "\n",
        "            # Processar cada edifício duplicado\n",
        "            unique_buildings = duplicated_buildings.index.unique()\n",
        "\n",
        "            for idx in tqdm(unique_buildings, desc=\"Resolvendo edifícios em múltiplas zonas\"):\n",
        "                # Obter todas as entradas para este edifício\n",
        "                building_entries = duplicated_buildings.loc[[idx]]\n",
        "\n",
        "                # Obter a geometria do edifício\n",
        "                building_geom = buildings_gdf.loc[idx, 'geometry']\n",
        "\n",
        "                # Calcular a área de interseção com cada zona de uso do solo\n",
        "                areas = []\n",
        "                for i, row in building_entries.iterrows():\n",
        "                    landuse_id = row['landuse_id']\n",
        "                    if pd.notna(landuse_id):\n",
        "                        landuse_geom = landuse_gdf.loc[landuse_gdf['landuse_id'] == landuse_id, 'geometry'].iloc[0]\n",
        "                        intersection = building_geom.intersection(landuse_geom)\n",
        "                        areas.append((i, intersection.area))\n",
        "\n",
        "                # Selecionar a entrada com a maior área de interseção\n",
        "                if areas:\n",
        "                    max_area_idx = max(areas, key=lambda x: x[1])[0]\n",
        "                    resolved_gdf = pd.concat([resolved_gdf, building_entries.loc[[max_area_idx]]])\n",
        "\n",
        "            print(f\"Resolução concluída. Resultaram {len(resolved_gdf)} edifícios após resolução de conflitos.\")\n",
        "            return resolved_gdf\n",
        "        else:\n",
        "            print(\"Nenhum edifício em múltiplas zonas de uso do solo encontrado.\")\n",
        "            return joined_gdf\n",
        "    else:\n",
        "        print(\"A coluna 'index_right' não foi encontrada nos resultados da junção. Verificando por duplicatas no índice.\")\n",
        "        # Verificar se há duplicatas no índice\n",
        "        duplicated_indices = joined_gdf.index.duplicated(keep=False)\n",
        "        if duplicated_indices.any():\n",
        "            print(f\"Encontrados {duplicated_indices.sum()} edifícios duplicados.\")\n",
        "            # Manter apenas a primeira ocorrência de cada edifício\n",
        "            return joined_gdf[~joined_gdf.index.duplicated(keep='first')]\n",
        "        else:\n",
        "            print(\"Nenhum edifício duplicado encontrado.\")\n",
        "            return joined_gdf\n",
        "\n",
        "# Resolver casos de edifícios em múltiplas zonas\n",
        "buildings_resolved = handle_multiple_zones(buildings_with_landuse, buildings_clean, landuse_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500830f2",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar o resultado da sobreposição\n",
        "def visualize_overlay_results(buildings_with_landuse, column='land_category', figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Visualiza os resultados da sobreposição espacial.\n",
        "\n",
        "    Args:\n",
        "        buildings_with_landuse: GeoDataFrame com os resultados da sobreposição\n",
        "        column: Coluna a ser usada para a classificação\n",
        "        figsize: Tamanho da figura\n",
        "    \"\"\"\n",
        "    if column not in buildings_with_landuse.columns:\n",
        "        print(f\"Coluna '{column}' não encontrada. Colunas disponíveis: {buildings_with_landuse.columns.tolist()}\")\n",
        "        # Tentar encontrar uma coluna alternativa\n",
        "        for alt_col in ['landuse', 'land_use', 'type']:\n",
        "            if alt_col in buildings_with_landuse.columns:\n",
        "                column = alt_col\n",
        "                print(f\"Usando coluna alternativa: '{column}'\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Nenhuma coluna alternativa encontrada. Visualizando sem classificação.\")\n",
        "            column = None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Plotar os edifícios classificados por uso do solo\n",
        "    if column:\n",
        "        buildings_with_landuse.plot(\n",
        "            column=column,\n",
        "            categorical=True,\n",
        "            legend=True,\n",
        "            ax=ax,\n",
        "            alpha=0.7,\n",
        "            markersize=10,\n",
        "            legend_kwds={'loc': 'upper left', 'bbox_to_anchor': (1, 1)}\n",
        "        )\n",
        "    else:\n",
        "        buildings_with_landuse.plot(ax=ax, alpha=0.7, markersize=10)\n",
        "\n",
        "    # Adicionar um mapa base para contexto\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=buildings_with_landuse.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar o gráfico\n",
        "    ax.set_title(\"Edifícios classificados por Uso do Solo\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Visualizar os resultados\n",
        "fig, ax = visualize_overlay_results(buildings_resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "665c0036",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Realizar uma análise inicial da relação entre edifícios e uso do solo\n",
        "def analyze_building_landuse_relationship(buildings_gdf):\n",
        "    \"\"\"\n",
        "    Analisa a relação entre os edifícios e o uso do solo.\n",
        "\n",
        "    Args:\n",
        "        buildings_gdf: GeoDataFrame com os edifícios e informações de uso do solo\n",
        "    \"\"\"\n",
        "    # Verificar se temos as colunas necessárias\n",
        "    if 'building' in buildings_gdf.columns and 'land_category' in buildings_gdf.columns:\n",
        "        # Criar uma tabela cruzada de tipos de edifícios x categorias de uso do solo\n",
        "        cross_tab = pd.crosstab(\n",
        "            buildings_gdf['building'],\n",
        "            buildings_gdf['land_category'],\n",
        "            margins=True,\n",
        "            normalize='index'\n",
        "        )\n",
        "\n",
        "        print(\"Análise de tipos de edifícios por categoria de uso do solo (normalizado por linha):\")\n",
        "        display(cross_tab)\n",
        "\n",
        "        # Criar um heatmap para visualizar a relação\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(cross_tab.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "        plt.title('Distribuição de Tipos de Edifícios por Categoria de Uso do Solo')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        # Tentar encontrar colunas alternativas\n",
        "        building_col = None\n",
        "        landuse_col = None\n",
        "\n",
        "        for col in buildings_gdf.columns:\n",
        "            if 'build' in col.lower():\n",
        "                building_col = col\n",
        "                break\n",
        "\n",
        "        for col in buildings_gdf.columns:\n",
        "            if 'land' in col.lower() or 'uso' in col.lower():\n",
        "                landuse_col = col\n",
        "                break\n",
        "\n",
        "        if building_col and landuse_col:\n",
        "            print(f\"Usando colunas alternativas: '{building_col}' e '{landuse_col}'\")\n",
        "\n",
        "            # Criar uma tabela cruzada com as colunas alternativas\n",
        "            cross_tab = pd.crosstab(\n",
        "                buildings_gdf[building_col],\n",
        "                buildings_gdf[landuse_col],\n",
        "                margins=True\n",
        "            )\n",
        "\n",
        "            print(f\"Análise de {building_col} por {landuse_col}:\")\n",
        "            display(cross_tab)\n",
        "        else:\n",
        "            print(\"Não foi possível encontrar colunas adequadas para análise de relação edifício-uso do solo.\")\n",
        "\n",
        "# Importar biblioteca adicional para visualização\n",
        "import seaborn as sns\n",
        "\n",
        "# Realizar análise da relação entre edifícios e uso do solo\n",
        "analyze_building_landuse_relationship(buildings_resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5b36610",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Salvar o resultado para uso nos próximos notebooks\n",
        "def save_results(buildings_with_landuse, filename='buildings_with_landuse.gpkg'):\n",
        "    \"\"\"\n",
        "    Salva os resultados da sobreposição espacial para uso posterior.\n",
        "\n",
        "    Args:\n",
        "        buildings_with_landuse: GeoDataFrame com os resultados\n",
        "        filename: Nome do arquivo para salvamento\n",
        "    \"\"\"\n",
        "    # Criar pasta de resultados se não existir\n",
        "    results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Caminho completo para o arquivo\n",
        "    result_path = os.path.join(results_dir, filename)\n",
        "\n",
        "    # Salvar como GeoPackage\n",
        "    buildings_with_landuse.to_file(result_path, driver='GPKG')\n",
        "\n",
        "    # Salvar também como pickle para preservar tipos de dados\n",
        "    pickle_path = os.path.join(results_dir, 'buildings_with_landuse.pkl')\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(buildings_with_landuse, f)\n",
        "\n",
        "    print(f\"Resultados salvos em:\\n- {result_path}\\n- {pickle_path}\")\n",
        "\n",
        "    return result_path, pickle_path\n",
        "\n",
        "# Salvar os resultados\n",
        "gpkg_path, pickle_path = save_results(buildings_resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d41d9d3b",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusão\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA SOBREPOSIÇÃO ESPACIAL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Estatísticas gerais\n",
        "building_count = len(buildings_resolved)\n",
        "landuse_categories = buildings_resolved['land_category'].nunique() if 'land_category' in buildings_resolved.columns else \"N/A\"\n",
        "null_landuse = buildings_resolved['landuse_id'].isna().sum() if 'landuse_id' in buildings_resolved.columns else \"N/A\"\n",
        "\n",
        "print(f\"Total de edifícios processados: {building_count}\")\n",
        "print(f\"Categorias de uso do solo identificadas: {landuse_categories}\")\n",
        "print(f\"Edifícios sem uso do solo associado: {null_landuse}\")\n",
        "\n",
        "print(\"\\nPrincipais distribuições:\")\n",
        "if 'land_category' in buildings_resolved.columns:\n",
        "    top_categories = buildings_resolved['land_category'].value_counts().head(5)\n",
        "    for category, count in top_categories.items():\n",
        "        print(f\"  - {category}: {count} edifícios ({count/building_count*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nPróximos passos:\")\n",
        "print(\"1. Categorização funcional dos edifícios usando as informações de uso do solo\")\n",
        "print(\"2. Análise de conformidade entre o uso real e o designado\")\n",
        "print(\"3. Criação de mapas temáticos de uso e ocupação do solo\")\n",
        "\n",
        "print(f\"\\nOs resultados foram salvos e estão prontos para uso nos próximos notebooks:\")\n",
        "print(f\"- GeoPackage: {os.path.basename(gpkg_path)}\")\n",
        "print(f\"- Pickle: {os.path.basename(pickle_path)}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c169948",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Categorização Funcional de Edifícios\n",
        "# Este notebook enriquece a classificação dos edifícios usando dados de uso do solo\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import contextily as cx\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "\n",
        "# Ignorar avisos específicos\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definição dos diretórios\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "buildings_landuse_pkl = os.path.join(results_dir, 'buildings_with_landuse.pkl')\n",
        "\n",
        "# Verificando se o arquivo existe\n",
        "if not os.path.exists(buildings_landuse_pkl):\n",
        "    raise FileNotFoundError(f\"Arquivo não encontrado: {buildings_landuse_pkl}. Execute o notebook 2.1_Sobreposicao_Espacial.ipynb primeiro.\")\n",
        "\n",
        "# Carregando os dados da etapa anterior\n",
        "with open(buildings_landuse_pkl, 'rb') as f:\n",
        "    buildings_with_landuse = pickle.load(f)\n",
        "\n",
        "print(f\"Dados carregados: {len(buildings_with_landuse)} edifícios com informações de uso do solo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cc82661",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Explorar os dados disponíveis para a categorização\n",
        "def explore_building_attributes(gdf):\n",
        "    \"\"\"\n",
        "    Explora os atributos disponíveis para categorização dos edifícios.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com os edifícios e informações de uso do solo\n",
        "    \"\"\"\n",
        "    # Verificar as colunas disponíveis\n",
        "    building_cols = [col for col in gdf.columns if 'build' in col.lower()]\n",
        "    landuse_cols = [col for col in gdf.columns if 'land' in col.lower() or 'uso' in col.lower()]\n",
        "    amenity_cols = [col for col in gdf.columns if 'amen' in col.lower()]\n",
        "    function_cols = [col for col in gdf.columns if 'func' in col.lower() or 'class' in col.lower()]\n",
        "\n",
        "    print(\"Colunas disponíveis para categorização:\")\n",
        "    print(f\"- Colunas de edifício: {building_cols}\")\n",
        "    print(f\"- Colunas de uso do solo: {landuse_cols}\")\n",
        "    print(f\"- Colunas de amenidades: {amenity_cols}\")\n",
        "    print(f\"- Colunas de função/classe: {function_cols}\")\n",
        "\n",
        "    # Explorar valores únicos em colunas principais\n",
        "    for cols in [building_cols, landuse_cols, amenity_cols, function_cols]:\n",
        "        for col in cols:\n",
        "            if col in gdf.columns:\n",
        "                values = gdf[col].dropna().unique()\n",
        "                print(f\"\\nValores únicos em '{col}' ({len(values)} valores):\")\n",
        "                if len(values) > 20:\n",
        "                    print(values[:20], \"... (mais valores)\")\n",
        "                else:\n",
        "                    print(values)\n",
        "\n",
        "# Explorando os atributos disponíveis\n",
        "explore_building_attributes(buildings_with_landuse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a81ffc3",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Definir a hierarquia de categorização funcional\n",
        "def define_functional_categories():\n",
        "    \"\"\"\n",
        "    Define a hierarquia e regras para categorização funcional dos edifícios.\n",
        "\n",
        "    Returns:\n",
        "        Dicionário com definições de categorias funcionais e mapeamento de valores\n",
        "    \"\"\"\n",
        "    # Definição hierárquica das categorias funcionais\n",
        "    categories = {\n",
        "        'residencial': {\n",
        "            'description': 'Edifícios residenciais unifamiliares e multifamiliares',\n",
        "            'subcategories': {\n",
        "                'unifamiliar': ['house', 'detached', 'bungalow', 'semidetached_house'],\n",
        "                'multifamiliar': ['apartments', 'residential', 'terrace'],\n",
        "                'misto': ['residential;commercial', 'mixed']\n",
        "            },\n",
        "            'landuse_match': ['residential', 'habitacional']\n",
        "        },\n",
        "        'comercial': {\n",
        "            'description': 'Edifícios comerciais e de serviços',\n",
        "            'subcategories': {\n",
        "                'varejo': ['retail', 'shop', 'store', 'supermarket', 'mall'],\n",
        "                'escritorios': ['commercial', 'office', 'offices', 'company'],\n",
        "                'hospedagem': ['hotel', 'hostel', 'motel', 'guest_house'],\n",
        "                'restauracao': ['restaurant', 'cafe', 'fast_food', 'food_court']\n",
        "            },\n",
        "            'landuse_match': ['commercial', 'retail', 'commercial']\n",
        "        },\n",
        "        'industrial': {\n",
        "            'description': 'Edifícios industriais e de armazenamento',\n",
        "            'subcategories': {\n",
        "                'fabrica': ['industrial', 'factory', 'manufacturing'],\n",
        "                'armazenamento': ['warehouse', 'storage', 'depot', 'shed'],\n",
        "                'logistica': ['logistics', 'distribution']\n",
        "            },\n",
        "            'landuse_match': ['industrial', 'industrial', 'manufacturing']\n",
        "        },\n",
        "        'institucional': {\n",
        "            'description': 'Edifícios institucionais e de serviços públicos',\n",
        "            'subcategories': {\n",
        "                'educacao': ['school', 'university', 'college', 'kindergarten', 'educational'],\n",
        "                'saude': ['hospital', 'clinic', 'healthcare', 'doctors', 'healthcare'],\n",
        "                'governo': ['government', 'public', 'townhall', 'civic'],\n",
        "                'religioso': ['church', 'mosque', 'temple', 'religious', 'place_of_worship'],\n",
        "                'cultural': ['theatre', 'cinema', 'library', 'museum', 'arts_centre']\n",
        "            },\n",
        "            'landuse_match': ['institutional', 'education', 'healthcare', 'religious']\n",
        "        },\n",
        "        'infraestrutura': {\n",
        "            'description': 'Infraestrutura e serviços urbanos',\n",
        "            'subcategories': {\n",
        "                'transporte': ['transportation', 'train_station', 'bus_station', 'terminal'],\n",
        "                'utilidades': ['utility', 'water_works', 'power', 'substation'],\n",
        "                'seguranca': ['police', 'fire_station', 'military']\n",
        "            },\n",
        "            'landuse_match': ['transportation', 'infrastructure']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Mapeamentos específicos de valores para otimizar a categorização\n",
        "    value_mappings = {\n",
        "        # Mapeamento de valores de building para categorias\n",
        "        'building_to_category': {\n",
        "            'house': 'residencial.unifamiliar',\n",
        "            'residential': 'residencial.multifamiliar',\n",
        "            'apartments': 'residencial.multifamiliar',\n",
        "            'commercial': 'comercial.escritorios',\n",
        "            'retail': 'comercial.varejo',\n",
        "            'industrial': 'industrial.fabrica',\n",
        "            'warehouse': 'industrial.armazenamento',\n",
        "            'school': 'institucional.educacao',\n",
        "            'university': 'institucional.educacao',\n",
        "            'hospital': 'institucional.saude',\n",
        "            'church': 'institucional.religioso',\n",
        "            'hotel': 'comercial.hospedagem',\n",
        "            'public': 'institucional.governo',\n",
        "            'office': 'comercial.escritorios',\n",
        "            'shed': 'industrial.armazenamento'\n",
        "        },\n",
        "\n",
        "        # Mapeamento de tipos de uso do solo para categorias funcionais\n",
        "        'landuse_to_category': {\n",
        "            'residential': 'residencial',\n",
        "            'commercial': 'comercial',\n",
        "            'retail': 'comercial',\n",
        "            'industrial': 'industrial',\n",
        "            'institutional': 'institucional',\n",
        "            'mixed': 'residencial.misto',\n",
        "            'education': 'institucional.educacao',\n",
        "            'healthcare': 'institucional.saude',\n",
        "            'transportation': 'infraestrutura.transporte',\n",
        "            'green': None,  # Uso do solo não implica diretamente em categoria funcional\n",
        "            'recreational': None,\n",
        "            'agriculture': None,\n",
        "            'water': None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return {'categories': categories, 'mappings': value_mappings}\n",
        "\n",
        "# Definindo as categorias funcionais\n",
        "functional_categories = define_functional_categories()\n",
        "\n",
        "# Exibindo a estrutura das categorias\n",
        "for category, info in functional_categories['categories'].items():\n",
        "    print(f\"\\n{category.upper()} - {info['description']}\")\n",
        "    for subcategory, values in info['subcategories'].items():\n",
        "        print(f\"  - {subcategory}: {', '.join(values[:3])}{'...' if len(values) > 3 else ''}\")\n",
        "    print(f\"  Usos do solo correspondentes: {', '.join(info['landuse_match'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0590a624",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Função para categorizar edifícios com base em atributos e uso do solo\n",
        "def categorize_buildings(gdf, categories_def):\n",
        "    \"\"\"\n",
        "    Categoriza edifícios com base em suas características e uso do solo.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifícios e informações de uso do solo\n",
        "        categories_def: Definição de categorias funcionais\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com novas colunas de categorização\n",
        "    \"\"\"\n",
        "    # Criar uma cópia para não modificar o original\n",
        "    categorized_gdf = gdf.copy()\n",
        "\n",
        "    # Extrair mapeamentos e categorias\n",
        "    categories = categories_def['categories']\n",
        "    mappings = categories_def['mappings']\n",
        "\n",
        "    # Inicializar colunas para categorização\n",
        "    categorized_gdf['categoria_funcional'] = None\n",
        "    categorized_gdf['subcategoria_funcional'] = None\n",
        "    categorized_gdf['fonte_categoria'] = None\n",
        "\n",
        "    # Identificar colunas disponíveis para categorização\n",
        "    building_col = next((col for col in categorized_gdf.columns if col == 'building'), None)\n",
        "    landuse_col = next((col for col in categorized_gdf.columns if col in ['landuse', 'land_category']), None)\n",
        "    amenity_col = next((col for col in categorized_gdf.columns if col == 'amenity'), None)\n",
        "\n",
        "    print(f\"Usando colunas para categorização: building={building_col}, landuse={landuse_col}, amenity={amenity_col}\")\n",
        "\n",
        "    # Contadores para estatísticas\n",
        "    categorization_stats = {\n",
        "        'total': len(categorized_gdf),\n",
        "        'from_building': 0,\n",
        "        'from_amenity': 0,\n",
        "        'from_landuse': 0,\n",
        "        'uncategorized': 0\n",
        "    }\n",
        "\n",
        "    # Etapa 1: Categorizar com base no tipo de edifício\n",
        "    if building_col:\n",
        "        for idx, row in tqdm(categorized_gdf.iterrows(), total=len(categorized_gdf), desc=\"Categorizando por tipo de edifício\"):\n",
        "            building_value = row[building_col]\n",
        "\n",
        "            if pd.notna(building_value) and building_value in mappings['building_to_category']:\n",
        "                category_path = mappings['building_to_category'][building_value]\n",
        "                if '.' in category_path:\n",
        "                    main_cat, sub_cat = category_path.split('.')\n",
        "                    categorized_gdf.at[idx, 'categoria_funcional'] = main_cat\n",
        "                    categorized_gdf.at[idx, 'subcategoria_funcional'] = sub_cat\n",
        "                else:\n",
        "                    categorized_gdf.at[idx, 'categoria_funcional'] = category_path\n",
        "\n",
        "                categorized_gdf.at[idx, 'fonte_categoria'] = 'building'\n",
        "                categorization_stats['from_building'] += 1\n",
        "\n",
        "    # Etapa 2: Complementar categorização com base em amenidades\n",
        "    if amenity_col:\n",
        "        for idx, row in tqdm(categorized_gdf.iterrows(), total=len(categorized_gdf), desc=\"Categorizando por amenidades\"):\n",
        "            # Só categorizar se ainda não foi categorizado\n",
        "            if pd.isna(row['categoria_funcional']) and pd.notna(row[amenity_col]):\n",
        "                amenity_value = row[amenity_col]\n",
        "\n",
        "                # Mapeamento simplificado de amenidades para categorias\n",
        "                amenity_mapping = {\n",
        "                    'school': 'institucional.educacao',\n",
        "                    'university': 'institucional.educacao',\n",
        "                    'library': 'institucional.cultural',\n",
        "                    'hospital': 'institucional.saude',\n",
        "                    'clinic': 'institucional.saude',\n",
        "                    'doctors': 'institucional.saude',\n",
        "                    'restaurant': 'comercial.restauracao',\n",
        "                    'cafe': 'comercial.restauracao',\n",
        "                    'fast_food': 'comercial.restauracao',\n",
        "                    'bank': 'comercial.escritorios',\n",
        "                    'marketplace': 'comercial.varejo',\n",
        "                    'place_of_worship': 'institucional.religioso',\n",
        "                    'police': 'infraestrutura.seguranca',\n",
        "                    'fire_station': 'infraestrutura.seguranca',\n",
        "                    'post_office': 'institucional.governo',\n",
        "                    'town_hall': 'institucional.governo'\n",
        "                }\n",
        "\n",
        "                if amenity_value in amenity_mapping:\n",
        "                    category_path = amenity_mapping[amenity_value]\n",
        "                    if '.' in category_path:\n",
        "                        main_cat, sub_cat = category_path.split('.')\n",
        "                        categorized_gdf.at[idx, 'categoria_funcional'] = main_cat\n",
        "                        categorized_gdf.at[idx, 'subcategoria_funcional'] = sub_cat\n",
        "                    else:\n",
        "                        categorized_gdf.at[idx, 'categoria_funcional'] = category_path\n",
        "\n",
        "                    categorized_gdf.at[idx, 'fonte_categoria'] = 'amenity'\n",
        "                    categorization_stats['from_amenity'] += 1\n",
        "\n",
        "    # Etapa 3: Complementar categorização com base no uso do solo\n",
        "    if landuse_col:\n",
        "        for idx, row in tqdm(categorized_gdf.iterrows(), total=len(categorized_gdf), desc=\"Categorizando por uso do solo\"):\n",
        "            # Só categorizar se ainda não foi categorizado\n",
        "            if pd.isna(row['categoria_funcional']) and pd.notna(row[landuse_col]):\n",
        "                landuse_value = row[landuse_col]\n",
        "\n",
        "                # Verificar se o valor de uso do solo está no mapeamento\n",
        "                if str(landuse_value).lower() in [k.lower() for k in mappings['landuse_to_category'].keys()]:\n",
        "                    # Encontrar a chave correspondente (ignorando maiúsculas/minúsculas)\n",
        "                    for key, value in mappings['landuse_to_category'].items():\n",
        "                        if str(landuse_value).lower() == key.lower() and value is not None:\n",
        "                            categorized_gdf.at[idx, 'categoria_funcional'] = value\n",
        "                            categorized_gdf.at[idx, 'fonte_categoria'] = 'landuse'\n",
        "                            categorization_stats['from_landuse'] += 1\n",
        "                            break\n",
        "\n",
        "    # Contar não categorizados\n",
        "    categorization_stats['uncategorized'] = categorization_stats['total'] - sum([\n",
        "        categorization_stats['from_building'],\n",
        "        categorization_stats['from_amenity'],\n",
        "        categorization_stats['from_landuse']\n",
        "    ])\n",
        "\n",
        "    # Exibir estatísticas\n",
        "    print(\"\\nEstatísticas de categorização:\")\n",
        "    print(f\"- Total de edifícios: {categorization_stats['total']}\")\n",
        "    print(f\"- Categorizados por tipo de edifício: {categorization_stats['from_building']} ({categorization_stats['from_building']/categorization_stats['total']*100:.2f}%)\")\n",
        "    print(f\"- Categorizados por amenidades: {categorization_stats['from_amenity']} ({categorization_stats['from_amenity']/categorization_stats['total']*100:.2f}%)\")\n",
        "    print(f\"- Categorizados por uso do solo: {categorization_stats['from_landuse']} ({categorization_stats['from_landuse']/categorization_stats['total']*100:.2f}%)\")\n",
        "    print(f\"- Não categorizados: {categorization_stats['uncategorized']} ({categorization_stats['uncategorized']/categorization_stats['total']*100:.2f}%)\")\n",
        "\n",
        "    return categorized_gdf, categorization_stats\n",
        "\n",
        "# Categorizar os edifícios\n",
        "categorized_buildings, cat_stats = categorize_buildings(buildings_with_landuse, functional_categories)\n",
        "\n",
        "# Exibir amostra do resultado\n",
        "print(\"\\nAmostra do resultado da categorização:\")\n",
        "display(categorized_buildings[['categoria_funcional', 'subcategoria_funcional', 'fonte_categoria']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a52498e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Analisar e visualizar os resultados da categorização\n",
        "def analyze_categorization_results(gdf, cat_stats):\n",
        "    \"\"\"\n",
        "    Analisa e visualiza os resultados da categorização funcional.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifícios categorizados\n",
        "        cat_stats: Estatísticas da categorização\n",
        "    \"\"\"\n",
        "    # Distribuição de categorias principais\n",
        "    main_categories = gdf['categoria_funcional'].dropna().value_counts()\n",
        "\n",
        "    # Gráfico de categorias principais\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    main_categories.plot(kind='bar', color='skyblue')\n",
        "    plt.title('Distribuição de Categorias Funcionais Principais')\n",
        "    plt.xlabel('Categoria')\n",
        "    plt.ylabel('Número de Edifícios')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Distribuição de subcategorias\n",
        "    subcategories = gdf.dropna(subset=['subcategoria_funcional'])\n",
        "    subcategory_counts = subcategories.groupby(['categoria_funcional', 'subcategoria_funcional']).size().unstack(fill_value=0)\n",
        "\n",
        "    # Gráfico de subcategorias (empilhado)\n",
        "    if not subcategory_counts.empty:\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        subcategory_counts.plot(kind='bar', stacked=True, cmap='viridis')\n",
        "        plt.title('Distribuição de Subcategorias Funcionais')\n",
        "        plt.xlabel('Categoria Principal')\n",
        "        plt.ylabel('Número de Edifícios')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.legend(title='Subcategoria', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Não há dados de subcategorias para visualização.\")\n",
        "\n",
        "    # Distribuição por fonte de categorização\n",
        "    source_dist = gdf['fonte_categoria'].value_counts()\n",
        "\n",
        "    # Gráfico de pizza da fonte de categorização\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    source_dist.plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('pastel'), startangle=90)\n",
        "    plt.title('Fonte de Categorização Funcional')\n",
        "    plt.ylabel('')\n",
        "    plt.axis('equal')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Análise cruzada de categoria x uso do solo\n",
        "    if 'land_category' in gdf.columns:\n",
        "        cross_tab = pd.crosstab(\n",
        "            gdf['categoria_funcional'],\n",
        "            gdf['land_category'],\n",
        "            margins=True,\n",
        "            normalize='index'\n",
        "        )\n",
        "\n",
        "        print(\"Análise cruzada: Categorias funcionais x Uso do solo (normalizado por linha):\")\n",
        "        display(cross_tab)\n",
        "\n",
        "        # Heatmap da relação\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(cross_tab.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "        plt.title('Distribuição de Categorias Funcionais por Uso do Solo')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Analisar os resultados da categorização\n",
        "analyze_categorization_results(categorized_buildings, cat_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26c4d74f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar os edifícios categorizados em um mapa\n",
        "def map_categorized_buildings(gdf, figsize=(15, 15), sample_size=1000):\n",
        "    \"\"\"\n",
        "    Cria um mapa dos edifícios categorizados.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifícios categorizados\n",
        "        figsize: Tamanho da figura\n",
        "        sample_size: Tamanho da amostra para visualização\n",
        "    \"\"\"\n",
        "    # Filtrar apenas edifícios categorizados\n",
        "    categorized = gdf.dropna(subset=['categoria_funcional']).copy()\n",
        "\n",
        "    # Se tiver muitos edifícios, amostrar para melhor visualização\n",
        "    if len(categorized) > sample_size:\n",
        "        categorized = categorized.sample(sample_size)\n",
        "\n",
        "    # Criar mapa\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Preparar uma paleta de cores\n",
        "    n_categories = categorized['categoria_funcional'].nunique()\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, n_categories))\n",
        "\n",
        "    # Plotar por categoria\n",
        "    for i, (category, group) in enumerate(categorized.groupby('categoria_funcional')):\n",
        "        color = colors[i % len(colors)]\n",
        "        group.plot(ax=ax, color=color, label=category, alpha=0.7, markersize=20)\n",
        "\n",
        "    # Adicionar mapa base\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=gdf.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar gráfico\n",
        "    ax.set_title('Categorização Funcional de Edifícios', fontsize=16)\n",
        "    ax.legend(title='Categoria Funcional', loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Criar mapa de edifícios categorizados\n",
        "fig, ax = map_categorized_buildings(categorized_buildings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f708e38e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Adicionar a classificação funcional ao GeoDataFrame original\n",
        "def finalize_categorization(gdf, existing_class_col=None):\n",
        "    \"\"\"\n",
        "    Finaliza a categorização criando uma coluna de classificação final.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com categorização preliminar\n",
        "        existing_class_col: Nome da coluna de classificação existente, se houver\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com classificação final\n",
        "    \"\"\"\n",
        "    # Criar cópia para não modificar o original\n",
        "    final_gdf = gdf.copy()\n",
        "\n",
        "    # Criar coluna de classificação final\n",
        "    final_gdf['building_class_enhanced'] = None\n",
        "\n",
        "    # Verificar se já existe uma coluna de classificação\n",
        "    if existing_class_col and existing_class_col in final_gdf.columns:\n",
        "        print(f\"Incorporando classificação existente da coluna '{existing_class_col}'\")\n",
        "        # Copiar classificação existente como base\n",
        "        final_gdf['building_class_enhanced'] = final_gdf[existing_class_col]\n",
        "\n",
        "    # Prioridade: categorização nova > classificação existente\n",
        "    for idx, row in tqdm(final_gdf.iterrows(), total=len(final_gdf), desc=\"Finalizando categorização\"):\n",
        "        # Se temos categoria funcional, usá-la\n",
        "        if pd.notna(row['categoria_funcional']):\n",
        "            # Se temos subcategoria, incluí-la na classificação\n",
        "            if pd.notna(row['subcategoria_funcional']):\n",
        "                classification = f\"{row['categoria_funcional']}_{row['subcategoria_funcional']}\"\n",
        "            else:\n",
        "                classification = row['categoria_funcional']\n",
        "\n",
        "            final_gdf.at[idx, 'building_class_enhanced'] = classification\n",
        "\n",
        "    # Para edifícios sem classificação final, tentar usar outros atributos\n",
        "    unclassified = final_gdf['building_class_enhanced'].isna()\n",
        "    print(f\"Edifícios ainda sem classificação: {unclassified.sum()} ({unclassified.sum()/len(final_gdf)*100:.2f}%)\")\n",
        "\n",
        "    if unclassified.any():\n",
        "        # Tentar usar 'building' para os não classificados\n",
        "        if 'building' in final_gdf.columns:\n",
        "            for idx in final_gdf[unclassified].index:\n",
        "                if pd.notna(final_gdf.at[idx, 'building']):\n",
        "                    final_gdf.at[idx, 'building_class_enhanced'] = f\"unclassified_{final_gdf.at[idx, 'building']}\"\n",
        "\n",
        "        # Atualizar contagem de não classificados\n",
        "        unclassified = final_gdf['building_class_enhanced'].isna()\n",
        "        print(f\"Edifícios ainda sem classificação após uso de 'building': {unclassified.sum()} ({unclassified.sum()/len(final_gdf)*100:.2f}%)\")\n",
        "\n",
        "        # Para os restantes, usar 'other' como classificação\n",
        "        final_gdf.loc[unclassified, 'building_class_enhanced'] = 'other'\n",
        "\n",
        "    # Exibir estatísticas da classificação final\n",
        "    final_stats = final_gdf['building_class_enhanced'].value_counts().head(10)\n",
        "    print(\"\\nTop 10 classificações finais:\")\n",
        "    for class_name, count in final_stats.items():\n",
        "        print(f\"- {class_name}: {count} ({count/len(final_gdf)*100:.2f}%)\")\n",
        "\n",
        "    return final_gdf\n",
        "\n",
        "# Identificar coluna de classificação existente, se houver\n",
        "existing_class_cols = [col for col in categorized_buildings.columns if 'class' in col.lower() and col != 'categoria_funcional']\n",
        "existing_class_col = existing_class_cols[0] if existing_class_cols else None\n",
        "\n",
        "# Finalizar a categorização\n",
        "final_categorized_buildings = finalize_categorization(categorized_buildings, existing_class_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf5ca3d9",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Validar a categorização final\n",
        "def validate_categorization(gdf, validation_sample_size=100):\n",
        "    \"\"\"\n",
        "    Validação da categorização funcional.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com a categorização final\n",
        "        validation_sample_size: Tamanho da amostra para validação manual\n",
        "    \"\"\"\n",
        "    # Análise de consistência entre categorias e atributos\n",
        "    consistency_metrics = {}\n",
        "\n",
        "    # Verificar consistência entre building e classificação\n",
        "    if 'building' in gdf.columns:\n",
        "        building_match = []\n",
        "        for idx, row in gdf.iterrows():\n",
        "            if pd.notna(row['building']) and pd.notna(row['building_class_enhanced']):\n",
        "                # Verificar se o tipo de edifício está refletido na classificação\n",
        "                building_match.append(str(row['building']).lower() in str(row['building_class_enhanced']).lower())\n",
        "\n",
        "        if building_match:\n",
        "            consistency_metrics['building_match_rate'] = sum(building_match) / len(building_match)\n",
        "\n",
        "    # Verificar consistência entre uso do solo e classificação\n",
        "    landuse_col = next((col for col in gdf.columns if col in ['landuse', 'land_category']), None)\n",
        "    if landuse_col:\n",
        "        landuse_consistency = []\n",
        "\n",
        "        # Mapeamentos esperados de uso do solo para categoria\n",
        "        expected_matches = {\n",
        "            'residential': ['residencial'],\n",
        "            'commercial': ['comercial'],\n",
        "            'industrial': ['industrial'],\n",
        "            'institutional': ['institucional'],\n",
        "            'mixed': ['residencial_misto', 'misto']\n",
        "        }\n",
        "\n",
        "        for idx, row in gdf.iterrows():\n",
        "            if pd.notna(row[landuse_col]) and pd.notna(row['building_class_enhanced']):\n",
        "                # Verificar se a classificação é compatível com o uso do solo\n",
        "                landuse_value = str(row[landuse_col]).lower()\n",
        "                found_match = False\n",
        "\n",
        "                for landuse_key, matching_categories in expected_matches.items():\n",
        "                    if landuse_key in landuse_value:\n",
        "                        found_match = any(match in str(row['building_class_enhanced']).lower() for match in matching_categories)\n",
        "                        if found_match:\n",
        "                            break\n",
        "\n",
        "                landuse_consistency.append(found_match)\n",
        "\n",
        "        if landuse_consistency:\n",
        "            consistency_metrics['landuse_consistency_rate'] = sum(landuse_consistency) / len(landuse_consistency)\n",
        "\n",
        "    # Exibir métricas de consistência\n",
        "    print(\"Métricas de consistência da categorização:\")\n",
        "    for metric, value in consistency_metrics.items():\n",
        "        print(f\"- {metric}: {value:.2f} ({value*100:.2f}%)\")\n",
        "\n",
        "    # Criar amostra para validação manual\n",
        "    validation_sample = gdf.sample(min(validation_sample_size, len(gdf)))\n",
        "\n",
        "    # Exibir amostra com atributos relevantes para validação manual\n",
        "    columns_to_show = ['building_class_enhanced', 'categoria_funcional', 'subcategoria_funcional']\n",
        "    if 'building' in gdf.columns:\n",
        "        columns_to_show.append('building')\n",
        "    if landuse_col:\n",
        "        columns_to_show.append(landuse_col)\n",
        "    if 'amenity' in gdf.columns:\n",
        "        columns_to_show.append('amenity')\n",
        "\n",
        "    print(\"\\nAmostra para validação manual:\")\n",
        "    display(validation_sample[columns_to_show])\n",
        "\n",
        "    return consistency_metrics, validation_sample\n",
        "\n",
        "# Validar a categorização\n",
        "consistency_metrics, validation_sample = validate_categorization(final_categorized_buildings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d34e9b6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Salvar o resultado final para uso no próximo notebook\n",
        "def save_final_categorization(gdf, filename='buildings_categorized.gpkg'):\n",
        "    \"\"\"\n",
        "    Salva a categorização final para uso posterior.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com a categorização final\n",
        "        filename: Nome do arquivo para salvamento\n",
        "    \"\"\"\n",
        "    # Criar pasta de resultados se não existir\n",
        "    results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Caminho completo para o arquivo\n",
        "    result_path = os.path.join(results_dir, filename)\n",
        "\n",
        "    # Salvar como GeoPackage\n",
        "    gdf.to_file(result_path, driver='GPKG')\n",
        "\n",
        "    # Salvar também como pickle para preservar tipos de dados\n",
        "    pickle_path = os.path.join(results_dir, 'buildings_categorized.pkl')\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(gdf, f)\n",
        "\n",
        "    print(f\"Categorização final salva em:\\n- {result_path}\\n- {pickle_path}\")\n",
        "\n",
        "    return result_path, pickle_path\n",
        "\n",
        "# Salvar a categorização final\n",
        "gpkg_path, pickle_path = save_final_categorization(final_categorized_buildings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc52532e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusão\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA CATEGORIZAÇÃO FUNCIONAL DE EDIFÍCIOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Estatísticas gerais\n",
        "total_buildings = len(final_categorized_buildings)\n",
        "categorized_count = final_categorized_buildings['categoria_funcional'].notna().sum()\n",
        "categories_count = final_categorized_buildings['categoria_funcional'].nunique()\n",
        "subcategories_count = final_categorized_buildings['subcategoria_funcional'].nunique()\n",
        "\n",
        "print(f\"Total de edifícios processados: {total_buildings}\")\n",
        "print(f\"Edifícios categorizados: {categorized_count} ({categorized_count/total_buildings*100:.2f}%)\")\n",
        "print(f\"Número de categorias principais: {categories_count}\")\n",
        "print(f\"Número de subcategorias: {subcategories_count}\")\n",
        "\n",
        "print(\"\\nDistribuição por categoria funcional:\")\n",
        "category_counts = final_categorized_buildings['categoria_funcional'].value_counts()\n",
        "for category, count in category_counts.items():\n",
        "    if pd.notna(category):\n",
        "        print(f\"  - {category}: {count} ({count/categorized_count*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nConsistência da categorização:\")\n",
        "for metric, value in consistency_metrics.items():\n",
        "    print(f\"  - {metric}: {value:.2f} ({value*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nMelhorias realizadas:\")\n",
        "print(\"1. Categorização funcional hierárquica (categoria e subcategoria)\")\n",
        "print(\"2. Integração das informações de uso do solo com os atributos dos edifícios\")\n",
        "print(\"3. Preenchimento de lacunas na classificação original\")\n",
        "print(\"4. Normalização da nomenclatura das categorias\")\n",
        "\n",
        "print(\"\\nPróximos passos:\")\n",
        "print(\"1. Análise de conformidade entre o uso real e o zoneamento\")\n",
        "print(\"2. Integração com análises demográficas\")\n",
        "print(\"3. Mapeamento temático avançado por categoria funcional\")\n",
        "\n",
        "print(f\"\\nA categorização funcional foi salva e está pronta para o próximo notebook:\")\n",
        "print(f\"- GeoPackage: {os.path.basename(gpkg_path)}\")\n",
        "print(f\"- Pickle: {os.path.basename(pickle_path)}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ada865"
      },
      "source": [
        "2.3_Analise_Conformidade_Uso.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c811edc",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Análise de Conformidade de Uso do Solo\n",
        "# Este notebook analisa a conformidade entre o uso real dos edifícios e o zoneamento\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import contextily as cx\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Ignorar avisos específicos\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definição dos diretórios\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "buildings_categorized_pkl = os.path.join(results_dir, 'buildings_categorized.pkl')\n",
        "\n",
        "# Verificando se o arquivo existe\n",
        "if not os.path.exists(buildings_categorized_pkl):\n",
        "    raise FileNotFoundError(f\"Arquivo não encontrado: {buildings_categorized_pkl}. Execute o notebook 2.2_Categorizacao_Funcional_Edificios.ipynb primeiro.\")\n",
        "\n",
        "# Carregando os dados da etapa anterior\n",
        "with open(buildings_categorized_pkl, 'rb') as f:\n",
        "    buildings_categorized = pickle.load(f)\n",
        "\n",
        "print(f\"Dados carregados: {len(buildings_categorized)} edifícios categorizados.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9365408",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Explorar os dados de zoneamento disponíveis\n",
        "def explore_landuse_data(gdf):\n",
        "    \"\"\"\n",
        "    Explora os dados de zoneamento disponíveis para análise de conformidade.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifícios categorizados e informações de uso do solo\n",
        "    \"\"\"\n",
        "    # Identificar colunas relacionadas a uso do solo\n",
        "    landuse_cols = [col for col in gdf.columns if 'land' in col.lower() or 'uso' in col.lower() or 'zon' in col.lower()]\n",
        "\n",
        "    print(f\"Colunas relacionadas a uso do solo: {landuse_cols}\")\n",
        "\n",
        "    # Explorar valores em colunas específicas\n",
        "    for col in landuse_cols:\n",
        "        if col in gdf.columns:\n",
        "            value_counts = gdf[col].value_counts()\n",
        "            unique_count = len(value_counts)\n",
        "\n",
        "            print(f\"\\nValores únicos em '{col}' ({unique_count} valores):\")\n",
        "            if unique_count > 20:\n",
        "                display(value_counts.head(20))\n",
        "                print(\"...\")\n",
        "            else:\n",
        "                display(value_counts)\n",
        "\n",
        "    # Identificar coluna principal de uso do solo (primeiramente explícita, depois derivada)\n",
        "    primary_landuse_col = None\n",
        "\n",
        "    for col_name in ['land_category', 'landuse', 'land_use', 'zoning']:\n",
        "        if col_name in gdf.columns and gdf[col_name].notna().any():\n",
        "            primary_landuse_col = col_name\n",
        "            break\n",
        "\n",
        "    if primary_landuse_col is None:\n",
        "        for col in landuse_cols:\n",
        "            if gdf[col].notna().any():\n",
        "                primary_landuse_col = col\n",
        "                break\n",
        "\n",
        "    if primary_landuse_col:\n",
        "        print(f\"\\nColuna principal de uso do solo identificada: '{primary_landuse_col}'\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma coluna adequada de uso do solo encontrada.\")\n",
        "\n",
        "    return primary_landuse_col\n",
        "\n",
        "# Explorar os dados de zoneamento\n",
        "primary_landuse_col = explore_landuse_data(buildings_categorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adb00cff",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Definir regras de conformidade para avaliação\n",
        "def define_conformity_rules():\n",
        "    \"\"\"\n",
        "    Define as regras para avaliação de conformidade entre uso real e zoneamento.\n",
        "\n",
        "    Returns:\n",
        "        Dicionário com regras de conformidade\n",
        "    \"\"\"\n",
        "    # Matriz de compatibilidade: {categoria de uso do solo: [categorias funcionais permitidas]}\n",
        "    conformity_matrix = {\n",
        "        # Zonas residenciais\n",
        "        'residential': {\n",
        "            'allowed': ['residencial', 'institucional_educacao', 'institucional_religioso'],\n",
        "            'conditional': ['comercial_varejo', 'comercial_escritorios', 'institucional_saude'],\n",
        "            'forbidden': ['industrial', 'infraestrutura']\n",
        "        },\n",
        "\n",
        "        # Zonas comerciais\n",
        "        'commercial': {\n",
        "            'allowed': ['comercial', 'residencial_misto', 'institucional'],\n",
        "            'conditional': ['residencial', 'industrial_armazenamento'],\n",
        "            'forbidden': ['industrial_fabrica', 'infraestrutura_utilidades']\n",
        "        },\n",
        "\n",
        "        # Zonas industriais\n",
        "        'industrial': {\n",
        "            'allowed': ['industrial', 'infraestrutura', 'comercial_escritorios'],\n",
        "            'conditional': ['comercial_varejo', 'comercial_restauracao'],\n",
        "            'forbidden': ['residencial', 'institucional_saude', 'institucional_educacao']\n",
        "        },\n",
        "\n",
        "        # Zonas institucionais\n",
        "        'institutional': {\n",
        "            'allowed': ['institucional', 'infraestrutura_seguranca', 'comercial_escritorios'],\n",
        "            'conditional': ['comercial', 'residencial'],\n",
        "            'forbidden': ['industrial']\n",
        "        },\n",
        "\n",
        "        # Zonas mistas\n",
        "        'mixed': {\n",
        "            'allowed': ['residencial', 'comercial', 'institucional'],\n",
        "            'conditional': ['industrial_armazenamento', 'infraestrutura'],\n",
        "            'forbidden': ['industrial_fabrica']\n",
        "        },\n",
        "\n",
        "        # Zonas verdes/rurais\n",
        "        'green': {\n",
        "            'allowed': ['institucional_cultural', 'infraestrutura_utilidades'],\n",
        "            'conditional': ['comercial_restauracao', 'institucional'],\n",
        "            'forbidden': ['residencial', 'comercial_varejo', 'industrial']\n",
        "        },\n",
        "\n",
        "        # Zonas de conservação\n",
        "        'conservation': {\n",
        "            'allowed': ['institucional_cultural'],\n",
        "            'conditional': ['infraestrutura_utilidades'],\n",
        "            'forbidden': ['residencial', 'comercial', 'industrial', 'institucional_saude']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Lista de sinônimos para cada categoria (para flexibilizar a correspondência)\n",
        "    category_synonyms = {\n",
        "        'residential': ['residencial', 'habitacional', 'housing', 'dwelling'],\n",
        "        'commercial': ['comercial', 'retail', 'business', 'service'],\n",
        "        'industrial': ['industrial', 'factory', 'manufacturing', 'plant'],\n",
        "        'institutional': ['institucional', 'public', 'government', 'education', 'health'],\n",
        "        'mixed': ['mixed', 'misto', 'mixed_use', 'multiple'],\n",
        "        'green': ['green', 'park', 'recreation', 'forest', 'rural', 'agriculture'],\n",
        "        'conservation': ['conservation', 'preserve', 'protected', 'environmental']\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'conformity_matrix': conformity_matrix,\n",
        "        'category_synonyms': category_synonyms\n",
        "    }\n",
        "\n",
        "# Definir as regras de conformidade\n",
        "conformity_rules = define_conformity_rules()\n",
        "\n",
        "# Exibir a matriz de conformidade\n",
        "print(\"Matriz de Conformidade de Uso do Solo:\")\n",
        "for zone, rules in conformity_rules['conformity_matrix'].items():\n",
        "    print(f\"\\n{zone.upper()}:\")\n",
        "    print(f\"  Permitido: {', '.join(rules['allowed'])}\")\n",
        "    print(f\"  Condicional: {', '.join(rules['conditional'])}\")\n",
        "    print(f\"  Proibido: {', '.join(rules['forbidden'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2729223",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Analisar a conformidade entre uso real e zoneamento\n",
        "def analyze_conformity(gdf, landuse_col, conformity_rules):\n",
        "    \"\"\"\n",
        "    Analisa a conformidade entre o uso real dos edifícios e o zoneamento.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifícios categorizados\n",
        "        landuse_col: Coluna principal de uso do solo\n",
        "        conformity_rules: Regras de conformidade definidas\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com análise de conformidade\n",
        "    \"\"\"\n",
        "    # Criar cópia para não modificar o original\n",
        "    conformity_gdf = gdf.copy()\n",
        "\n",
        "    # Inicializar colunas de conformidade\n",
        "    conformity_gdf['conformidade_uso'] = None\n",
        "    conformity_gdf['nivel_conformidade'] = None\n",
        "    conformity_gdf['regra_aplicada'] = None\n",
        "\n",
        "    # Extrair regras e sinônimos\n",
        "    matrix = conformity_rules['conformity_matrix']\n",
        "    synonyms = conformity_rules['category_synonyms']\n",
        "\n",
        "    # Função para determinar a categoria de zoneamento\n",
        "    def get_zoning_category(landuse_value):\n",
        "        if pd.isna(landuse_value):\n",
        "            return None\n",
        "\n",
        "        landuse_lower = str(landuse_value).lower()\n",
        "\n",
        "        # Verificar correspondência direta\n",
        "        for category, synonyms_list in synonyms.items():\n",
        "            if any(syn in landuse_lower for syn in synonyms_list):\n",
        "                return category\n",
        "\n",
        "        # Se não há correspondência direta, tentar correspondência parcial\n",
        "        for category, synonyms_list in synonyms.items():\n",
        "            for syn in synonyms_list:\n",
        "                if syn in landuse_lower or landuse_lower in syn:\n",
        "                    return category\n",
        "\n",
        "        return None\n",
        "\n",
        "    # Função para determinar a conformidade\n",
        "    def evaluate_conformity(zoning_category, functional_category):\n",
        "        if pd.isna(zoning_category) or pd.isna(functional_category):\n",
        "            return None, None, None\n",
        "\n",
        "        if zoning_category not in matrix:\n",
        "            return \"não avaliado\", \"desconhecido\", f\"categoria de zoneamento '{zoning_category}' não definida na matriz\"\n",
        "\n",
        "        # Verificar se a categoria funcional está nas listas de conformidade\n",
        "        for level, categories in [('permitido', matrix[zoning_category]['allowed']),\n",
        "                                  ('condicional', matrix[zoning_category]['conditional']),\n",
        "                                  ('proibido', matrix[zoning_category]['forbidden'])]:\n",
        "            # Verificar correspondência direta\n",
        "            if any(functional_category.startswith(cat) for cat in categories):\n",
        "                conformity = \"conforme\" if level != \"proibido\" else \"não conforme\"\n",
        "                return conformity, level, f\"categoria funcional '{functional_category}' é {level} em zona '{zoning_category}'\"\n",
        "\n",
        "            # Verificar correspondência por subcategoria (se categoria_subcategoria)\n",
        "            if '_' in functional_category:\n",
        "                main_cat = functional_category.split('_')[0]\n",
        "                if any(main_cat.startswith(cat) for cat in categories):\n",
        "                    conformity = \"conforme\" if level != \"proibido\" else \"não conforme\"\n",
        "                    return conformity, level, f\"categoria funcional '{main_cat}' é {level} em zona '{zoning_category}'\"\n",
        "\n",
        "        # Se não encontrou em nenhuma lista, considerar como não avaliado\n",
        "        return \"não avaliado\", \"desconhecido\", \"sem regra aplicável definida\"\n",
        "\n",
        "    # Aplicar análise de conformidade\n",
        "    for idx, row in tqdm(conformity_gdf.iterrows(), total=len(conformity_gdf), desc=\"Analisando conformidade\"):\n",
        "        # Obter categoria de zoneamento\n",
        "        if pd.notna(row[landuse_col]):\n",
        "            zoning_category = get_zoning_category(row[landuse_col])\n",
        "        else:\n",
        "            zoning_category = None\n",
        "\n",
        "        # Obter categoria funcional\n",
        "        functional_category = row['building_class_enhanced'] if pd.notna(row['building_class_enhanced']) else None\n",
        "\n",
        "        # Avaliar conformidade\n",
        "        if zoning_category and functional_category:\n",
        "            conformity, level, rule = evaluate_conformity(zoning_category, functional_category)\n",
        "\n",
        "            conformity_gdf.at[idx, 'conformidade_uso'] = conformity\n",
        "            conformity_gdf.at[idx, 'nivel_conformidade'] = level\n",
        "            conformity_gdf.at[idx, 'regra_aplicada'] = rule\n",
        "\n",
        "    # Estatísticas de conformidade\n",
        "    conformity_stats = conformity_gdf['conformidade_uso'].value_counts()\n",
        "\n",
        "    print(\"\\nEstatísticas de conformidade:\")\n",
        "    for status, count in conformity_stats.items():\n",
        "        if pd.notna(status):\n",
        "            print(f\"- {status}: {count} ({count/len(conformity_gdf)*100:.2f}%)\")\n",
        "\n",
        "    # Estatísticas por nível\n",
        "    level_stats = conformity_gdf['nivel_conformidade'].value_counts()\n",
        "\n",
        "    print(\"\\nEstatísticas por nível de conformidade:\")\n",
        "    for level, count in level_stats.items():\n",
        "        if pd.notna(level):\n",
        "            print(f\"- {level}: {count} ({count/len(conformity_gdf)*100:.2f}%)\")\n",
        "\n",
        "    return conformity_gdf, conformity_stats, level_stats\n",
        "\n",
        "# Analisar a conformidade\n",
        "conformity_gdf, conformity_stats, level_stats = analyze_conformity(buildings_categorized, primary_landuse_col, conformity_rules)\n",
        "\n",
        "# Exibir amostra do resultado\n",
        "print(\"\\nAmostra do resultado da análise de conformidade:\")\n",
        "display(conformity_gdf[['building_class_enhanced', primary_landuse_col, 'conformidade_uso', 'nivel_conformidade']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "293436b1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar a conformidade de uso em mapa\n",
        "def map_conformity(gdf, sample_size=1000, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Cria um mapa temático da conformidade de uso do solo.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com análise de conformidade\n",
        "        sample_size: Tamanho da amostra para visualização\n",
        "        figsize: Tamanho da figura\n",
        "    \"\"\"\n",
        "    # Filtrar apenas edifícios com conformidade avaliada\n",
        "    conformity_map = gdf.dropna(subset=['conformidade_uso']).copy()\n",
        "\n",
        "    # Se tiver muitos edifícios, amostrar para melhor visualização\n",
        "    if len(conformity_map) > sample_size:\n",
        "        conformity_map = conformity_map.sample(sample_size)\n",
        "\n",
        "    # Definir cores para os diferentes status de conformidade\n",
        "    color_dict = {\n",
        "        'conforme': '#1b9e77',  # Verde\n",
        "        'não conforme': '#d95f02',  # Laranja/Vermelho\n",
        "        'não avaliado': '#7570b3'  # Azul/Roxo\n",
        "    }\n",
        "\n",
        "    # Criar mapa\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Plotar por status de conformidade\n",
        "    for status, group in conformity_map.groupby('conformidade_uso'):\n",
        "        if pd.notna(status) and status in color_dict:\n",
        "            color = color_dict[status]\n",
        "            group.plot(ax=ax, color=color, label=status, alpha=0.7, markersize=20)\n",
        "\n",
        "    # Adicionar mapa base\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=gdf.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar gráfico\n",
        "    ax.set_title('Conformidade de Uso do Solo', fontsize=16)\n",
        "    ax.legend(title='Status de Conformidade', loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Criar mapa de conformidade\n",
        "fig, ax = map_conformity(conformity_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8048b809",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Analisar a conformidade por zona e categoria\n",
        "def analyze_conformity_patterns(gdf, landuse_col):\n",
        "    \"\"\"\n",
        "    Analisa padrões de conformidade por zona e categoria funcional.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com análise de conformidade\n",
        "        landuse_col: Coluna principal de uso do solo\n",
        "    \"\"\"\n",
        "    # Criar tabela cruzada de conformidade por zona\n",
        "    if landuse_col in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        cross_zone = pd.crosstab(\n",
        "            gdf[landuse_col],\n",
        "            gdf['conformidade_uso'],\n",
        "            normalize='index',\n",
        "            margins=True\n",
        "        )\n",
        "\n",
        "        print(\"Análise de conformidade por zona (normalizado por linha):\")\n",
        "        display(cross_zone)\n",
        "\n",
        "        # Visualizar com heatmap\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        if not cross_zone.empty and cross_zone.shape[0] > 1 and cross_zone.shape[1] > 1:\n",
        "            sns.heatmap(cross_zone.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "            plt.title('Conformidade por Zona de Uso do Solo')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # Criar tabela cruzada de conformidade por categoria funcional\n",
        "    if 'categoria_funcional' in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        cross_category = pd.crosstab(\n",
        "            gdf['categoria_funcional'],\n",
        "            gdf['conformidade_uso'],\n",
        "            normalize='index',\n",
        "            margins=True\n",
        "        )\n",
        "\n",
        "        print(\"\\nAnálise de conformidade por categoria funcional (normalizado por linha):\")\n",
        "        display(cross_category)\n",
        "\n",
        "        # Visualizar com heatmap\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        if not cross_category.empty and cross_category.shape[0] > 1 and cross_category.shape[1] > 1:\n",
        "            sns.heatmap(cross_category.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "            plt.title('Conformidade por Categoria Funcional')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # Análise de hotspots de não conformidade\n",
        "    if 'conformidade_uso' in gdf.columns:\n",
        "        nonconforming = gdf[gdf['conformidade_uso'] == 'não conforme'].copy()\n",
        "\n",
        "        if len(nonconforming) > 0:\n",
        "            print(f\"\\nHotspots de não conformidade ({len(nonconforming)} edifícios):\")\n",
        "\n",
        "            # Agrupar por zona e categoria funcional\n",
        "            hotspots = nonconforming.groupby([landuse_col, 'categoria_funcional']).size().reset_index()\n",
        "            hotspots.columns = [landuse_col, 'categoria_funcional', 'count']\n",
        "            hotspots = hotspots.sort_values('count', ascending=False)\n",
        "\n",
        "            display(hotspots.head(10))\n",
        "\n",
        "            # Visualizar hotspots em mapa\n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            # Densidade de Kernel\n",
        "            try:\n",
        "                # Se tiver muitos pontos, usar densidade de Kernel\n",
        "                if len(nonconforming) > 50:\n",
        "                    nonconforming_projected = nonconforming.to_crs(epsg=3857)  # Projetar para Mercator para melhor visualização\n",
        "                    ax = nonconforming_projected.plot(color='red', alpha=0.1, markersize=5)\n",
        "\n",
        "                    from scipy.stats import gaussian_kde\n",
        "                    x = nonconforming_projected.geometry.x\n",
        "                    y = nonconforming_projected.geometry.y\n",
        "\n",
        "                    # Calcular densidade de pontos\n",
        "                    xy = np.vstack([x, y])\n",
        "                    z = gaussian_kde(xy)(xy)\n",
        "\n",
        "                    # Ordenar os pontos pela densidade\n",
        "                    idx = z.argsort()\n",
        "                    x, y, z = x.iloc[idx], y.iloc[idx], z[idx]\n",
        "\n",
        "                    plt.scatter(x, y, c=z, s=50, alpha=0.5, cmap='Reds')\n",
        "                    plt.colorbar(label='Densidade de Não Conformidade')\n",
        "\n",
        "                    try:\n",
        "                        cx.add_basemap(ax, crs=nonconforming_projected.crs)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "                    plt.title('Hotspots de Não Conformidade de Uso do Solo')\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                else:\n",
        "                    # Se tiver poucos pontos, mostrar apenas os pontos\n",
        "                    ax = nonconforming.plot(color='red', alpha=0.7, markersize=30)\n",
        "\n",
        "                    try:\n",
        "                        cx.add_basemap(ax, crs=nonconforming.crs)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "                    plt.title('Edifícios com Uso Não Conforme')\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Não foi possível criar o mapa de hotspots: {e}\")\n",
        "\n",
        "# Analisar padrões de conformidade\n",
        "analyze_conformity_patterns(conformity_gdf, primary_landuse_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77844410",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Calcular índices de conformidade\n",
        "def calculate_conformity_indices(gdf):\n",
        "    \"\"\"\n",
        "    Calcula índices de conformidade para análise quantitativa.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com análise de conformidade\n",
        "    \"\"\"\n",
        "    # Inicializar dicionário de índices\n",
        "    indices = {}\n",
        "\n",
        "    # Índice geral de conformidade (% de edifícios conformes)\n",
        "    if 'conformidade_uso' in gdf.columns:\n",
        "        conforming = gdf['conformidade_uso'] == 'conforme'\n",
        "        non_conforming = gdf['conformidade_uso'] == 'não conforme'\n",
        "        assessed = gdf['conformidade_uso'].notna()\n",
        "\n",
        "        if assessed.any():\n",
        "            indices['indice_geral'] = conforming.sum() / assessed.sum()\n",
        "\n",
        "        # Índice de não conformidade\n",
        "        if assessed.any():\n",
        "            indices['indice_nao_conformidade'] = non_conforming.sum() / assessed.sum()\n",
        "\n",
        "        # Cobertura da avaliação (% de edifícios avaliados)\n",
        "        indices['cobertura_avaliacao'] = assessed.sum() / len(gdf)\n",
        "\n",
        "    # Índices por categoria funcional\n",
        "    if 'categoria_funcional' in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        category_indices = {}\n",
        "        for category in gdf['categoria_funcional'].dropna().unique():\n",
        "            category_mask = gdf['categoria_funcional'] == category\n",
        "            category_assessed = category_mask & gdf['conformidade_uso'].notna()\n",
        "            category_conforming = category_mask & (gdf['conformidade_uso'] == 'conforme')\n",
        "\n",
        "            if category_assessed.any():\n",
        "                category_indices[category] = category_conforming.sum() / category_assessed.sum()\n",
        "\n",
        "        indices['indices_por_categoria'] = category_indices\n",
        "\n",
        "    # Índices por zona\n",
        "    if primary_landuse_col in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        zone_indices = {}\n",
        "        for zone in gdf[primary_landuse_col].dropna().unique():\n",
        "            zone_mask = gdf[primary_landuse_col] == zone\n",
        "            zone_assessed = zone_mask & gdf['conformidade_uso'].notna()\n",
        "            zone_conforming = zone_mask & (gdf['conformidade_uso'] == 'conforme')\n",
        "\n",
        "            if zone_assessed.any():\n",
        "                zone_indices[zone] = zone_conforming.sum() / zone_assessed.sum()\n",
        "\n",
        "        indices['indices_por_zona'] = zone_indices\n",
        "\n",
        "    # Exibir índices calculados\n",
        "    print(\"Índices de Conformidade de Uso do Solo:\")\n",
        "\n",
        "    if 'indice_geral' in indices:\n",
        "        print(f\"- Índice Geral de Conformidade: {indices['indice_geral']:.4f} ({indices['indice_geral']*100:.2f}%)\")\n",
        "\n",
        "    if 'indice_nao_conformidade' in indices:\n",
        "        print(f\"- Índice de Não Conformidade: {indices['indice_nao_conformidade']:.4f} ({indices['indice_nao_conformidade']*100:.2f}%)\")\n",
        "\n",
        "    if 'cobertura_avaliacao' in indices:\n",
        "        print(f\"- Cobertura da Avaliação: {indices['cobertura_avaliacao']:.4f} ({indices['cobertura_avaliacao']*100:.2f}%)\")\n",
        "\n",
        "    # Visualizar índices por categoria\n",
        "    if 'indices_por_categoria' in indices:\n",
        "        print(\"\\nÍndices de Conformidade por Categoria Funcional:\")\n",
        "        category_df = pd.DataFrame(list(indices['indices_por_categoria'].items()),\n",
        "                                  columns=['Categoria', 'Índice'])\n",
        "        category_df = category_df.sort_values('Índice', ascending=False)\n",
        "\n",
        "        # Exibir índices\n",
        "        for _, row in category_df.iterrows():\n",
        "            print(f\"- {row['Categoria']}: {row['Índice']:.4f} ({row['Índice']*100:.2f}%)\")\n",
        "\n",
        "        # Visualizar gráfico\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Índice', y='Categoria', data=category_df, palette='viridis')\n",
        "        plt.title('Índices de Conformidade por Categoria Funcional')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Visualizar índices por zona\n",
        "    if 'indices_por_zona' in indices:\n",
        "        print(\"\\nÍndices de Conformidade por Zona:\")\n",
        "        zone_df = pd.DataFrame(list(indices['indices_por_zona'].items()),\n",
        "                              columns=['Zona', 'Índice'])\n",
        "        zone_df = zone_df.sort_values('Índice', ascending=False)\n",
        "\n",
        "        # Exibir índices\n",
        "        for _, row in zone_df.iterrows():\n",
        "            print(f\"- {row['Zona']}: {row['Índice']:.4f} ({row['Índice']*100:.2f}%)\")\n",
        "\n",
        "        # Visualizar gráfico\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Índice', y='Zona', data=zone_df, palette='viridis')\n",
        "        plt.title('Índices de Conformidade por Zona')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return indices\n",
        "\n",
        "# Calcular índices de conformidade\n",
        "conformity_indices = calculate_conformity_indices(conformity_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ab708f6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Identificar anomalias e padrões espaciais\n",
        "def identify_anomalies(gdf, landuse_col):\n",
        "    \"\"\"\n",
        "    Identifica anomalias e padrões espaciais de não conformidade.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com análise de conformidade\n",
        "        landuse_col: Coluna principal de uso do solo\n",
        "    \"\"\"\n",
        "    # Identificar áreas com alta concentração de não conformidade\n",
        "    if 'conformidade_uso' in gdf.columns:\n",
        "        nonconforming = gdf[gdf['conformidade_uso'] == 'não conforme'].copy()\n",
        "\n",
        "        if len(nonconforming) > 0:\n",
        "            print(f\"Análise de anomalias em {len(nonconforming)} edifícios não conformes:\")\n",
        "\n",
        "            # Calcular proporção de não conformidade por zona\n",
        "            zone_stats = pd.crosstab(\n",
        "                gdf[landuse_col],\n",
        "                gdf['conformidade_uso'],\n",
        "                normalize='index'\n",
        "            )\n",
        "\n",
        "            # Ordenar zonas por taxa de não conformidade\n",
        "            if 'não conforme' in zone_stats.columns:\n",
        "                non_conform_rates = zone_stats['não conforme'].sort_values(ascending=False)\n",
        "\n",
        "                print(\"\\nZonas com maior taxa de não conformidade:\")\n",
        "                for zone, rate in non_conform_rates.head(5).items():\n",
        "                    print(f\"- {zone}: {rate:.4f} ({rate*100:.2f}%)\")\n",
        "\n",
        "            # Análise de conflitos típicos\n",
        "            print(\"\\nConflitos típicos (combinações zona x categoria funcional não conformes):\")\n",
        "            conflicts = nonconforming.groupby([landuse_col, 'categoria_funcional']).size()\n",
        "            conflicts = conflicts.reset_index().rename(columns={0: 'count'})\n",
        "            conflicts = conflicts.sort_values('count', ascending=False)\n",
        "\n",
        "            for _, row in conflicts.head(5).iterrows():\n",
        "                print(f\"- {row[landuse_col]} x {row['categoria_funcional']}: {row['count']} ocorrências\")\n",
        "\n",
        "            # Análise de proximidade entre edifícios não conformes\n",
        "            if len(nonconforming) > 1:\n",
        "                try:\n",
        "                    # Criar buffer ao redor de edifícios não conformes\n",
        "                    buffer_distance = 100  # Metros\n",
        "                    nonconforming_proj = nonconforming.to_crs(epsg=3857)  # Projetar para calcular em metros\n",
        "                    nonconforming_buffers = nonconforming_proj.buffer(buffer_distance)\n",
        "\n",
        "                    # Unir os buffers sobrepostos\n",
        "                    from shapely.ops import unary_union\n",
        "                    unified_buffers = unary_union(nonconforming_buffers)\n",
        "\n",
        "                    # Converter para GeoDataFrame\n",
        "                    if hasattr(unified_buffers, '__iter__'):\n",
        "                        # Se for uma coleção de geometrias\n",
        "                        clusters = gpd.GeoDataFrame(geometry=list(unified_buffers), crs=nonconforming_proj.crs)\n",
        "                    else:\n",
        "                        # Se for uma única geometria\n",
        "                        clusters = gpd.GeoDataFrame(geometry=[unified_buffers], crs=nonconforming_proj.crs)\n",
        "\n",
        "                    # Contar edifícios em cada cluster\n",
        "                    clusters['n_edificios'] = 0\n",
        "                    for i, cluster in enumerate(clusters.geometry):\n",
        "                        count = sum(nonconforming_proj.geometry.intersects(cluster))\n",
        "                        clusters.at[i, 'n_edificios'] = count\n",
        "\n",
        "                    # Ordenar clusters por número de edifícios\n",
        "                    clusters = clusters.sort_values('n_edificios', ascending=False)\n",
        "\n",
        "                    print(f\"\\nIdentificados {len(clusters)} clusters de não conformidade (buffer de {buffer_distance}m):\")\n",
        "                    for i, (_, cluster) in enumerate(clusters.head(5).iterrows()):\n",
        "                        print(f\"- Cluster {i+1}: {cluster['n_edificios']} edifícios não conformes\")\n",
        "\n",
        "                    # Visualizar clusters\n",
        "                    if len(clusters) > 0:\n",
        "                        # Projetar de volta para CRS original\n",
        "                        clusters = clusters.to_crs(gdf.crs)\n",
        "\n",
        "                        fig, ax = plt.subplots(figsize=(15, 15))\n",
        "\n",
        "                        # Plotar todos os edifícios como contexto\n",
        "                        gdf.plot(ax=ax, color='lightgray', alpha=0.3, markersize=5)\n",
        "\n",
        "                        # Plotar edifícios não conformes\n",
        "                        nonconforming.plot(ax=ax, color='red', alpha=0.7, markersize=30)\n",
        "\n",
        "                        # Plotar clusters de não conformidade\n",
        "                        clusters.plot(ax=ax, color='blue', alpha=0.2, edgecolor='blue')\n",
        "\n",
        "                        # Adicionar mapa base\n",
        "                        try:\n",
        "                            cx.add_basemap(ax, crs=gdf.crs)\n",
        "                        except Exception as e:\n",
        "                            print(f\"Não foi possível adicionar o mapa base: {e}\")\n",
        "\n",
        "                        # Configurar gráfico\n",
        "                        ax.set_title('Clusters de Não Conformidade de Uso do Solo', fontsize=16)\n",
        "                        plt.tight_layout()\n",
        "                        plt.show()\n",
        "                except Exception as e:\n",
        "                    print(f\"Não foi possível realizar a análise de clusters: {e}\")\n",
        "        else:\n",
        "            print(\"Nenhum edifício não conforme encontrado para análise de anomalias.\")\n",
        "\n",
        "# Identificar anomalias e padrões\n",
        "identify_anomalies(conformity_gdf, primary_landuse_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b8e4f4c",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Salvar o resultado final com a análise de conformidade\n",
        "def save_conformity_analysis(gdf, filename='buildings_conformity.gpkg'):\n",
        "    \"\"\"\n",
        "    Salva a análise de conformidade para uso posterior.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com análise de conformidade\n",
        "        filename: Nome do arquivo para salvamento\n",
        "    \"\"\"\n",
        "    # Criar pasta de resultados se não existir\n",
        "    results_dir = os.path.join(data_dir, 'results')\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Caminho completo para o arquivo\n",
        "    result_path = os.path.join(results_dir, filename)\n",
        "\n",
        "    # Salvar como GeoPackage\n",
        "    gdf.to_file(result_path, driver='GPKG')\n",
        "\n",
        "    # Salvar também como pickle para preservar tipos de dados\n",
        "    pickle_path = os.path.join(results_dir, 'buildings_conformity.pkl')\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(gdf, f)\n",
        "\n",
        "    # Salvar índices de conformidade\n",
        "    indices_path = os.path.join(results_dir, 'conformity_indices.json')\n",
        "    pd.Series(conformity_indices).to_json(indices_path)\n",
        "\n",
        "    print(f\"Análise de conformidade salva em:\\n- {result_path}\\n- {pickle_path}\")\n",
        "    print(f\"Índices de conformidade salvos em: {indices_path}\")\n",
        "\n",
        "    return result_path, pickle_path, indices_path\n",
        "\n",
        "# Salvar a análise de conformidade\n",
        "gpkg_path, pickle_path, indices_path = save_conformity_analysis(conformity_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b45dcf8",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusão\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA ANÁLISE DE CONFORMIDADE DE USO DO SOLO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Estatísticas gerais\n",
        "total_buildings = len(conformity_gdf)\n",
        "assessed_count = conformity_gdf['conformidade_uso'].notna().sum()\n",
        "conforming_count = (conformity_gdf['conformidade_uso'] == 'conforme').sum()\n",
        "non_conforming_count = (conformity_gdf['conformidade_uso'] == 'não conforme').sum()\n",
        "\n",
        "print(f\"Total de edifícios analisados: {total_buildings}\")\n",
        "print(f\"Edifícios com conformidade avaliada: {assessed_count} ({assessed_count/total_buildings*100:.2f}%)\")\n",
        "print(f\"Edifícios conformes: {conforming_count} ({conforming_count/assessed_count*100:.2f}% dos avaliados)\")\n",
        "print(f\"Edifícios não conformes: {non_conforming_count} ({non_conforming_count/assessed_count*100:.2f}% dos avaliados)\")\n",
        "\n",
        "# Principais conflitos\n",
        "if non_conforming_count > 0:\n",
        "    print(\"\\nPrincipais conflitos identificados:\")\n",
        "    conflicts = conformity_gdf[conformity_gdf['conformidade_uso'] == 'não conforme'].groupby([primary_landuse_col, 'categoria_funcional']).size()\n",
        "    conflicts = conflicts.reset_index().rename(columns={0: 'count'})\n",
        "    conflicts = conflicts.sort_values('count', ascending=False)\n",
        "\n",
        "    for _, row in conflicts.head(5).iterrows():\n",
        "        print(f\"- {row[primary_landuse_col]} x {row['categoria_funcional']}: {row['count']} ocorrências ({row['count']/non_conforming_count*100:.2f}% dos não conformes)\")\n",
        "\n",
        "# Recomendações\n",
        "print(\"\\nRecomendações para planejamento urbano:\")\n",
        "print(\"1. Revisar zoneamento em áreas com alta concentração de não conformidade\")\n",
        "print(\"2. Considerar ajustes nas regras de uso permitido para zonas com baixa conformidade\")\n",
        "print(\"3. Implementar zonas de transição em áreas com conflitos frequentes\")\n",
        "print(\"4. Monitorar evolução da conformidade ao longo do tempo\")\n",
        "\n",
        "print(\"\\nPróximos passos:\")\n",
        "print(\"1. Integração com análises demográficas para avaliar impacto populacional\")\n",
        "print(\"2. Análise de tendências temporais de conformidade (se dados históricos disponíveis)\")\n",
        "print(\"3. Modelagem de cenários de alteração de zoneamento\")\n",
        "\n",
        "print(f\"\\nA análise de conformidade foi salva e está pronta para uso em outras análises:\")\n",
        "print(f\"- GeoPackage: {os.path.basename(gpkg_path)}\")\n",
        "print(f\"- Pickle: {os.path.basename(pickle_path)}\")\n",
        "print(f\"- Índices: {os.path.basename(indices_path)}\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17188148bd854eb89e0f61acf242d7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cfa2fb3c5983469bb1fbf54ae9b033b9",
            "placeholder": "​",
            "style": "IPY_MODEL_d60ee9a724284044a90fff3b1f158d41",
            "tabbable": null,
            "tooltip": null,
            "value": " 1/9 [00:01&lt;00:08,  1.09s/it]"
          }
        },
        "19db4ff634f54c39bb1ce3b1155cbf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b2254247fbf4fad903828370d9f2fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2c76f7f484374f7683e5af25ccf4eb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4093e2ad6186493ba9290c878eab1758",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19db4ff634f54c39bb1ce3b1155cbf8a",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "4093e2ad6186493ba9290c878eab1758": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522231ed2fe14bfea5356b522cf08375": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54234ad943de4155987bb7994692e1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_522231ed2fe14bfea5356b522cf08375",
            "placeholder": "​",
            "style": "IPY_MODEL_1b2254247fbf4fad903828370d9f2fca",
            "tabbable": null,
            "tooltip": null,
            "value": " 1/1 [00:01&lt;00:00,  1.07s/it]"
          }
        },
        "655cf9cd39d64c46b46148f4a8bf7fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9952b233b734b459546a4cc82c79440",
              "IPY_MODEL_2c76f7f484374f7683e5af25ccf4eb07",
              "IPY_MODEL_54234ad943de4155987bb7994692e1b6"
            ],
            "layout": "IPY_MODEL_fe0a3275e4b3400590d860bbb3f99f33",
            "tabbable": null,
            "tooltip": null
          }
        },
        "8b066468064f4cd4a668528cfaf1fd4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b78089f74154151a2b7589978d14963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73455c14a1244888389dfa9c0b8dfe1",
              "IPY_MODEL_a113fff2f6114caa9e8221ffddaeb12c",
              "IPY_MODEL_17188148bd854eb89e0f61acf242d7bb"
            ],
            "layout": "IPY_MODEL_8e6e321e23ab4d5f8028f6e2a9d66ca2",
            "tabbable": null,
            "tooltip": null
          }
        },
        "8e6e321e23ab4d5f8028f6e2a9d66ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2269378cc04fc0b865c11a738f1cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a113fff2f6114caa9e8221ffddaeb12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cc833ad3e9e54ec6adbce3033fd839e7",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4a7c0f07888431e97d8c6c275c5e662",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "a73455c14a1244888389dfa9c0b8dfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8b066468064f4cd4a668528cfaf1fd4f",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8efe577f5a4ce4b919037badd406cf",
            "tabbable": null,
            "tooltip": null,
            "value": "Carregando arquivos GPKG:  11%"
          }
        },
        "ad2422bb71b84313b81380767388d2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "cc833ad3e9e54ec6adbce3033fd839e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa2fb3c5983469bb1fbf54ae9b033b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60ee9a724284044a90fff3b1f158d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f4a7c0f07888431e97d8c6c275c5e662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9952b233b734b459546a4cc82c79440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9f2269378cc04fc0b865c11a738f1cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_ad2422bb71b84313b81380767388d2e3",
            "tabbable": null,
            "tooltip": null,
            "value": "Camadas em inmet_processed.gpkg: 100%"
          }
        },
        "fc8efe577f5a4ce4b919037badd406cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fe0a3275e4b3400590d860bbb3f99f33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
