{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D0mP3dr0/geoprocessing_gnn/blob/main/geoprocessing_gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z7e7-1lZSbr"
      },
      "source": [
        "CRIACAO DO GRAFO INTRACAMADA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrRMRDsyZSHz",
        "outputId": "529b9ca4-7b04-4459-cc50-f69807c0d346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: me de o comando para carregar o drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIS70xouqJR-"
      },
      "source": [
        "ğŸ““ 1_Configuracao_Ambiente/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH2ghAPRqJR-",
        "outputId": "0d93e4e3-5fa9-428f-abc8-f6dff7cc833f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Apr 13 20:35:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   39C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Verificar o tipo de GPU disponÃ­vel\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qCBmkGUqJR-",
        "outputId": "adb08d05-37a6-4c9f-9396-3ef2d72d6566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VersÃ£o do Python: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n"
          ]
        }
      ],
      "source": [
        "# Verificar a versÃ£o do Python e ambiente atual\n",
        "import sys\n",
        "print(f\"VersÃ£o do Python: {sys.version}\")\n",
        "!pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_oX6eBxqJR-",
        "outputId": "04c122ae-2287-4810-9506-b268b15144f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (3.7.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rtree\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pycrs\n",
            "  Downloading PyCRS-1.0.2.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mapclassify\n",
            "  Downloading mapclassify-2.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: pyogrio in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/dist-packages (from mapclassify) (3.4.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from mapclassify) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from mapclassify) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->mapclassify) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->mapclassify) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pycrs\n",
            "  Building wheel for pycrs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycrs: filename=PyCRS-1.0.2-py3-none-any.whl size=32686 sha256=fba5d2566f08a883db1bf559016854e4263800ee89988169e4cbebb40fd708fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/ad/a3/183ed754d7698fc15a2eb153705e05d05a0d97f3331293ce48\n",
            "Successfully built pycrs\n",
            "Installing collected packages: pycrs, rtree, cligj, click-plugins, affine, rasterio, fiona, mapclassify\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 fiona-1.10.1 mapclassify-2.8.1 pycrs-1.0.2 rasterio-1.4.3 rtree-1.4.0\n",
            "Collecting osmnx\n",
            "  Downloading osmnx-2.0.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Collecting keplergl\n",
            "  Downloading keplergl-0.3.7.tar.gz (18.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.4/18.4 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: geopandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.32.3)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.1.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.1.0)\n",
            "Collecting ipywidgets>=8.1.5 (from keplergl)\n",
            "  Using cached ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from keplergl) (0.2.1)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.11/dist-packages (from keplergl) (5.7.1)\n",
            "Collecting jupyter_packaging>=0.12.3 (from keplergl)\n",
            "  Using cached jupyter_packaging-0.12.3-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting jupyter>=1.0.0 (from keplergl)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting jupyterlab>=4.1.6 (from keplergl)\n",
            "  Downloading jupyterlab-4.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: notebook>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from keplergl) (6.5.7)\n",
            "Requirement already satisfied: pyarrow>=16.0.0 in /usr/local/lib/python3.11/dist-packages (from keplergl) (18.1.0)\n",
            "Collecting geoarrow-pyarrow>=0.1.2 (from keplergl)\n",
            "  Downloading geoarrow_pyarrow-0.1.2-py3-none-any.whl.metadata (613 bytes)\n",
            "Collecting geoarrow-pandas>=0.1.1 (from keplergl)\n",
            "  Downloading geoarrow_pandas-0.1.1-py3-none-any.whl.metadata (493 bytes)\n",
            "Collecting geoarrow-c (from geoarrow-pyarrow>=0.1.2->keplergl)\n",
            "  Downloading geoarrow_c-0.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (400 bytes)\n",
            "Collecting pyarrow-hotfix (from geoarrow-pyarrow>=0.1.2->keplergl)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (3.7.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.5->keplergl) (7.34.0)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->keplergl) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->keplergl) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->keplergl) (6.17.1)\n",
            "Collecting deprecation (from jupyter_packaging>=0.12.3->keplergl)\n",
            "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: setuptools>=60.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyter_packaging>=0.12.3->keplergl) (75.2.0)\n",
            "Collecting tomlkit (from jupyter_packaging>=0.12.3->keplergl)\n",
            "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from jupyter_packaging>=0.12.3->keplergl) (0.45.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.1.6->keplergl) (6.4.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (5.10.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=6.0.1->keplergl) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->keplergl) (1.8.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->keplergl) (0.1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->keplergl) (5.9.5)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl)\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=4.1.6->keplergl) (4.3.7)\n",
            "Collecting jupyter-client<8,>=5.3.4 (from notebook>=6.0.1->keplergl)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=6.0.1->keplergl) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8,>=5.3.4->notebook>=6.0.1->keplergl) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (4.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->keplergl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->keplergl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=6.0.1->keplergl) (2.21.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook>=6.0.1->keplergl) (0.7.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.1.6->keplergl) (4.13.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->keplergl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->keplergl) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.1.6->keplergl) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.5->keplergl) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=6.0.1->keplergl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->keplergl) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=6.0.1->keplergl) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.1.6->keplergl)\n",
            "  Using cached types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading osmnx-2.0.2-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geoarrow_pandas-0.1.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading geoarrow_pyarrow-0.1.2-py3-none-any.whl (26 kB)\n",
            "Using cached ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Using cached jupyter_packaging-0.12.3-py3-none-any.whl (15 kB)\n",
            "Downloading jupyterlab-4.4.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "Using cached jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "Using cached jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
            "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading geoarrow_c-0.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Using cached json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Using cached types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: keplergl\n",
            "  Building wheel for keplergl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keplergl: filename=keplergl-0.3.7-py2.py3-none-any.whl size=35080504 sha256=03c886cb5fc1af0dd7cc627b6e2d42291fdc6d04e2736f277ebcd759e868f7c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/15/4b/f54140da2477a3d3d74bab2fccfc495849a1b3f2ca391f7c18\n",
            "Successfully built keplergl\n",
            "Installing collected packages: widgetsnbextension, uri-template, types-python-dateutil, tomlkit, rfc3986-validator, rfc3339-validator, python-json-logger, pyarrow-hotfix, overrides, jupyterlab_widgets, json5, jedi, geoarrow-c, fqdn, deprecation, comm, async-lru, jupyter-server-terminals, jupyter_packaging, jupyter-client, geoarrow-pyarrow, arrow, isoduration, ipywidgets, geoarrow-pandas, osmnx, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, keplergl\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: jupyterlab_widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed arrow-1.3.0 async-lru-2.0.5 comm-0.2.2 deprecation-2.1.0 fqdn-1.5.1 geoarrow-c-0.1.2 geoarrow-pandas-0.1.1 geoarrow-pyarrow-0.1.2 ipywidgets-8.1.6 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyter_packaging-0.12.3 jupyterlab-4.4.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.14 keplergl-0.3.7 osmnx-2.0.2 overrides-7.7.0 pyarrow-hotfix-0.6 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 tomlkit-0.13.2 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 widgetsnbextension-4.0.14\n",
            "Collecting rasterstats\n",
            "  Downloading rasterstats-0.20.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.1.2)\n",
            "Collecting xarray\n",
            "  Downloading xarray-2025.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.18.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterstats) (2.4.0)\n",
            "Requirement already satisfied: click>7.1 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.4 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (0.7.2)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.11/dist-packages (from rasterstats) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (2.0.2)\n",
            "Requirement already satisfied: rasterio>=1.0 in /usr/local/lib/python3.11/dist-packages (from rasterstats) (1.4.3)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from rasterstats) (3.20.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from rasterstats) (2.1.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.0->rasterstats) (25.3.0)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.0->rasterstats) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.0->rasterstats) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray) (1.17.0)\n",
            "Downloading rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
            "Downloading xarray-2025.3.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rioxarray-0.18.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4, xarray, rasterstats, rioxarray\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2025.1.2\n",
            "    Uninstalling xarray-2025.1.2:\n",
            "      Successfully uninstalled xarray-2025.1.2\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2 rasterstats-0.20.0 rioxarray-0.18.2 xarray-2025.3.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from plotly) (1.33.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, plotly, matplotlib\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "Successfully installed matplotlib-3.10.1 plotly-6.0.1 scipy-1.15.2\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (6.5.7)\n",
            "Collecting notebook\n",
            "  Downloading notebook-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.6)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.0.5)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.1)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.14)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (24.0.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (4.13.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.24.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.8.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
            "Downloading notebook-7.4.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: notebook\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.5.7\n",
            "    Uninstalling notebook-6.5.7:\n",
            "      Successfully uninstalled notebook-6.5.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed notebook-7.4.0\n",
            "Collecting pygeos\n",
            "  Downloading pygeos-0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting contextily\n",
            "  Downloading contextily-1.6.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pysal\n",
            "  Downloading pysal-25.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting momepy\n",
            "  Downloading momepy-0.9.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from pygeos) (2.0.2)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (from contextily) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from contextily) (3.10.1)\n",
            "Collecting mercantile (from contextily)\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from contextily) (11.1.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from contextily) (1.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from contextily) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from contextily) (1.4.2)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from contextily) (2025.1.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.11/dist-packages (from pysal) (4.13.3)\n",
            "Requirement already satisfied: geopandas>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.0.1)\n",
            "Requirement already satisfied: packaging>=22 in /usr/local/lib/python3.11/dist-packages (from pysal) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.2.2)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pysal) (4.3.7)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.15.2)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.1.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.6.1)\n",
            "Collecting libpysal>=4.12.1 (from pysal)\n",
            "  Downloading libpysal-4.13.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting access>=1.1.9 (from pysal)\n",
            "  Downloading access-1.1.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting esda>=2.6.0 (from pysal)\n",
            "  Downloading esda-2.7.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting giddy>=2.3.6 (from pysal)\n",
            "  Downloading giddy-2.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inequality>=1.1.1 (from pysal)\n",
            "  Downloading inequality-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pointpats>=2.5.1 (from pysal)\n",
            "  Downloading pointpats-2.5.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting segregation>=2.5.1 (from pysal)\n",
            "  Downloading segregation-2.5.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting spaghetti>=1.7.6 (from pysal)\n",
            "  Downloading spaghetti-1.7.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mgwr>=2.2.1 (from pysal)\n",
            "  Downloading mgwr-2.2.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting spglm>=1.1.0 (from pysal)\n",
            "  Downloading spglm-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting spint>=1.0.7 (from pysal)\n",
            "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spreg>=1.8.1 (from pysal)\n",
            "  Downloading spreg-1.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tobler>=0.12.1 (from pysal)\n",
            "  Downloading tobler-0.12.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: mapclassify>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.8.1)\n",
            "Collecting splot>=1.1.7 (from pysal)\n",
            "  Downloading splot-1.1.7-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting spopt>=0.6.1 (from pysal)\n",
            "  Downloading spopt-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from momepy) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from momepy) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal) (4.13.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.10.0->pysal) (0.10.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.10.0->pysal) (3.7.1)\n",
            "Collecting quantecon>=0.7 (from giddy>=2.3.6->pysal)\n",
            "  Downloading quantecon-0.8.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->pysal) (3.6.0)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (2.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (0.13.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (0.60.0)\n",
            "Requirement already satisfied: rtree>=1.0 in /usr/local/lib/python3.11/dist-packages (from spaghetti>=1.7.6->pysal) (1.4.0)\n",
            "Collecting pulp>=2.7 (from spopt>=0.6.1->pysal)\n",
            "  Downloading pulp-3.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal) (0.14.4)\n",
            "Requirement already satisfied: rasterstats in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal) (0.20.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy->contextily) (2.0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.11/dist-packages (from mercantile->contextily) (8.1.8)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (25.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->contextily) (1.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from quantecon>=0.7->giddy>=2.3.6->pysal) (1.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->segregation>=2.5.1->pysal) (0.43.0)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.11/dist-packages (from rasterstats->tobler>=0.12.1->pysal) (1.10.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from rasterstats->tobler>=0.12.1->pysal) (3.20.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->tobler>=0.12.1->pysal) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal) (1.3.0)\n",
            "Downloading pygeos-0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextily-1.6.2-py3-none-any.whl (17 kB)\n",
            "Downloading pysal-25.1-py3-none-any.whl (17 kB)\n",
            "Downloading momepy-0.9.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading access-1.1.9-py3-none-any.whl (21 kB)\n",
            "Downloading esda-2.7.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading giddy-2.3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inequality-1.1.1-py3-none-any.whl (29 kB)\n",
            "Downloading libpysal-4.13.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mgwr-2.2.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pointpats-2.5.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segregation-2.5.2-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaghetti-1.7.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglm-1.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading splot-1.1.7-py3-none-any.whl (39 kB)\n",
            "Downloading spopt-0.6.1-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spreg-1.8.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tobler-0.12.1-py3-none-any.whl (28 kB)\n",
            "Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading pulp-3.1.1-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantecon-0.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.7/322.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spint\n",
            "  Building wheel for spint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31354 sha256=a00be8f3c30dc7e772b3e79aaffbf31a4b7e544689d18f8da5e03a6e7d980635\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/dc/2e/400caaa67e697355772a82b77b8c2ac7cd61633f595c477fd8\n",
            "Successfully built spint\n",
            "Installing collected packages: pygeos, pulp, mercantile, quantecon, contextily, libpysal, access, tobler, spreg, segregation, pointpats, momepy, inequality, esda, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal\n",
            "Successfully installed access-1.1.9 contextily-1.6.2 esda-2.7.0 giddy-2.3.6 inequality-1.1.1 libpysal-4.13.0 mercantile-1.2.1 mgwr-2.2.1 momepy-0.9.1 pointpats-2.5.1 pulp-3.1.1 pygeos-0.14 pysal-25.1 quantecon-0.8.0 segregation-2.5.2 spaghetti-1.7.6 spglm-1.1.0 spint-1.0.7 splot-1.1.7 spopt-0.6.1 spreg-1.8.2 tobler-0.12.1\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Collecting geoalchemy2\n",
            "  Downloading GeoAlchemy2-0.17.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geoalchemy2) (24.2)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GeoAlchemy2-0.17.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary, geoalchemy2\n",
            "Successfully installed geoalchemy2-0.17.1 psycopg2-binary-2.9.10\n"
          ]
        }
      ],
      "source": [
        "# InstalaÃ§Ã£o de bibliotecas essenciais para processamento geoespacial\n",
        "!pip install -U geopandas rasterio pyproj shapely fiona rtree pycrs mapclassify pyogrio\n",
        "!pip install -U osmnx networkx folium keplergl\n",
        "!pip install -U rasterstats xarray rioxarray netCDF4\n",
        "!pip install -U scipy scikit-learn statsmodels plotly matplotlib seaborn\n",
        "!pip install -U tqdm jupyterlab notebook ipywidgets\n",
        "!pip install -U pygeos contextily pysal momepy\n",
        "!pip install -U psycopg2-binary sqlalchemy geoalchemy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsvh2ClZqJR_",
        "outputId": "1f5cfbc1-4aec-4169-8776-d15a4271e1bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cudf\n",
            "  Downloading cudf-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cuml\n",
            "  Downloading cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cuspatial\n",
            "  Downloading cuspatial-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cupy\n",
            "  Downloading cupy-13.4.1.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy) (0.8.3)\n",
            "Building wheels for collected packages: cudf, cuml, cuspatial, cupy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cudf (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cudf\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cudf\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cuml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cuml\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cuml\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cuspatial (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cuspatial\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cuspatial\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "# InstalaÃ§Ã£o das bibliotecas RAPIDS para processamento acelerado por GPU\n",
        "# O L4 Ã© compatÃ­vel com RAPIDS, que acelera significativamente operaÃ§Ãµes geoespaciais\n",
        "!pip install -U cudf cuml cuspatial cupy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8umVbJztqJR_",
        "outputId": "3eb91324-8e71-43cc-aade-2893c5b9abc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: xlwt in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.11/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Requirement already satisfied: pyshp in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: geojson in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: topojson in /usr/local/lib/python3.11/dist-packages (1.9)\n",
            "Requirement already satisfied: geobuf in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: mapbox-vector-tile in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from topojson) (2.2.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from topojson) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from topojson) (24.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geobuf) (8.1.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from geobuf) (5.29.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geobuf) (1.17.0)\n",
            "Requirement already satisfied: pyclipper<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from mapbox-vector-tile) (1.3.0.post6)\n",
            "Requirement already satisfied: geoviews in /usr/local/lib/python3.11/dist-packages (1.14.0)\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.11/dist-packages (1.20.2)\n",
            "Requirement already satisfied: datashader in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: hvplot in /usr/local/lib/python3.11/dist-packages (0.11.2)\n",
            "Requirement already satisfied: bokeh>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from geoviews) (3.6.3)\n",
            "Requirement already satisfied: cartopy>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from geoviews) (0.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geoviews) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geoviews) (24.2)\n",
            "Requirement already satisfied: param<3.0,>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from geoviews) (2.2.0)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (from geoviews) (3.7.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from geoviews) (2.1.0)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from geoviews) (2025.1.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from holoviews) (3.1.0)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.11/dist-packages (from holoviews) (2.2.3)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews) (3.0.4)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from datashader) (1.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from datashader) (0.60.0)\n",
            "Requirement already satisfied: pyct in /usr/local/lib/python3.11/dist-packages (from datashader) (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from datashader) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from datashader) (1.15.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from datashader) (0.12.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from datashader) (2025.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel) (0.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from panel) (4.13.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.6.0->geoviews) (6.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy>=0.18.0->geoviews) (3.10.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy>=0.18.0->geoviews) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->holoviews) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->holoviews) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3->holoviews) (2025.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj->geoviews) (2025.1.31)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->datashader) (0.43.0)\n",
            "Collecting numpy (from geoviews)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->datashader) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->datashader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->datashader) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=3.6.0->geoviews) (3.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy>=0.18.0->geoviews) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3->holoviews) (1.17.0)\n",
            "Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n",
            "Collecting dask\n",
            "  Using cached dask-2025.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: distributed in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n",
            "Collecting distributed\n",
            "  Using cached distributed-2025.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement hdf5 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for hdf5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Bibliotecas especÃ­ficas para manipulaÃ§Ã£o de dados tabulares e leitura de arquivos\n",
        "!pip install -U pandas numpy openpyxl xlrd xlwt xlsxwriter\n",
        "!pip install -U pyshp geojson topojson geobuf mapbox-vector-tile\n",
        "!pip install -U geoviews holoviews datashader panel hvplot\n",
        "!pip install -U dask distributed h5py hdf5 zarr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgA0y3sBqJR_",
        "outputId": "f9115779-27af-4d4f-8be7-f6583970d265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VerificaÃ§Ã£o de configuraÃ§Ã£o bÃ¡sica concluÃ­da. Bibliotecas principais carregadas com sucesso.\n"
          ]
        }
      ],
      "source": [
        "# Verificar importaÃ§Ãµes essenciais e configuraÃ§Ãµes bÃ¡sicas\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import networkx as nx\n",
        "\n",
        "print(\"VerificaÃ§Ã£o de configuraÃ§Ã£o bÃ¡sica concluÃ­da. Bibliotecas principais carregadas com sucesso.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j162HTdJqJR_",
        "outputId": "d0c1ffff-e078-4669-bf3b-9a15da65c0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VariÃ¡veis de ambiente configuradas para otimizaÃ§Ã£o com GPU L4\n"
          ]
        }
      ],
      "source": [
        "# Configurar ambiente para trabalhar com o L4 GPU\n",
        "import os\n",
        "\n",
        "# Definir variÃ¡veis de ambiente para otimizaÃ§Ã£o de bibliotecas geoespaciais\n",
        "os.environ['USE_PYGEOS'] = '0'  # Usar GeoPandas com GEOS (mais estÃ¡vel)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Utilizar GPU 0\n",
        "\n",
        "# ConfiguraÃ§Ãµes para utilizar memÃ³ria de GPU de forma eficiente\n",
        "os.environ['RAPIDS_NO_INITIALIZE'] = '1'  # InicializaÃ§Ã£o manual do RAPIDS\n",
        "\n",
        "print(\"VariÃ¡veis de ambiente configuradas para otimizaÃ§Ã£o com GPU L4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY6a0yOqqJR_",
        "outputId": "26fc176b-9bcc-4afc-fb52-6fe88cddf733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConfiguraÃ§Ãµes de visualizaÃ§Ã£o otimizadas\n"
          ]
        }
      ],
      "source": [
        "# ConfiguraÃ§Ã£o para visualizaÃ§Ã£o interativa\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Aumentar limite de exibiÃ§Ã£o para melhor visualizaÃ§Ã£o de dados geoespaciais\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Configurar matplotlib para visualizaÃ§Ãµes de alta qualidade\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"ConfiguraÃ§Ãµes de visualizaÃ§Ã£o otimizadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE04pXRJqJR_",
        "outputId": "3a20ac36-0cea-4b88-f098-3d73cdfa8d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uso de memÃ³ria RAM:\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            52Gi       1.5Gi        38Gi        24Mi        13Gi        50Gi\n",
            "Swap:             0B          0B          0B\n",
            "\n",
            "Uso de memÃ³ria GPU:\n",
            "memory.used [MiB], memory.total [MiB]\n",
            "0 MiB, 23034 MiB\n"
          ]
        }
      ],
      "source": [
        "# FunÃ§Ã£o utilitÃ¡ria para verificar consumo de memÃ³ria\n",
        "def check_memory_usage():\n",
        "    \"\"\"Exibe o uso atual de memÃ³ria RAM e GPU.\"\"\"\n",
        "    print(\"Uso de memÃ³ria RAM:\")\n",
        "    !free -h\n",
        "\n",
        "    print(\"\\nUso de memÃ³ria GPU:\")\n",
        "    !nvidia-smi --query-gpu=memory.used,memory.total --format=csv\n",
        "\n",
        "check_memory_usage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "VhB9F3MZqJSA",
        "outputId": "86eab4e0-b654-40f5-c1e4-d9f22e807eec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teste de funcionalidade geoespacial concluÃ­do com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Testar leitura bÃ¡sica de dados geoespaciais\n",
        "try:\n",
        "    # Criar um GeoDataFrame simples para teste\n",
        "    from shapely.geometry import Point\n",
        "\n",
        "    # Criar alguns pontos de teste\n",
        "    geometry = [Point(0, 0), Point(1, 1), Point(2, 2)]\n",
        "    gdf = gpd.GeoDataFrame(geometry=geometry)\n",
        "\n",
        "    # Plotar para verificar funcionamento\n",
        "    gdf.plot()\n",
        "    plt.title(\"Teste de Plotagem Geoespacial\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Teste de funcionalidade geoespacial concluÃ­do com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao testar funcionalidade geoespacial: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiRTZwhpqJSA",
        "outputId": "9b34eb57-e09b-4649-edea-e31ce573195d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CONFIGURAÃ‡ÃƒO DO AMBIENTE CONCLUÃDA COM SUCESSO\n",
            "================================================================================\n",
            "\n",
            "Bibliotecas instaladas e configuradas:\n",
            "- Processamento geoespacial: GeoPandas, Rasterio, Shapely, Fiona\n",
            "- AnÃ¡lise de redes: NetworkX, OSMnx\n",
            "- Processamento de dados: Pandas, NumPy, SciPy, Scikit-learn\n",
            "- VisualizaÃ§Ã£o: Matplotlib, Folium, Plotly, Kepler.gl\n",
            "- AceleraÃ§Ã£o GPU: RAPIDS (cuDF, cuSpatial)\n",
            "\n",
            "PrÃ³ximos passos:\n",
            "1. Execute 1.2_Carregamento_Datasets.ipynb para carregar os dados\n",
            "2. Execute 1.3_Configuracao_Sistema_Coordenadas.ipynb para configurar os sistemas de referÃªncia\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Resumo da configuraÃ§Ã£o do ambiente\n",
        "print(\"=\"*80)\n",
        "print(\"CONFIGURAÃ‡ÃƒO DO AMBIENTE CONCLUÃDA COM SUCESSO\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nBibliotecas instaladas e configuradas:\")\n",
        "print(\"- Processamento geoespacial: GeoPandas, Rasterio, Shapely, Fiona\")\n",
        "print(\"- AnÃ¡lise de redes: NetworkX, OSMnx\")\n",
        "print(\"- Processamento de dados: Pandas, NumPy, SciPy, Scikit-learn\")\n",
        "print(\"- VisualizaÃ§Ã£o: Matplotlib, Folium, Plotly, Kepler.gl\")\n",
        "print(\"- AceleraÃ§Ã£o GPU: RAPIDS (cuDF, cuSpatial)\")\n",
        "print(\"\\nPrÃ³ximos passos:\")\n",
        "print(\"1. Execute 1.2_Carregamento_Datasets.ipynb para carregar os dados\")\n",
        "print(\"2. Execute 1.3_Configuracao_Sistema_Coordenadas.ipynb para configurar os sistemas de referÃªncia\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MblDidi8qJSA"
      },
      "source": [
        "1.2_Carregamento_Datasets.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo1Nh4nRqJSA",
        "outputId": "98855af8-6e47-4ffc-c668-d18b287222cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Carregamento de Datasets para IntegraÃ§Ã£o Geoespacial\n",
        "# Este notebook carrega os datasets GPKG necessÃ¡rios para o projeto\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "from shapely.geometry import box\n",
        "\n",
        "# Montando o Google Drive para acessar os dados\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29g8zplqJSA",
        "outputId": "5a96ecae-d1a0-4090-b8e5-b40852414205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DiretÃ³rio de dados encontrado: /content/drive/MyDrive/geoprocessamento_gnn/DATA\n"
          ]
        }
      ],
      "source": [
        "# DefiniÃ§Ã£o do diretÃ³rio onde estÃ£o os datasets\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "\n",
        "# Verificando se o diretÃ³rio existe\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(f\"O diretÃ³rio {data_dir} nÃ£o foi encontrado. Verifique o caminho.\")\n",
        "\n",
        "print(f\"DiretÃ³rio de dados encontrado: {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eONoPkfCqJSA",
        "outputId": "02ad33d1-4ede-4e4a-d88a-744d56580e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encontrados 9 arquivos GPKG:\n",
            "1. inmet_processed.gpkg\n",
            "2. setores_censitarios_enriched.gpkg\n",
            "3. hidrografia_enriched_20250412_233008.gpkg\n",
            "4. buildings_enriched_20250413_131208.gpkg\n",
            "5. railways_enriched_20250413_134853.gpkg\n",
            "6. natural_areas_enriched_20250413_144444.gpkg\n",
            "7. roads_enriched_20250412_230707.gpkg\n",
            "8. landuse_enriched_20250413_105344.gpkg\n",
            "9. rbs_enriched_20250413_153946.gpkg\n"
          ]
        }
      ],
      "source": [
        "# Listando todos os arquivos GPKG no diretÃ³rio de dados\n",
        "gpkg_files = glob.glob(os.path.join(data_dir, \"*.gpkg\"))\n",
        "print(f\"Encontrados {len(gpkg_files)} arquivos GPKG:\")\n",
        "for i, file in enumerate(gpkg_files):\n",
        "    print(f\"{i+1}. {os.path.basename(file)}\")\n",
        "\n",
        "if len(gpkg_files) == 0:\n",
        "    print(\"Nenhum arquivo GPKG encontrado. Verifique o caminho ou extensÃ£o dos arquivos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "f99TmMILB7Bx",
        "outputId": "df4330c4-facf-4878-d049-421f04561300"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "explore_gpkg() missing 1 required positional argument: 'gpkg_path'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-bed126f3c434>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using the default path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexplore_gpkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Specifying a different path if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexplore_gpkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/geoprocessamento_gnn/DATA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: explore_gpkg() missing 1 required positional argument: 'gpkg_path'"
          ]
        }
      ],
      "source": [
        "# Using the default path\n",
        "explore_gpkg()\n",
        "\n",
        "# Specifying a different path if needed\n",
        "explore_gpkg('/content/drive/MyDrive/geoprocessamento_gnn/DATA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "goGxfEc5qJSA",
        "outputId": "9314d526-0da8-498d-8009-6ef8465ef2f0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-55-3114e8a9e133>, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-3114e8a9e133>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    layers = fiona.listlayers(gpkg_path)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "#def explore_gpkg(gpkg_path='/content/drive/MyDrive/geoprocessamento_gnn/DATA'):\n",
        "    # Listar todas as camadas no arquivo\n",
        "    layers = fiona.listlayers(gpkg_path)\n",
        "\n",
        "    # Coletar informaÃ§Ãµes sobre cada camada\n",
        "    layer_info = []\n",
        "    for layer in layers:\n",
        "        try:\n",
        "            # Abrir a camada para obter informaÃ§Ãµes\n",
        "            with fiona.open(gpkg_path, layer=layer) as src:\n",
        "                # Obter a contagem de feiÃ§Ãµes\n",
        "                count = len(src)\n",
        "                # Obter o tipo de geometria\n",
        "                if count > 0:\n",
        "                    geometry_type = src.schema['geometry']\n",
        "                else:\n",
        "                    geometry_type = \"Desconhecido\"\n",
        "                # Obter o CRS\n",
        "                crs = src.crs\n",
        "                # Obter os campos de atributos\n",
        "                fields = list(src.schema['properties'].keys())\n",
        "\n",
        "                layer_info.append({\n",
        "                    'Layer': layer,\n",
        "                    'Feature Count': count,\n",
        "                    'Geometry Type': geometry_type,\n",
        "                    'CRS': crs,\n",
        "                    'Fields': fields[:5] + ['...'] if len(fields) > 5 else fields\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar camada {layer}: {e}\")\n",
        "            layer_info.append({\n",
        "                'Layer': layer,\n",
        "                'Error': str(e)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(layer_info)\n",
        "\n",
        "# Importamos fiona aqui para listar as camadas\n",
        "import fiona\n",
        "\n",
        "# Explorando cada arquivo GPKG\n",
        "for gpkg_file in gpkg_files:\n",
        "    file_name = os.path.basename(gpkg_file)\n",
        "    print(f\"\\n{'='*80}\\nExplorando arquivo: {file_name}\\n{'='*80}\")\n",
        "\n",
        "    layers_info = explore_gpkg(gpkg_file)\n",
        "    display(layers_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651,
          "referenced_widgets": [
            "8b78089f74154151a2b7589978d14963",
            "a73455c14a1244888389dfa9c0b8dfe1",
            "a113fff2f6114caa9e8221ffddaeb12c",
            "17188148bd854eb89e0f61acf242d7bb",
            "8e6e321e23ab4d5f8028f6e2a9d66ca2",
            "8b066468064f4cd4a668528cfaf1fd4f",
            "fc8efe577f5a4ce4b919037badd406cf",
            "cc833ad3e9e54ec6adbce3033fd839e7",
            "f4a7c0f07888431e97d8c6c275c5e662",
            "cfa2fb3c5983469bb1fbf54ae9b033b9",
            "d60ee9a724284044a90fff3b1f158d41",
            "655cf9cd39d64c46b46148f4a8bf7fd7",
            "f9952b233b734b459546a4cc82c79440",
            "2c76f7f484374f7683e5af25ccf4eb07",
            "54234ad943de4155987bb7994692e1b6",
            "fe0a3275e4b3400590d860bbb3f99f33",
            "9f2269378cc04fc0b865c11a738f1cc8",
            "ad2422bb71b84313b81380767388d2e3",
            "4093e2ad6186493ba9290c878eab1758",
            "19db4ff634f54c39bb1ce3b1155cbf8a",
            "522231ed2fe14bfea5356b522cf08375",
            "1b2254247fbf4fad903828370d9f2fca"
          ]
        },
        "id": "zBbrUayOqJSA",
        "outputId": "c2264801-ceb5-467f-e531-bda2d38173f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b78089f74154151a2b7589978d14963",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Carregando arquivos GPKG:   0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "655cf9cd39d64c46b46148f4a8bf7fd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Camadas em inmet_processed.gpkg:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregado: inmet_processed.gpkg - inmet_processed - 8784 registros\n"
          ]
        },
        {
          "ename": "DriverError",
          "evalue": "Failed to open dataset (flags=68): /content/drive/MyDrive/geoprocessamento_gnn/DATA/setores_censitarios_enriched.gpkg",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.StackChecker.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: `/content/drive/MyDrive/geoprocessamento_gnn/DATA/setores_censitarios_enriched.gpkg' not recognized as being in a supported file format.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-23a663360ac7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Carregando todos os datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpkg_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Salvando em uma variÃ¡vel global para acesso posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-23a663360ac7>\u001b[0m in \u001b[0;36mload_all_datasets\u001b[0;34m(gpkg_files)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Listar camadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Camadas em {file_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mlistlayers\u001b[0;34m(fp, opener, vfs, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mpobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_listlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_vsi_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext._listlayers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDriverError\u001b[0m: Failed to open dataset (flags=68): /content/drive/MyDrive/geoprocessamento_gnn/DATA/setores_censitarios_enriched.gpkg"
          ]
        }
      ],
      "source": [
        "# FunÃ§Ã£o para carregar e armazenar todos os datasets em um dicionÃ¡rio\n",
        "def load_all_datasets(gpkg_files):\n",
        "    \"\"\"\n",
        "    Carrega todos os arquivos GPKG e suas camadas em um dicionÃ¡rio.\n",
        "\n",
        "    Args:\n",
        "        gpkg_files: Lista de caminhos para arquivos GPKG\n",
        "\n",
        "    Returns:\n",
        "        Um dicionÃ¡rio de GeoDataFrames organizados por nome de arquivo e camada\n",
        "    \"\"\"\n",
        "    datasets = {}\n",
        "\n",
        "    for gpkg_file in tqdm(gpkg_files, desc=\"Carregando arquivos GPKG\"):\n",
        "        file_name = os.path.basename(gpkg_file)\n",
        "        datasets[file_name] = {}\n",
        "\n",
        "        # Listar camadas\n",
        "        layers = fiona.listlayers(gpkg_file)\n",
        "\n",
        "        for layer in tqdm(layers, desc=f\"Camadas em {file_name}\", leave=False):\n",
        "            try:\n",
        "                # Carregar o GeoDataFrame\n",
        "                gdf = gpd.read_file(gpkg_file, layer=layer)\n",
        "\n",
        "                # Armazenar no dicionÃ¡rio\n",
        "                datasets[file_name][layer] = gdf\n",
        "\n",
        "                print(f\"Carregado: {file_name} - {layer} - {len(gdf)} registros\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao carregar camada {layer} de {file_name}: {e}\")\n",
        "\n",
        "    return datasets\n",
        "\n",
        "# Carregando todos os datasets\n",
        "datasets = load_all_datasets(gpkg_files)\n",
        "\n",
        "# Salvando em uma variÃ¡vel global para acesso posterior\n",
        "import builtins\n",
        "builtins.datasets = datasets\n",
        "\n",
        "print(\"\\nCarregamento completo. Todos os datasets estÃ£o armazenados na variÃ¡vel global 'datasets'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa7_zA81z8_Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LHmyVfoz8_R"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn_DxGVhz8_R"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twh9YC7bqJSA"
      },
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o para visualizar a extensÃ£o geogrÃ¡fica de todos os datasets em um mapa\n",
        "def plot_dataset_extents(datasets):\n",
        "    \"\"\"\n",
        "    Visualiza a extensÃ£o geogrÃ¡fica de todos os datasets carregados.\n",
        "\n",
        "    Args:\n",
        "        datasets: DicionÃ¡rio de datasets carregados\n",
        "    \"\"\"\n",
        "    # Criar um grÃ¡fico vazio\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
        "\n",
        "    # Cores para diferentes datasets\n",
        "    colors = plt.cm.tab20.colors\n",
        "    color_idx = 0\n",
        "\n",
        "    # Legenda\n",
        "    legend_items = []\n",
        "\n",
        "    # Iterar atravÃ©s dos datasets\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            # Verificar se o GeoDataFrame tem geometria\n",
        "            if gdf.geometry.is_empty.all():\n",
        "                print(f\"Geometria vazia em {file_name} - {layer_name}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Obter a extensÃ£o do dataset\n",
        "                minx, miny, maxx, maxy = gdf.total_bounds\n",
        "                extent_box = box(minx, miny, maxx, maxy)\n",
        "\n",
        "                # Criar um GeoDataFrame com a extensÃ£o\n",
        "                extent_gdf = gpd.GeoDataFrame(geometry=[extent_box], crs=gdf.crs)\n",
        "\n",
        "                # Plotar no mapa\n",
        "                color = colors[color_idx % len(colors)]\n",
        "                extent_gdf.boundary.plot(ax=ax, color=color, linewidth=2,\n",
        "                                        label=f\"{file_name} - {layer_name}\")\n",
        "\n",
        "                # Adicionar Ã  legenda\n",
        "                legend_items.append(f\"{file_name} - {layer_name}\")\n",
        "\n",
        "                # Incrementar Ã­ndice de cor\n",
        "                color_idx += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao plotar extensÃ£o de {file_name} - {layer_name}: {e}\")\n",
        "\n",
        "    # Configurar o grÃ¡fico\n",
        "    ax.set_title(\"ExtensÃ£o geogrÃ¡fica dos datasets carregados\", fontsize=16)\n",
        "    ax.legend(legend_items, fontsize=10, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizando a extensÃ£o dos datasets\n",
        "plot_dataset_extents(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTtnv5LjqJSA"
      },
      "outputs": [],
      "source": [
        "# Salvando o estado dos datasets para uso no prÃ³ximo notebook\n",
        "import pickle\n",
        "\n",
        "# Criando pasta de estado se nÃ£o existir\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "os.makedirs(state_dir, exist_ok=True)\n",
        "\n",
        "# Caminho para o arquivo de estado\n",
        "state_file = os.path.join(state_dir, 'datasets_state.pkl')\n",
        "\n",
        "# Salvando o dicionÃ¡rio de datasets\n",
        "with open(state_file, 'wb') as f:\n",
        "    pickle.dump(datasets, f)\n",
        "\n",
        "print(f\"Estado dos datasets salvo em: {state_file}\")\n",
        "print(\"Os datasets estÃ£o prontos para o prÃ³ximo notebook de configuraÃ§Ã£o do sistema de coordenadas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5G8mL8fqJSB"
      },
      "outputs": [],
      "source": [
        "# Resumo do carregamento de dados\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMO DE CARREGAMENTO DE DADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Contabilizar totais\n",
        "total_layers = 0\n",
        "total_features = 0\n",
        "\n",
        "# Exibir estatÃ­sticas por arquivo\n",
        "for file_name, layers in datasets.items():\n",
        "    layer_count = len(layers)\n",
        "    total_layers += layer_count\n",
        "\n",
        "    feature_counts = [len(gdf) for gdf in layers.values()]\n",
        "    total_file_features = sum(feature_counts)\n",
        "    total_features += total_file_features\n",
        "\n",
        "    print(f\"\\nArquivo: {file_name}\")\n",
        "    print(f\"  NÃºmero de camadas: {layer_count}\")\n",
        "    print(f\"  Total de feiÃ§Ãµes: {total_file_features:,}\")\n",
        "\n",
        "    # Listar cada camada com contagem\n",
        "    for layer_name, gdf in layers.items():\n",
        "        print(f\"    - {layer_name}: {len(gdf):,} feiÃ§Ãµes\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"TOTAL GERAL: {total_layers} camadas, {total_features:,} feiÃ§Ãµes\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thiGS2DRqJSB"
      },
      "source": [
        "1.3_Configuracao_Sistema_Coordenadas.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J00J9ODqJSB"
      },
      "outputs": [],
      "source": [
        "# ConfiguraÃ§Ã£o do Sistema de Coordenadas para IntegraÃ§Ã£o Geoespacial\n",
        "# Este notebook padroniza todos os datasets para o sistema SIRGAS 2000 23S (EPSG:31983)\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "\n",
        "# Montando o Google Drive para acessar os dados\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmQ4vsvtqJSB"
      },
      "outputs": [],
      "source": [
        "# DiretÃ³rio de dados\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "state_file = os.path.join(state_dir, 'datasets_state.pkl')\n",
        "\n",
        "# Verificando se o arquivo de estado existe\n",
        "if not os.path.exists(state_file):\n",
        "    raise FileNotFoundError(f\"Arquivo de estado nÃ£o encontrado: {state_file}\")\n",
        "\n",
        "# Carregando o estado dos datasets do notebook anterior\n",
        "with open(state_file, 'rb') as f:\n",
        "    datasets = pickle.load(f)\n",
        "\n",
        "# Definindo globalmente para uso posterior\n",
        "import builtins\n",
        "builtins.datasets = datasets\n",
        "\n",
        "print(f\"Datasets carregados com sucesso do arquivo: {state_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps2Xyn0IqJSB"
      },
      "outputs": [],
      "source": [
        "# DefiniÃ§Ã£o do sistema de coordenadas alvo: SIRGAS 2000 / UTM zone 23S (EPSG:31983)\n",
        "TARGET_CRS = \"EPSG:31983\"\n",
        "\n",
        "# InformaÃ§Ãµes sobre o sistema de coordenadas alvo\n",
        "sirgas_info = {\n",
        "    'EPSG': 31983,\n",
        "    'Nome': 'SIRGAS 2000 / UTM zone 23S',\n",
        "    'ProjeÃ§Ã£o': 'Transverse Mercator',\n",
        "    'Datum': 'SIRGAS 2000',\n",
        "    'Unidade': 'metros',\n",
        "    'Zona UTM': '23S',\n",
        "    'Meridiano Central': '-45',\n",
        "    'Latitude de Origem': '0',\n",
        "    'Falso Leste': '500000',\n",
        "    'Falso Norte': '10000000',\n",
        "    'Fator de Escala': '0.9996'\n",
        "}\n",
        "\n",
        "print(\"Sistema de coordenadas alvo:\")\n",
        "for key, value in sirgas_info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\nEste sistema de coordenadas Ã© ideal para o nosso projeto porque:\")\n",
        "print(\"1. MantÃ©m a precisÃ£o das mediÃ§Ãµes em metros para a Ã¡rea de estudo\")\n",
        "print(\"2. Ã‰ o sistema padrÃ£o para projetos geoespaciais no Brasil, especialmente na zona 23S\")\n",
        "print(\"3. Permite calcular Ã¡reas, distÃ¢ncias e anÃ¡lises espaciais com precisÃ£o\")\n",
        "print(\"4. Minimiza distorÃ§Ãµes para a regiÃ£o de estudo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfjZ4LlSqJSB"
      },
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o para verificar e tabular os sistemas de coordenadas atuais de todos os datasets\n",
        "def check_crs(datasets):\n",
        "    \"\"\"\n",
        "    Verifica os sistemas de coordenadas de todos os datasets.\n",
        "\n",
        "    Args:\n",
        "        datasets: DicionÃ¡rio de datasets carregados\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com informaÃ§Ãµes sobre os sistemas de coordenadas\n",
        "    \"\"\"\n",
        "    crs_info = []\n",
        "\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            try:\n",
        "                # Obter informaÃ§Ãµes do CRS\n",
        "                if gdf.crs is None:\n",
        "                    crs_code = None\n",
        "                    crs_name = \"NÃ£o definido\"\n",
        "                    is_projected = False\n",
        "                    units = \"Desconhecido\"\n",
        "                else:\n",
        "                    crs_code = gdf.crs.to_epsg()\n",
        "                    crs_name = gdf.crs.name if hasattr(gdf.crs, 'name') else str(gdf.crs)\n",
        "                    is_projected = gdf.crs.is_projected\n",
        "                    units = gdf.crs.axis_info[0].unit_name if hasattr(gdf.crs, 'axis_info') else \"Desconhecido\"\n",
        "\n",
        "                needs_transformation = crs_code != 31983 and crs_code is not None\n",
        "\n",
        "                crs_info.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG': crs_code,\n",
        "                    'CRS Nome': crs_name,\n",
        "                    'Projetado': is_projected,\n",
        "                    'Unidades': units,\n",
        "                    'Requer TransformaÃ§Ã£o': needs_transformation\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao verificar CRS de {file_name} - {layer_name}: {e}\")\n",
        "                crs_info.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG': None,\n",
        "                    'CRS Nome': f\"ERRO: {str(e)}\",\n",
        "                    'Projetado': None,\n",
        "                    'Unidades': None,\n",
        "                    'Requer TransformaÃ§Ã£o': None\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(crs_info)\n",
        "\n",
        "# Analisando os sistemas de coordenadas atuais\n",
        "crs_status = check_crs(datasets)\n",
        "display(crs_status)\n",
        "\n",
        "# Contabilizando quantos datasets precisam de transformaÃ§Ã£o\n",
        "requires_transformation = crs_status['Requer TransformaÃ§Ã£o'].sum()\n",
        "total_layers = len(crs_status)\n",
        "\n",
        "print(f\"\\nStatus de transformaÃ§Ã£o: {requires_transformation} de {total_layers} camadas precisam ser transformadas para SIRGAS 2000 / UTM zone 23S (EPSG:31983)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6pPzMw3qJSB"
      },
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o para transformar datasets para o CRS alvo\n",
        "def transform_datasets(datasets, target_crs=TARGET_CRS):\n",
        "    \"\"\"\n",
        "    Transforma todos os datasets para o sistema de coordenadas alvo.\n",
        "\n",
        "    Args:\n",
        "        datasets: DicionÃ¡rio de datasets carregados\n",
        "        target_crs: Sistema de coordenadas alvo\n",
        "\n",
        "    Returns:\n",
        "        DicionÃ¡rio de datasets transformados\n",
        "    \"\"\"\n",
        "    transformed_datasets = {}\n",
        "    transformation_report = []\n",
        "\n",
        "    # Para cada arquivo\n",
        "    for file_name, layers in tqdm(datasets.items(), desc=\"Transformando arquivos\"):\n",
        "        transformed_datasets[file_name] = {}\n",
        "\n",
        "        # Para cada camada\n",
        "        for layer_name, gdf in tqdm(layers.items(), desc=f\"Camadas em {file_name}\", leave=False):\n",
        "            try:\n",
        "                # Verificar se o CRS atual Ã© None\n",
        "                if gdf.crs is None:\n",
        "                    print(f\"AVISO: {file_name} - {layer_name} nÃ£o possui CRS definido. Atribuindo o CRS alvo sem transformaÃ§Ã£o.\")\n",
        "                    gdf.crs = target_crs\n",
        "                    transformed_gdf = gdf\n",
        "                    status = \"AtribuÃ­do CRS (sem transformaÃ§Ã£o)\"\n",
        "\n",
        "                # Verificar se jÃ¡ estÃ¡ no CRS alvo\n",
        "                elif gdf.crs.to_epsg() == 31983:\n",
        "                    print(f\"{file_name} - {layer_name} jÃ¡ estÃ¡ no CRS alvo. Nenhuma transformaÃ§Ã£o necessÃ¡ria.\")\n",
        "                    transformed_gdf = gdf\n",
        "                    status = \"JÃ¡ no CRS alvo\"\n",
        "\n",
        "                # Realizar a transformaÃ§Ã£o\n",
        "                else:\n",
        "                    # Registrar informaÃ§Ãµes antes da transformaÃ§Ã£o\n",
        "                    if 'geometry' in gdf.columns and len(gdf) > 0 and not gdf.geometry.is_empty.all():\n",
        "                        pre_bounds = gdf.total_bounds\n",
        "                    else:\n",
        "                        pre_bounds = None\n",
        "\n",
        "                    # Executar a transformaÃ§Ã£o\n",
        "                    with warnings.catch_warnings():\n",
        "                        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "                        transformed_gdf = gdf.to_crs(target_crs)\n",
        "\n",
        "                    # Registrar informaÃ§Ãµes apÃ³s a transformaÃ§Ã£o\n",
        "                    if pre_bounds is not None and len(transformed_gdf) > 0 and not transformed_gdf.geometry.is_empty.all():\n",
        "                        post_bounds = transformed_gdf.total_bounds\n",
        "                        status = \"Transformado com sucesso\"\n",
        "                    else:\n",
        "                        post_bounds = None\n",
        "                        status = \"Transformado (sem geometria para validar)\"\n",
        "\n",
        "                # Armazenar o GeoDataFrame transformado\n",
        "                transformed_datasets[file_name][layer_name] = transformed_gdf\n",
        "\n",
        "                # Registrar no relatÃ³rio\n",
        "                transformation_report.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'CRS Original': str(gdf.crs),\n",
        "                    'CRS Final': str(transformed_gdf.crs),\n",
        "                    'Status': status,\n",
        "                    'Registros': len(gdf)\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ERRO ao transformar {file_name} - {layer_name}: {e}\")\n",
        "                # Manter o dataset original em caso de erro\n",
        "                transformed_datasets[file_name][layer_name] = gdf\n",
        "                transformation_report.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'CRS Original': str(gdf.crs) if hasattr(gdf, 'crs') else \"Desconhecido\",\n",
        "                    'CRS Final': \"ERRO\",\n",
        "                    'Status': f\"Erro: {str(e)}\",\n",
        "                    'Registros': len(gdf) if hasattr(gdf, 'len') else \"Desconhecido\"\n",
        "                })\n",
        "\n",
        "    return transformed_datasets, pd.DataFrame(transformation_report)\n",
        "\n",
        "# Executando a transformaÃ§Ã£o\n",
        "transformed_datasets, transformation_report = transform_datasets(datasets)\n",
        "\n",
        "# Atualizando a variÃ¡vel global com os datasets transformados\n",
        "builtins.datasets = transformed_datasets\n",
        "\n",
        "# Exibindo o relatÃ³rio de transformaÃ§Ã£o\n",
        "display(transformation_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj10Z5y3qJSB"
      },
      "outputs": [],
      "source": [
        "# ValidaÃ§Ã£o final: verificando se todos os datasets estÃ£o no sistema de coordenadas correto\n",
        "def validate_transformations(datasets, target_crs=TARGET_CRS):\n",
        "    \"\"\"\n",
        "    Verifica se todos os datasets estÃ£o no sistema de coordenadas alvo.\n",
        "\n",
        "    Args:\n",
        "        datasets: DicionÃ¡rio de datasets transformados\n",
        "        target_crs: Sistema de coordenadas alvo\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com resultados da validaÃ§Ã£o\n",
        "    \"\"\"\n",
        "    validation_results = []\n",
        "    target_epsg = 31983  # EPSG para SIRGAS 2000 / UTM zone 23S\n",
        "\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            try:\n",
        "                current_epsg = gdf.crs.to_epsg()\n",
        "                is_valid = current_epsg == target_epsg\n",
        "\n",
        "                validation_results.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG Atual': current_epsg,\n",
        "                    'EPSG Alvo': target_epsg,\n",
        "                    'ValidaÃ§Ã£o': \"Sucesso\" if is_valid else \"Falha\",\n",
        "                    'CRS': str(gdf.crs)\n",
        "                })\n",
        "            except Exception as e:\n",
        "                validation_results.append({\n",
        "                    'Arquivo': file_name,\n",
        "                    'Camada': layer_name,\n",
        "                    'EPSG Atual': None,\n",
        "                    'EPSG Alvo': target_epsg,\n",
        "                    'ValidaÃ§Ã£o': f\"Erro: {str(e)}\",\n",
        "                    'CRS': str(gdf.crs) if hasattr(gdf, 'crs') else \"Desconhecido\"\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(validation_results)\n",
        "\n",
        "# Validando todas as transformaÃ§Ãµes\n",
        "validation_results = validate_transformations(transformed_datasets)\n",
        "display(validation_results)\n",
        "\n",
        "# Verificando sucesso geral\n",
        "success_count = (validation_results['ValidaÃ§Ã£o'] == \"Sucesso\").sum()\n",
        "total_count = len(validation_results)\n",
        "success_rate = success_count / total_count * 100\n",
        "\n",
        "print(f\"\\nValidaÃ§Ã£o concluÃ­da: {success_count} de {total_count} camadas ({success_rate:.2f}%) estÃ£o no sistema de coordenadas SIRGAS 2000 / UTM zone 23S (EPSG:31983)\")\n",
        "\n",
        "if success_count < total_count:\n",
        "    print(\"\\nATENÃ‡ÃƒO: Algumas camadas nÃ£o foram transformadas corretamente. Verifique o relatÃ³rio acima.\")\n",
        "else:\n",
        "    print(\"\\nTodos os datasets foram transformados com sucesso para o sistema de coordenadas alvo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNnq0rCBqJSB"
      },
      "outputs": [],
      "source": [
        "# Salvando os datasets transformados\n",
        "import pickle\n",
        "\n",
        "# Criando pasta de estado se nÃ£o existir\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "os.makedirs(state_dir, exist_ok=True)\n",
        "\n",
        "# Caminho para o arquivo de estado\n",
        "transformed_state_file = os.path.join(state_dir, 'datasets_transformed_state.pkl')\n",
        "\n",
        "# Salvando o dicionÃ¡rio de datasets transformados\n",
        "with open(transformed_state_file, 'wb') as f:\n",
        "    pickle.dump(transformed_datasets, f)\n",
        "\n",
        "print(f\"Estado dos datasets transformados salvo em: {transformed_state_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVcgBqHpqJSC"
      },
      "outputs": [],
      "source": [
        "# Visualizando algumas feiÃ§Ãµes para verificar visualmente a transformaÃ§Ã£o\n",
        "def plot_sample_geometries(datasets):\n",
        "    \"\"\"\n",
        "    Plota amostras de geometrias para verificaÃ§Ã£o visual.\n",
        "\n",
        "    Args:\n",
        "        datasets: DicionÃ¡rio de datasets transformados\n",
        "    \"\"\"\n",
        "    # Criar um layout de 2x2 para visualizaÃ§Ã£o\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Contador para controlar quantas camadas plotar\n",
        "    plot_count = 0\n",
        "    max_plots = 4\n",
        "\n",
        "    # Cores para diferentes datasets\n",
        "    colors = plt.cm.tab10.colors\n",
        "\n",
        "    # Para cada arquivo e camada\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            if plot_count >= max_plots:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                # Verificar se hÃ¡ geometrias para plotar\n",
        "                if 'geometry' not in gdf.columns or len(gdf) == 0 or gdf.geometry.is_empty.all():\n",
        "                    continue\n",
        "\n",
        "                # Plotar apenas uma amostra (mÃ¡ximo 100 feiÃ§Ãµes)\n",
        "                sample_size = min(100, len(gdf))\n",
        "                ax = axes[plot_count]\n",
        "\n",
        "                # Plotar a amostra\n",
        "                gdf.sample(sample_size).plot(\n",
        "                    ax=ax,\n",
        "                    color=colors[plot_count % len(colors)],\n",
        "                    alpha=0.7,\n",
        "                    edgecolor='black',\n",
        "                    linewidth=0.5\n",
        "                )\n",
        "\n",
        "                # Configurar o tÃ­tulo e rÃ³tulos\n",
        "                ax.set_title(f\"{file_name}\\n{layer_name}\", fontsize=12)\n",
        "                ax.set_xlabel(\"Coordenada X (metros)\")\n",
        "                ax.set_ylabel(\"Coordenada Y (metros)\")\n",
        "                ax.grid(True)\n",
        "\n",
        "                # Adicionar informaÃ§Ãµes de CRS\n",
        "                ax.text(0.5, -0.1, f\"CRS: {gdf.crs.name if hasattr(gdf.crs, 'name') else str(gdf.crs)[:50]}...\",\n",
        "                       horizontalalignment='center', verticalalignment='center',\n",
        "                       transform=ax.transAxes, fontsize=10)\n",
        "\n",
        "                plot_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao plotar {file_name} - {layer_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "    if plot_count == 0:\n",
        "        print(\"Nenhuma geometria disponÃ­vel para visualizaÃ§Ã£o.\")\n",
        "        plt.close(fig)\n",
        "        return\n",
        "\n",
        "    # Ocultar eixos nÃ£o utilizados\n",
        "    for i in range(plot_count, max_plots):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizando amostras das geometrias transformadas\n",
        "plot_sample_geometries(transformed_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3kdKmxuqJSC"
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusÃ£o\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA CONFIGURAÃ‡ÃƒO DE SISTEMA DE COORDENADAS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSistema de coordenadas alvo: SIRGAS 2000 / UTM zone 23S (EPSG:31983)\")\n",
        "print(f\"Total de arquivos processados: {len(transformed_datasets)}\")\n",
        "print(f\"Total de camadas processadas: {total_count}\")\n",
        "print(f\"Camadas transformadas com sucesso: {success_count} ({success_rate:.2f}%)\")\n",
        "\n",
        "print(\"\\nBenefÃ­cios da padronizaÃ§Ã£o:\")\n",
        "print(\"1. Todas as anÃ¡lises espaciais agora usarÃ£o o mesmo sistema de referÃªncia\")\n",
        "print(\"2. CÃ¡lculos de Ã¡rea, distÃ¢ncia e proximidade serÃ£o precisos e consistentes\")\n",
        "print(\"3. VisualizaÃ§Ãµes de mapas estarÃ£o corretamente alinhadas\")\n",
        "print(\"4. OperaÃ§Ãµes de sobreposiÃ§Ã£o espacial funcionarÃ£o corretamente\")\n",
        "\n",
        "print(\"\\nPrÃ³ximos passos:\")\n",
        "print(\"1. Prosseguir para a integraÃ§Ã£o de EdifÃ­cios e Uso do Solo\")\n",
        "print(\"2. Criar anÃ¡lises demogrÃ¡ficas usando os datasets transformados\")\n",
        "print(\"3. Realizar as operaÃ§Ãµes hidrogrÃ¡ficas com os dados padronizados\")\n",
        "\n",
        "print(\"\\nOs datasets transformados estÃ£o disponÃ­veis na variÃ¡vel global 'datasets'\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdfoWU8mwlc1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a75fdbe7",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "2_Integracao_Edificios_UsoSolo/\n",
        "â”‚   â”œâ”€â”€ 2.1_Sobreposicao_Espacial.ipynb\n",
        "â”‚   â”œâ”€â”€ 2.2_Categorizacao_Funcional_Edificios.ipynb\n",
        "â”‚   â””â”€â”€ 2.3_Analise_Conformidade_Uso.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74f307b4"
      },
      "source": [
        "2.1_Sobreposicao_Espacial.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b75065d",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# SobreposiÃ§Ã£o Espacial: EdifÃ­cios x Uso do Solo\n",
        "# Este notebook realiza a sobreposiÃ§Ã£o espacial entre as camadas de edifÃ­cios e uso do solo\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import contextily as cx\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "\n",
        "# Ignorar avisos especÃ­ficos para operaÃ§Ãµes espaciais\n",
        "warnings.filterwarnings('ignore', category=UserWarning, message='.*CRS mismatch.*')\n",
        "\n",
        "# Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# DefiniÃ§Ã£o dos diretÃ³rios\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "state_dir = os.path.join(data_dir, 'state')\n",
        "state_file = os.path.join(state_dir, 'datasets_transformed_state.pkl')\n",
        "\n",
        "# Carregando os datasets transformados\n",
        "with open(state_file, 'rb') as f:\n",
        "    datasets = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95169ed6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Extraindo as camadas de edifÃ­cios e uso do solo dos datasets carregados\n",
        "def extract_layers(datasets, target_names):\n",
        "    \"\"\"\n",
        "    Extrai camadas especÃ­ficas do dicionÃ¡rio de datasets.\n",
        "\n",
        "    Args:\n",
        "        datasets: DicionÃ¡rio de datasets carregados\n",
        "        target_names: Lista de nomes de camadas a serem buscados (parcial)\n",
        "\n",
        "    Returns:\n",
        "        DicionÃ¡rio com as camadas encontradas\n",
        "    \"\"\"\n",
        "    extracted = {}\n",
        "\n",
        "    for file_name, layers in datasets.items():\n",
        "        for layer_name, gdf in layers.items():\n",
        "            # Verificar se o nome da camada ou arquivo contÃ©m algum dos alvos\n",
        "            for target in target_names:\n",
        "                if target.lower() in file_name.lower() or target.lower() in layer_name.lower():\n",
        "                    key = f\"{file_name}:{layer_name}\"\n",
        "                    extracted[key] = gdf\n",
        "                    print(f\"Encontrada camada: {key} ({len(gdf)} feiÃ§Ãµes)\")\n",
        "                    break\n",
        "\n",
        "    return extracted\n",
        "\n",
        "# Extraindo as camadas relevantes\n",
        "building_keys = ['building', 'edificio', 'edif']\n",
        "landuse_keys = ['land', 'uso', 'landuse']\n",
        "\n",
        "building_layers = extract_layers(datasets, building_keys)\n",
        "landuse_layers = extract_layers(datasets, landuse_keys)\n",
        "\n",
        "# Verificando se encontramos as camadas necessÃ¡rias\n",
        "if not building_layers:\n",
        "    raise ValueError(\"Nenhuma camada de edifÃ­cios encontrada. Verifique os nomes das camadas ou arquivos.\")\n",
        "\n",
        "if not landuse_layers:\n",
        "    raise ValueError(\"Nenhuma camada de uso do solo encontrada. Verifique os nomes das camadas ou arquivos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19851bb",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Selecionar as camadas especÃ­ficas para trabalhar\n",
        "# Em um ambiente real, vocÃª pode querer pedir ao usuÃ¡rio para selecionar\n",
        "# Neste caso, vamos pegar a primeira de cada tipo\n",
        "\n",
        "# FunÃ§Ã£o para mostrar informaÃ§Ãµes detalhadas sobre as camadas\n",
        "def show_layer_details(layers_dict):\n",
        "    \"\"\"\n",
        "    Exibe informaÃ§Ãµes detalhadas sobre as camadas para ajudar na seleÃ§Ã£o.\n",
        "\n",
        "    Args:\n",
        "        layers_dict: DicionÃ¡rio contendo as camadas encontradas\n",
        "    \"\"\"\n",
        "    details = []\n",
        "\n",
        "    for key, gdf in layers_dict.items():\n",
        "        # Colunas de interesse especÃ­ficas para cada tipo\n",
        "        if 'building' in key.lower():\n",
        "            special_cols = ['building', 'building_class', 'type', 'amenity', 'landuse']\n",
        "        else:  # uso do solo\n",
        "            special_cols = ['landuse', 'land_category', 'type', 'natural']\n",
        "\n",
        "        # Buscar valores Ãºnicos nas colunas de interesse\n",
        "        sample_values = {}\n",
        "        for col in special_cols:\n",
        "            if col in gdf.columns:\n",
        "                unique_vals = gdf[col].dropna().unique()\n",
        "                sample_values[col] = unique_vals[:5] if len(unique_vals) > 5 else unique_vals\n",
        "\n",
        "        # Adicionar Ã  lista de detalhes\n",
        "        details.append({\n",
        "            'Camada': key,\n",
        "            'FeiÃ§Ãµes': len(gdf),\n",
        "            'Colunas': len(gdf.columns),\n",
        "            'Geometria': gdf.geometry.geom_type.unique(),\n",
        "            'CRS': gdf.crs,\n",
        "            'Atributos Importantes': sample_values\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(details)\n",
        "\n",
        "# Exibir detalhes para ajudar na seleÃ§Ã£o\n",
        "print(\"\\nDetalhes das camadas de edifÃ­cios:\")\n",
        "display(show_layer_details(building_layers))\n",
        "\n",
        "print(\"\\nDetalhes das camadas de uso do solo:\")\n",
        "display(show_layer_details(landuse_layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0995dc59",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Selecionar a primeira camada de cada tipo para este exemplo\n",
        "# Em um ambiente real, vocÃª pode substituir isso por uma interface de seleÃ§Ã£o\n",
        "building_key = list(building_layers.keys())[0]\n",
        "landuse_key = list(landuse_layers.keys())[0]\n",
        "\n",
        "buildings_gdf = building_layers[building_key]\n",
        "landuse_gdf = landuse_layers[landuse_key]\n",
        "\n",
        "print(f\"Camada de edifÃ­cios selecionada: {building_key}\")\n",
        "print(f\"Camada de uso do solo selecionada: {landuse_key}\")\n",
        "\n",
        "# Exibindo informaÃ§Ãµes bÃ¡sicas de cada camada\n",
        "print(\"\\nInformaÃ§Ãµes da camada de edifÃ­cios:\")\n",
        "print(f\"- NÃºmero de feiÃ§Ãµes: {len(buildings_gdf)}\")\n",
        "print(f\"- Sistema de coordenadas: {buildings_gdf.crs}\")\n",
        "print(f\"- Colunas: {buildings_gdf.columns.tolist()}\")\n",
        "\n",
        "print(\"\\nInformaÃ§Ãµes da camada de uso do solo:\")\n",
        "print(f\"- NÃºmero de feiÃ§Ãµes: {len(landuse_gdf)}\")\n",
        "print(f\"- Sistema de coordenadas: {landuse_gdf.crs}\")\n",
        "print(f\"- Colunas: {landuse_gdf.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60b2790f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar os dados para verificar a sobreposiÃ§Ã£o\n",
        "def plot_overlap(buildings, landuse, sample_size=1000, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Visualiza a sobreposiÃ§Ã£o entre edifÃ­cios e uso do solo.\n",
        "\n",
        "    Args:\n",
        "        buildings: GeoDataFrame com os edifÃ­cios\n",
        "        landuse: GeoDataFrame com o uso do solo\n",
        "        sample_size: NÃºmero de edifÃ­cios a mostrar (para nÃ£o sobrecarregar a visualizaÃ§Ã£o)\n",
        "        figsize: Tamanho da figura\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Plotar uso do solo com transparÃªncia\n",
        "    if 'land_category' in landuse.columns:\n",
        "        # Usar categorias de uso do solo se disponÃ­veis\n",
        "        landuse.plot(ax=ax, column='land_category', alpha=0.5,\n",
        "                     legend=True, categorical=True,\n",
        "                     legend_kwds={'loc': 'upper left'})\n",
        "    else:\n",
        "        # Caso contrÃ¡rio, tentar outras colunas comuns\n",
        "        for col in ['landuse', 'type', 'class']:\n",
        "            if col in landuse.columns and landuse[col].notna().any():\n",
        "                landuse.plot(ax=ax, column=col, alpha=0.5,\n",
        "                             legend=True, categorical=True,\n",
        "                             legend_kwds={'loc': 'upper left'})\n",
        "                break\n",
        "        else:\n",
        "            # Se nenhuma coluna for adequada, plotar sem classificaÃ§Ã£o\n",
        "            landuse.plot(ax=ax, alpha=0.5)\n",
        "\n",
        "    # Amostrar edifÃ­cios para nÃ£o sobrecarregar a visualizaÃ§Ã£o\n",
        "    sample_buildings = buildings.sample(min(sample_size, len(buildings)))\n",
        "\n",
        "    # Plotar edifÃ­cios\n",
        "    if 'building_class' in buildings.columns:\n",
        "        sample_buildings.plot(ax=ax, column='building_class',\n",
        "                              categorical=True, alpha=0.8,\n",
        "                              markersize=5, legend=True,\n",
        "                              legend_kwds={'loc': 'upper right'})\n",
        "    else:\n",
        "        sample_buildings.plot(ax=ax, color='blue', alpha=0.8, markersize=5)\n",
        "\n",
        "    # Adicionar basemap para contexto\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=buildings.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar o grÃ¡fico\n",
        "    ax.set_title(\"SobreposiÃ§Ã£o entre EdifÃ­cios e Uso do Solo\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Visualizar a sobreposiÃ§Ã£o (amostra de atÃ© 1000 edifÃ­cios para nÃ£o sobrecarregar)\n",
        "fig, ax = plot_overlap(buildings_gdf, landuse_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "102640f4",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Verificar e preparar as geometrias antes da sobreposiÃ§Ã£o espacial\n",
        "def prepare_for_overlay(buildings_gdf, landuse_gdf):\n",
        "    \"\"\"\n",
        "    Prepara os GeoDataFrames para a sobreposiÃ§Ã£o espacial.\n",
        "\n",
        "    Args:\n",
        "        buildings_gdf: GeoDataFrame dos edifÃ­cios\n",
        "        landuse_gdf: GeoDataFrame do uso do solo\n",
        "\n",
        "    Returns:\n",
        "        Tuple de GeoDataFrames preparados\n",
        "    \"\"\"\n",
        "    print(\"Preparando GeoDataFrames para sobreposiÃ§Ã£o espacial...\")\n",
        "\n",
        "    # Verificar validade das geometrias\n",
        "    invalid_buildings = ~buildings_gdf.geometry.is_valid\n",
        "    invalid_landuse = ~landuse_gdf.geometry.is_valid\n",
        "\n",
        "    if invalid_buildings.any():\n",
        "        print(f\"Corrigindo {invalid_buildings.sum()} geometrias invÃ¡lidas em edifÃ­cios...\")\n",
        "        buildings_gdf.geometry = buildings_gdf.geometry.buffer(0)\n",
        "\n",
        "    if invalid_landuse.any():\n",
        "        print(f\"Corrigindo {invalid_landuse.sum()} geometrias invÃ¡lidas em uso do solo...\")\n",
        "        landuse_gdf.geometry = landuse_gdf.geometry.buffer(0)\n",
        "\n",
        "    # Verificar se os sistemas de coordenadas sÃ£o iguais\n",
        "    if buildings_gdf.crs != landuse_gdf.crs:\n",
        "        print(f\"Os sistemas de coordenadas sÃ£o diferentes. Transformando uso do solo para {buildings_gdf.crs}\")\n",
        "        landuse_gdf = landuse_gdf.to_crs(buildings_gdf.crs)\n",
        "\n",
        "    # Verificar se hÃ¡ edifÃ­cios fora da Ã¡rea de cobertura do uso do solo\n",
        "    landuse_bounds = box(*landuse_gdf.total_bounds)\n",
        "    buildings_within = buildings_gdf.intersects(landuse_bounds)\n",
        "\n",
        "    if not buildings_within.all():\n",
        "        outside_count = (~buildings_within).sum()\n",
        "        print(f\"AVISO: {outside_count} edifÃ­cios ({outside_count/len(buildings_gdf)*100:.2f}%) estÃ£o fora da Ã¡rea coberta pelos dados de uso do solo.\")\n",
        "\n",
        "    return buildings_gdf, landuse_gdf\n",
        "\n",
        "# Preparar os dados para a sobreposiÃ§Ã£o\n",
        "buildings_clean, landuse_clean = prepare_for_overlay(buildings_gdf, landuse_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c4656b0",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Realizar a operaÃ§Ã£o de sobreposiÃ§Ã£o espacial (join espacial)\n",
        "def perform_spatial_join(buildings_gdf, landuse_gdf):\n",
        "    \"\"\"\n",
        "    Realiza a junÃ§Ã£o espacial entre edifÃ­cios e uso do solo.\n",
        "\n",
        "    Args:\n",
        "        buildings_gdf: GeoDataFrame dos edifÃ­cios\n",
        "        landuse_gdf: GeoDataFrame do uso do solo\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com a junÃ§Ã£o espacial\n",
        "    \"\"\"\n",
        "    print(\"Realizando a junÃ§Ã£o espacial...\", flush=True)\n",
        "\n",
        "    # Selecionar colunas relevantes do uso do solo para nÃ£o duplicar dados\n",
        "    # Estas sÃ£o colunas comuns em dados de uso do solo\n",
        "    landuse_cols = ['landuse', 'land_category', 'land_use', 'type', 'class']\n",
        "    landuse_cols = [col for col in landuse_cols if col in landuse_gdf.columns]\n",
        "\n",
        "    # Se land_category nÃ£o existir, tente identificar uma coluna principal\n",
        "    if 'land_category' not in landuse_cols and landuse_cols:\n",
        "        main_category_col = landuse_cols[0]\n",
        "        # Renomear a coluna principal para land_category para padronizaÃ§Ã£o\n",
        "        landuse_gdf = landuse_gdf.copy()\n",
        "        landuse_gdf['land_category'] = landuse_gdf[main_category_col]\n",
        "        landuse_cols.append('land_category')\n",
        "\n",
        "    # Adicionar geometria e um identificador Ãºnico\n",
        "    selected_cols = landuse_cols + ['geometry']\n",
        "    landuse_for_join = landuse_gdf[selected_cols].copy()\n",
        "    landuse_for_join['landuse_id'] = range(len(landuse_for_join))\n",
        "\n",
        "    # Realizar a junÃ§Ã£o espacial\n",
        "    print(f\"Juntando {len(buildings_gdf)} edifÃ­cios com {len(landuse_gdf)} polÃ­gonos de uso do solo...\")\n",
        "    joined = gpd.sjoin(buildings_gdf, landuse_for_join, how='left', predicate='intersects')\n",
        "\n",
        "    # Verificar se hÃ¡ edifÃ­cios que nÃ£o foram associados a nenhum uso do solo\n",
        "    null_landuse = joined['landuse_id'].isna().sum()\n",
        "    if null_landuse > 0:\n",
        "        print(f\"AVISO: {null_landuse} edifÃ­cios ({null_landuse/len(joined)*100:.2f}%) nÃ£o foram associados a nenhum uso do solo.\")\n",
        "\n",
        "    return joined\n",
        "\n",
        "# Realizar a junÃ§Ã£o espacial\n",
        "buildings_with_landuse = perform_spatial_join(buildings_clean, landuse_clean)\n",
        "\n",
        "# Exibir as primeiras linhas do resultado\n",
        "print(\"\\nAmostra do resultado da sobreposiÃ§Ã£o espacial:\")\n",
        "display(buildings_with_landuse.head())\n",
        "\n",
        "# Exibir estatÃ­sticas bÃ¡sicas\n",
        "print(\"\\nDistribuiÃ§Ã£o de edifÃ­cios por categoria de uso do solo:\")\n",
        "if 'land_category' in buildings_with_landuse.columns:\n",
        "    display(buildings_with_landuse['land_category'].value_counts())\n",
        "else:\n",
        "    print(\"Coluna 'land_category' nÃ£o encontrada nos resultados.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cde8c926",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Lidar com casos de edifÃ­cios que estÃ£o em mÃºltiplas zonas de uso do solo\n",
        "def handle_multiple_zones(joined_gdf, buildings_gdf, landuse_gdf):\n",
        "    \"\"\"\n",
        "    Identifica e resolve casos de edifÃ­cios em mÃºltiplas zonas de uso do solo.\n",
        "\n",
        "    Args:\n",
        "        joined_gdf: Resultado da junÃ§Ã£o espacial\n",
        "        buildings_gdf: GeoDataFrame original dos edifÃ­cios\n",
        "        landuse_gdf: GeoDataFrame original do uso do solo\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com casos mÃºltiplos resolvidos\n",
        "    \"\"\"\n",
        "    # Identificar edifÃ­cios duplicados (que caÃ­ram em mais de uma zona)\n",
        "    if 'index_right' in joined_gdf.columns:\n",
        "        duplicated_indices = joined_gdf.index.duplicated(keep=False)\n",
        "        duplicate_count = duplicated_indices.sum()\n",
        "\n",
        "        if duplicate_count > 0:\n",
        "            print(f\"Encontrados {duplicate_count} edifÃ­cios ({duplicate_count/len(buildings_gdf)*100:.2f}%) em mÃºltiplas zonas de uso do solo.\")\n",
        "\n",
        "            # Identificar quais edifÃ­cios estÃ£o duplicados\n",
        "            duplicated_buildings = joined_gdf[duplicated_indices].copy()\n",
        "\n",
        "            # EstratÃ©gia 1: Usar a Ã¡rea de interseÃ§Ã£o para determinar o uso do solo predominante\n",
        "            print(\"Resolvendo conflitos com base na Ã¡rea de interseÃ§Ã£o...\")\n",
        "\n",
        "            # Criar um GeoDataFrame para armazenar o resultado final\n",
        "            resolved_gdf = joined_gdf[~duplicated_indices].copy()\n",
        "\n",
        "            # Processar cada edifÃ­cio duplicado\n",
        "            unique_buildings = duplicated_buildings.index.unique()\n",
        "\n",
        "            for idx in tqdm(unique_buildings, desc=\"Resolvendo edifÃ­cios em mÃºltiplas zonas\"):\n",
        "                # Obter todas as entradas para este edifÃ­cio\n",
        "                building_entries = duplicated_buildings.loc[[idx]]\n",
        "\n",
        "                # Obter a geometria do edifÃ­cio\n",
        "                building_geom = buildings_gdf.loc[idx, 'geometry']\n",
        "\n",
        "                # Calcular a Ã¡rea de interseÃ§Ã£o com cada zona de uso do solo\n",
        "                areas = []\n",
        "                for i, row in building_entries.iterrows():\n",
        "                    landuse_id = row['landuse_id']\n",
        "                    if pd.notna(landuse_id):\n",
        "                        landuse_geom = landuse_gdf.loc[landuse_gdf['landuse_id'] == landuse_id, 'geometry'].iloc[0]\n",
        "                        intersection = building_geom.intersection(landuse_geom)\n",
        "                        areas.append((i, intersection.area))\n",
        "\n",
        "                # Selecionar a entrada com a maior Ã¡rea de interseÃ§Ã£o\n",
        "                if areas:\n",
        "                    max_area_idx = max(areas, key=lambda x: x[1])[0]\n",
        "                    resolved_gdf = pd.concat([resolved_gdf, building_entries.loc[[max_area_idx]]])\n",
        "\n",
        "            print(f\"ResoluÃ§Ã£o concluÃ­da. Resultaram {len(resolved_gdf)} edifÃ­cios apÃ³s resoluÃ§Ã£o de conflitos.\")\n",
        "            return resolved_gdf\n",
        "        else:\n",
        "            print(\"Nenhum edifÃ­cio em mÃºltiplas zonas de uso do solo encontrado.\")\n",
        "            return joined_gdf\n",
        "    else:\n",
        "        print(\"A coluna 'index_right' nÃ£o foi encontrada nos resultados da junÃ§Ã£o. Verificando por duplicatas no Ã­ndice.\")\n",
        "        # Verificar se hÃ¡ duplicatas no Ã­ndice\n",
        "        duplicated_indices = joined_gdf.index.duplicated(keep=False)\n",
        "        if duplicated_indices.any():\n",
        "            print(f\"Encontrados {duplicated_indices.sum()} edifÃ­cios duplicados.\")\n",
        "            # Manter apenas a primeira ocorrÃªncia de cada edifÃ­cio\n",
        "            return joined_gdf[~joined_gdf.index.duplicated(keep='first')]\n",
        "        else:\n",
        "            print(\"Nenhum edifÃ­cio duplicado encontrado.\")\n",
        "            return joined_gdf\n",
        "\n",
        "# Resolver casos de edifÃ­cios em mÃºltiplas zonas\n",
        "buildings_resolved = handle_multiple_zones(buildings_with_landuse, buildings_clean, landuse_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500830f2",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar o resultado da sobreposiÃ§Ã£o\n",
        "def visualize_overlay_results(buildings_with_landuse, column='land_category', figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Visualiza os resultados da sobreposiÃ§Ã£o espacial.\n",
        "\n",
        "    Args:\n",
        "        buildings_with_landuse: GeoDataFrame com os resultados da sobreposiÃ§Ã£o\n",
        "        column: Coluna a ser usada para a classificaÃ§Ã£o\n",
        "        figsize: Tamanho da figura\n",
        "    \"\"\"\n",
        "    if column not in buildings_with_landuse.columns:\n",
        "        print(f\"Coluna '{column}' nÃ£o encontrada. Colunas disponÃ­veis: {buildings_with_landuse.columns.tolist()}\")\n",
        "        # Tentar encontrar uma coluna alternativa\n",
        "        for alt_col in ['landuse', 'land_use', 'type']:\n",
        "            if alt_col in buildings_with_landuse.columns:\n",
        "                column = alt_col\n",
        "                print(f\"Usando coluna alternativa: '{column}'\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Nenhuma coluna alternativa encontrada. Visualizando sem classificaÃ§Ã£o.\")\n",
        "            column = None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Plotar os edifÃ­cios classificados por uso do solo\n",
        "    if column:\n",
        "        buildings_with_landuse.plot(\n",
        "            column=column,\n",
        "            categorical=True,\n",
        "            legend=True,\n",
        "            ax=ax,\n",
        "            alpha=0.7,\n",
        "            markersize=10,\n",
        "            legend_kwds={'loc': 'upper left', 'bbox_to_anchor': (1, 1)}\n",
        "        )\n",
        "    else:\n",
        "        buildings_with_landuse.plot(ax=ax, alpha=0.7, markersize=10)\n",
        "\n",
        "    # Adicionar um mapa base para contexto\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=buildings_with_landuse.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar o grÃ¡fico\n",
        "    ax.set_title(\"EdifÃ­cios classificados por Uso do Solo\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Visualizar os resultados\n",
        "fig, ax = visualize_overlay_results(buildings_resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "665c0036",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Realizar uma anÃ¡lise inicial da relaÃ§Ã£o entre edifÃ­cios e uso do solo\n",
        "def analyze_building_landuse_relationship(buildings_gdf):\n",
        "    \"\"\"\n",
        "    Analisa a relaÃ§Ã£o entre os edifÃ­cios e o uso do solo.\n",
        "\n",
        "    Args:\n",
        "        buildings_gdf: GeoDataFrame com os edifÃ­cios e informaÃ§Ãµes de uso do solo\n",
        "    \"\"\"\n",
        "    # Verificar se temos as colunas necessÃ¡rias\n",
        "    if 'building' in buildings_gdf.columns and 'land_category' in buildings_gdf.columns:\n",
        "        # Criar uma tabela cruzada de tipos de edifÃ­cios x categorias de uso do solo\n",
        "        cross_tab = pd.crosstab(\n",
        "            buildings_gdf['building'],\n",
        "            buildings_gdf['land_category'],\n",
        "            margins=True,\n",
        "            normalize='index'\n",
        "        )\n",
        "\n",
        "        print(\"AnÃ¡lise de tipos de edifÃ­cios por categoria de uso do solo (normalizado por linha):\")\n",
        "        display(cross_tab)\n",
        "\n",
        "        # Criar um heatmap para visualizar a relaÃ§Ã£o\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(cross_tab.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "        plt.title('DistribuiÃ§Ã£o de Tipos de EdifÃ­cios por Categoria de Uso do Solo')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        # Tentar encontrar colunas alternativas\n",
        "        building_col = None\n",
        "        landuse_col = None\n",
        "\n",
        "        for col in buildings_gdf.columns:\n",
        "            if 'build' in col.lower():\n",
        "                building_col = col\n",
        "                break\n",
        "\n",
        "        for col in buildings_gdf.columns:\n",
        "            if 'land' in col.lower() or 'uso' in col.lower():\n",
        "                landuse_col = col\n",
        "                break\n",
        "\n",
        "        if building_col and landuse_col:\n",
        "            print(f\"Usando colunas alternativas: '{building_col}' e '{landuse_col}'\")\n",
        "\n",
        "            # Criar uma tabela cruzada com as colunas alternativas\n",
        "            cross_tab = pd.crosstab(\n",
        "                buildings_gdf[building_col],\n",
        "                buildings_gdf[landuse_col],\n",
        "                margins=True\n",
        "            )\n",
        "\n",
        "            print(f\"AnÃ¡lise de {building_col} por {landuse_col}:\")\n",
        "            display(cross_tab)\n",
        "        else:\n",
        "            print(\"NÃ£o foi possÃ­vel encontrar colunas adequadas para anÃ¡lise de relaÃ§Ã£o edifÃ­cio-uso do solo.\")\n",
        "\n",
        "# Importar biblioteca adicional para visualizaÃ§Ã£o\n",
        "import seaborn as sns\n",
        "\n",
        "# Realizar anÃ¡lise da relaÃ§Ã£o entre edifÃ­cios e uso do solo\n",
        "analyze_building_landuse_relationship(buildings_resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5b36610",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Salvar o resultado para uso nos prÃ³ximos notebooks\n",
        "def save_results(buildings_with_landuse, filename='buildings_with_landuse.gpkg'):\n",
        "    \"\"\"\n",
        "    Salva os resultados da sobreposiÃ§Ã£o espacial para uso posterior.\n",
        "\n",
        "    Args:\n",
        "        buildings_with_landuse: GeoDataFrame com os resultados\n",
        "        filename: Nome do arquivo para salvamento\n",
        "    \"\"\"\n",
        "    # Criar pasta de resultados se nÃ£o existir\n",
        "    results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Caminho completo para o arquivo\n",
        "    result_path = os.path.join(results_dir, filename)\n",
        "\n",
        "    # Salvar como GeoPackage\n",
        "    buildings_with_landuse.to_file(result_path, driver='GPKG')\n",
        "\n",
        "    # Salvar tambÃ©m como pickle para preservar tipos de dados\n",
        "    pickle_path = os.path.join(results_dir, 'buildings_with_landuse.pkl')\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(buildings_with_landuse, f)\n",
        "\n",
        "    print(f\"Resultados salvos em:\\n- {result_path}\\n- {pickle_path}\")\n",
        "\n",
        "    return result_path, pickle_path\n",
        "\n",
        "# Salvar os resultados\n",
        "gpkg_path, pickle_path = save_results(buildings_resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d41d9d3b",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusÃ£o\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA SOBREPOSIÃ‡ÃƒO ESPACIAL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# EstatÃ­sticas gerais\n",
        "building_count = len(buildings_resolved)\n",
        "landuse_categories = buildings_resolved['land_category'].nunique() if 'land_category' in buildings_resolved.columns else \"N/A\"\n",
        "null_landuse = buildings_resolved['landuse_id'].isna().sum() if 'landuse_id' in buildings_resolved.columns else \"N/A\"\n",
        "\n",
        "print(f\"Total de edifÃ­cios processados: {building_count}\")\n",
        "print(f\"Categorias de uso do solo identificadas: {landuse_categories}\")\n",
        "print(f\"EdifÃ­cios sem uso do solo associado: {null_landuse}\")\n",
        "\n",
        "print(\"\\nPrincipais distribuiÃ§Ãµes:\")\n",
        "if 'land_category' in buildings_resolved.columns:\n",
        "    top_categories = buildings_resolved['land_category'].value_counts().head(5)\n",
        "    for category, count in top_categories.items():\n",
        "        print(f\"  - {category}: {count} edifÃ­cios ({count/building_count*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nPrÃ³ximos passos:\")\n",
        "print(\"1. CategorizaÃ§Ã£o funcional dos edifÃ­cios usando as informaÃ§Ãµes de uso do solo\")\n",
        "print(\"2. AnÃ¡lise de conformidade entre o uso real e o designado\")\n",
        "print(\"3. CriaÃ§Ã£o de mapas temÃ¡ticos de uso e ocupaÃ§Ã£o do solo\")\n",
        "\n",
        "print(f\"\\nOs resultados foram salvos e estÃ£o prontos para uso nos prÃ³ximos notebooks:\")\n",
        "print(f\"- GeoPackage: {os.path.basename(gpkg_path)}\")\n",
        "print(f\"- Pickle: {os.path.basename(pickle_path)}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c169948",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# CategorizaÃ§Ã£o Funcional de EdifÃ­cios\n",
        "# Este notebook enriquece a classificaÃ§Ã£o dos edifÃ­cios usando dados de uso do solo\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import contextily as cx\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "\n",
        "# Ignorar avisos especÃ­ficos\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# DefiniÃ§Ã£o dos diretÃ³rios\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "buildings_landuse_pkl = os.path.join(results_dir, 'buildings_with_landuse.pkl')\n",
        "\n",
        "# Verificando se o arquivo existe\n",
        "if not os.path.exists(buildings_landuse_pkl):\n",
        "    raise FileNotFoundError(f\"Arquivo nÃ£o encontrado: {buildings_landuse_pkl}. Execute o notebook 2.1_Sobreposicao_Espacial.ipynb primeiro.\")\n",
        "\n",
        "# Carregando os dados da etapa anterior\n",
        "with open(buildings_landuse_pkl, 'rb') as f:\n",
        "    buildings_with_landuse = pickle.load(f)\n",
        "\n",
        "print(f\"Dados carregados: {len(buildings_with_landuse)} edifÃ­cios com informaÃ§Ãµes de uso do solo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cc82661",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Explorar os dados disponÃ­veis para a categorizaÃ§Ã£o\n",
        "def explore_building_attributes(gdf):\n",
        "    \"\"\"\n",
        "    Explora os atributos disponÃ­veis para categorizaÃ§Ã£o dos edifÃ­cios.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com os edifÃ­cios e informaÃ§Ãµes de uso do solo\n",
        "    \"\"\"\n",
        "    # Verificar as colunas disponÃ­veis\n",
        "    building_cols = [col for col in gdf.columns if 'build' in col.lower()]\n",
        "    landuse_cols = [col for col in gdf.columns if 'land' in col.lower() or 'uso' in col.lower()]\n",
        "    amenity_cols = [col for col in gdf.columns if 'amen' in col.lower()]\n",
        "    function_cols = [col for col in gdf.columns if 'func' in col.lower() or 'class' in col.lower()]\n",
        "\n",
        "    print(\"Colunas disponÃ­veis para categorizaÃ§Ã£o:\")\n",
        "    print(f\"- Colunas de edifÃ­cio: {building_cols}\")\n",
        "    print(f\"- Colunas de uso do solo: {landuse_cols}\")\n",
        "    print(f\"- Colunas de amenidades: {amenity_cols}\")\n",
        "    print(f\"- Colunas de funÃ§Ã£o/classe: {function_cols}\")\n",
        "\n",
        "    # Explorar valores Ãºnicos em colunas principais\n",
        "    for cols in [building_cols, landuse_cols, amenity_cols, function_cols]:\n",
        "        for col in cols:\n",
        "            if col in gdf.columns:\n",
        "                values = gdf[col].dropna().unique()\n",
        "                print(f\"\\nValores Ãºnicos em '{col}' ({len(values)} valores):\")\n",
        "                if len(values) > 20:\n",
        "                    print(values[:20], \"... (mais valores)\")\n",
        "                else:\n",
        "                    print(values)\n",
        "\n",
        "# Explorando os atributos disponÃ­veis\n",
        "explore_building_attributes(buildings_with_landuse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a81ffc3",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Definir a hierarquia de categorizaÃ§Ã£o funcional\n",
        "def define_functional_categories():\n",
        "    \"\"\"\n",
        "    Define a hierarquia e regras para categorizaÃ§Ã£o funcional dos edifÃ­cios.\n",
        "\n",
        "    Returns:\n",
        "        DicionÃ¡rio com definiÃ§Ãµes de categorias funcionais e mapeamento de valores\n",
        "    \"\"\"\n",
        "    # DefiniÃ§Ã£o hierÃ¡rquica das categorias funcionais\n",
        "    categories = {\n",
        "        'residencial': {\n",
        "            'description': 'EdifÃ­cios residenciais unifamiliares e multifamiliares',\n",
        "            'subcategories': {\n",
        "                'unifamiliar': ['house', 'detached', 'bungalow', 'semidetached_house'],\n",
        "                'multifamiliar': ['apartments', 'residential', 'terrace'],\n",
        "                'misto': ['residential;commercial', 'mixed']\n",
        "            },\n",
        "            'landuse_match': ['residential', 'habitacional']\n",
        "        },\n",
        "        'comercial': {\n",
        "            'description': 'EdifÃ­cios comerciais e de serviÃ§os',\n",
        "            'subcategories': {\n",
        "                'varejo': ['retail', 'shop', 'store', 'supermarket', 'mall'],\n",
        "                'escritorios': ['commercial', 'office', 'offices', 'company'],\n",
        "                'hospedagem': ['hotel', 'hostel', 'motel', 'guest_house'],\n",
        "                'restauracao': ['restaurant', 'cafe', 'fast_food', 'food_court']\n",
        "            },\n",
        "            'landuse_match': ['commercial', 'retail', 'commercial']\n",
        "        },\n",
        "        'industrial': {\n",
        "            'description': 'EdifÃ­cios industriais e de armazenamento',\n",
        "            'subcategories': {\n",
        "                'fabrica': ['industrial', 'factory', 'manufacturing'],\n",
        "                'armazenamento': ['warehouse', 'storage', 'depot', 'shed'],\n",
        "                'logistica': ['logistics', 'distribution']\n",
        "            },\n",
        "            'landuse_match': ['industrial', 'industrial', 'manufacturing']\n",
        "        },\n",
        "        'institucional': {\n",
        "            'description': 'EdifÃ­cios institucionais e de serviÃ§os pÃºblicos',\n",
        "            'subcategories': {\n",
        "                'educacao': ['school', 'university', 'college', 'kindergarten', 'educational'],\n",
        "                'saude': ['hospital', 'clinic', 'healthcare', 'doctors', 'healthcare'],\n",
        "                'governo': ['government', 'public', 'townhall', 'civic'],\n",
        "                'religioso': ['church', 'mosque', 'temple', 'religious', 'place_of_worship'],\n",
        "                'cultural': ['theatre', 'cinema', 'library', 'museum', 'arts_centre']\n",
        "            },\n",
        "            'landuse_match': ['institutional', 'education', 'healthcare', 'religious']\n",
        "        },\n",
        "        'infraestrutura': {\n",
        "            'description': 'Infraestrutura e serviÃ§os urbanos',\n",
        "            'subcategories': {\n",
        "                'transporte': ['transportation', 'train_station', 'bus_station', 'terminal'],\n",
        "                'utilidades': ['utility', 'water_works', 'power', 'substation'],\n",
        "                'seguranca': ['police', 'fire_station', 'military']\n",
        "            },\n",
        "            'landuse_match': ['transportation', 'infrastructure']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Mapeamentos especÃ­ficos de valores para otimizar a categorizaÃ§Ã£o\n",
        "    value_mappings = {\n",
        "        # Mapeamento de valores de building para categorias\n",
        "        'building_to_category': {\n",
        "            'house': 'residencial.unifamiliar',\n",
        "            'residential': 'residencial.multifamiliar',\n",
        "            'apartments': 'residencial.multifamiliar',\n",
        "            'commercial': 'comercial.escritorios',\n",
        "            'retail': 'comercial.varejo',\n",
        "            'industrial': 'industrial.fabrica',\n",
        "            'warehouse': 'industrial.armazenamento',\n",
        "            'school': 'institucional.educacao',\n",
        "            'university': 'institucional.educacao',\n",
        "            'hospital': 'institucional.saude',\n",
        "            'church': 'institucional.religioso',\n",
        "            'hotel': 'comercial.hospedagem',\n",
        "            'public': 'institucional.governo',\n",
        "            'office': 'comercial.escritorios',\n",
        "            'shed': 'industrial.armazenamento'\n",
        "        },\n",
        "\n",
        "        # Mapeamento de tipos de uso do solo para categorias funcionais\n",
        "        'landuse_to_category': {\n",
        "            'residential': 'residencial',\n",
        "            'commercial': 'comercial',\n",
        "            'retail': 'comercial',\n",
        "            'industrial': 'industrial',\n",
        "            'institutional': 'institucional',\n",
        "            'mixed': 'residencial.misto',\n",
        "            'education': 'institucional.educacao',\n",
        "            'healthcare': 'institucional.saude',\n",
        "            'transportation': 'infraestrutura.transporte',\n",
        "            'green': None,  # Uso do solo nÃ£o implica diretamente em categoria funcional\n",
        "            'recreational': None,\n",
        "            'agriculture': None,\n",
        "            'water': None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return {'categories': categories, 'mappings': value_mappings}\n",
        "\n",
        "# Definindo as categorias funcionais\n",
        "functional_categories = define_functional_categories()\n",
        "\n",
        "# Exibindo a estrutura das categorias\n",
        "for category, info in functional_categories['categories'].items():\n",
        "    print(f\"\\n{category.upper()} - {info['description']}\")\n",
        "    for subcategory, values in info['subcategories'].items():\n",
        "        print(f\"  - {subcategory}: {', '.join(values[:3])}{'...' if len(values) > 3 else ''}\")\n",
        "    print(f\"  Usos do solo correspondentes: {', '.join(info['landuse_match'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0590a624",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o para categorizar edifÃ­cios com base em atributos e uso do solo\n",
        "def categorize_buildings(gdf, categories_def):\n",
        "    \"\"\"\n",
        "    Categoriza edifÃ­cios com base em suas caracterÃ­sticas e uso do solo.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifÃ­cios e informaÃ§Ãµes de uso do solo\n",
        "        categories_def: DefiniÃ§Ã£o de categorias funcionais\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com novas colunas de categorizaÃ§Ã£o\n",
        "    \"\"\"\n",
        "    # Criar uma cÃ³pia para nÃ£o modificar o original\n",
        "    categorized_gdf = gdf.copy()\n",
        "\n",
        "    # Extrair mapeamentos e categorias\n",
        "    categories = categories_def['categories']\n",
        "    mappings = categories_def['mappings']\n",
        "\n",
        "    # Inicializar colunas para categorizaÃ§Ã£o\n",
        "    categorized_gdf['categoria_funcional'] = None\n",
        "    categorized_gdf['subcategoria_funcional'] = None\n",
        "    categorized_gdf['fonte_categoria'] = None\n",
        "\n",
        "    # Identificar colunas disponÃ­veis para categorizaÃ§Ã£o\n",
        "    building_col = next((col for col in categorized_gdf.columns if col == 'building'), None)\n",
        "    landuse_col = next((col for col in categorized_gdf.columns if col in ['landuse', 'land_category']), None)\n",
        "    amenity_col = next((col for col in categorized_gdf.columns if col == 'amenity'), None)\n",
        "\n",
        "    print(f\"Usando colunas para categorizaÃ§Ã£o: building={building_col}, landuse={landuse_col}, amenity={amenity_col}\")\n",
        "\n",
        "    # Contadores para estatÃ­sticas\n",
        "    categorization_stats = {\n",
        "        'total': len(categorized_gdf),\n",
        "        'from_building': 0,\n",
        "        'from_amenity': 0,\n",
        "        'from_landuse': 0,\n",
        "        'uncategorized': 0\n",
        "    }\n",
        "\n",
        "    # Etapa 1: Categorizar com base no tipo de edifÃ­cio\n",
        "    if building_col:\n",
        "        for idx, row in tqdm(categorized_gdf.iterrows(), total=len(categorized_gdf), desc=\"Categorizando por tipo de edifÃ­cio\"):\n",
        "            building_value = row[building_col]\n",
        "\n",
        "            if pd.notna(building_value) and building_value in mappings['building_to_category']:\n",
        "                category_path = mappings['building_to_category'][building_value]\n",
        "                if '.' in category_path:\n",
        "                    main_cat, sub_cat = category_path.split('.')\n",
        "                    categorized_gdf.at[idx, 'categoria_funcional'] = main_cat\n",
        "                    categorized_gdf.at[idx, 'subcategoria_funcional'] = sub_cat\n",
        "                else:\n",
        "                    categorized_gdf.at[idx, 'categoria_funcional'] = category_path\n",
        "\n",
        "                categorized_gdf.at[idx, 'fonte_categoria'] = 'building'\n",
        "                categorization_stats['from_building'] += 1\n",
        "\n",
        "    # Etapa 2: Complementar categorizaÃ§Ã£o com base em amenidades\n",
        "    if amenity_col:\n",
        "        for idx, row in tqdm(categorized_gdf.iterrows(), total=len(categorized_gdf), desc=\"Categorizando por amenidades\"):\n",
        "            # SÃ³ categorizar se ainda nÃ£o foi categorizado\n",
        "            if pd.isna(row['categoria_funcional']) and pd.notna(row[amenity_col]):\n",
        "                amenity_value = row[amenity_col]\n",
        "\n",
        "                # Mapeamento simplificado de amenidades para categorias\n",
        "                amenity_mapping = {\n",
        "                    'school': 'institucional.educacao',\n",
        "                    'university': 'institucional.educacao',\n",
        "                    'library': 'institucional.cultural',\n",
        "                    'hospital': 'institucional.saude',\n",
        "                    'clinic': 'institucional.saude',\n",
        "                    'doctors': 'institucional.saude',\n",
        "                    'restaurant': 'comercial.restauracao',\n",
        "                    'cafe': 'comercial.restauracao',\n",
        "                    'fast_food': 'comercial.restauracao',\n",
        "                    'bank': 'comercial.escritorios',\n",
        "                    'marketplace': 'comercial.varejo',\n",
        "                    'place_of_worship': 'institucional.religioso',\n",
        "                    'police': 'infraestrutura.seguranca',\n",
        "                    'fire_station': 'infraestrutura.seguranca',\n",
        "                    'post_office': 'institucional.governo',\n",
        "                    'town_hall': 'institucional.governo'\n",
        "                }\n",
        "\n",
        "                if amenity_value in amenity_mapping:\n",
        "                    category_path = amenity_mapping[amenity_value]\n",
        "                    if '.' in category_path:\n",
        "                        main_cat, sub_cat = category_path.split('.')\n",
        "                        categorized_gdf.at[idx, 'categoria_funcional'] = main_cat\n",
        "                        categorized_gdf.at[idx, 'subcategoria_funcional'] = sub_cat\n",
        "                    else:\n",
        "                        categorized_gdf.at[idx, 'categoria_funcional'] = category_path\n",
        "\n",
        "                    categorized_gdf.at[idx, 'fonte_categoria'] = 'amenity'\n",
        "                    categorization_stats['from_amenity'] += 1\n",
        "\n",
        "    # Etapa 3: Complementar categorizaÃ§Ã£o com base no uso do solo\n",
        "    if landuse_col:\n",
        "        for idx, row in tqdm(categorized_gdf.iterrows(), total=len(categorized_gdf), desc=\"Categorizando por uso do solo\"):\n",
        "            # SÃ³ categorizar se ainda nÃ£o foi categorizado\n",
        "            if pd.isna(row['categoria_funcional']) and pd.notna(row[landuse_col]):\n",
        "                landuse_value = row[landuse_col]\n",
        "\n",
        "                # Verificar se o valor de uso do solo estÃ¡ no mapeamento\n",
        "                if str(landuse_value).lower() in [k.lower() for k in mappings['landuse_to_category'].keys()]:\n",
        "                    # Encontrar a chave correspondente (ignorando maiÃºsculas/minÃºsculas)\n",
        "                    for key, value in mappings['landuse_to_category'].items():\n",
        "                        if str(landuse_value).lower() == key.lower() and value is not None:\n",
        "                            categorized_gdf.at[idx, 'categoria_funcional'] = value\n",
        "                            categorized_gdf.at[idx, 'fonte_categoria'] = 'landuse'\n",
        "                            categorization_stats['from_landuse'] += 1\n",
        "                            break\n",
        "\n",
        "    # Contar nÃ£o categorizados\n",
        "    categorization_stats['uncategorized'] = categorization_stats['total'] - sum([\n",
        "        categorization_stats['from_building'],\n",
        "        categorization_stats['from_amenity'],\n",
        "        categorization_stats['from_landuse']\n",
        "    ])\n",
        "\n",
        "    # Exibir estatÃ­sticas\n",
        "    print(\"\\nEstatÃ­sticas de categorizaÃ§Ã£o:\")\n",
        "    print(f\"- Total de edifÃ­cios: {categorization_stats['total']}\")\n",
        "    print(f\"- Categorizados por tipo de edifÃ­cio: {categorization_stats['from_building']} ({categorization_stats['from_building']/categorization_stats['total']*100:.2f}%)\")\n",
        "    print(f\"- Categorizados por amenidades: {categorization_stats['from_amenity']} ({categorization_stats['from_amenity']/categorization_stats['total']*100:.2f}%)\")\n",
        "    print(f\"- Categorizados por uso do solo: {categorization_stats['from_landuse']} ({categorization_stats['from_landuse']/categorization_stats['total']*100:.2f}%)\")\n",
        "    print(f\"- NÃ£o categorizados: {categorization_stats['uncategorized']} ({categorization_stats['uncategorized']/categorization_stats['total']*100:.2f}%)\")\n",
        "\n",
        "    return categorized_gdf, categorization_stats\n",
        "\n",
        "# Categorizar os edifÃ­cios\n",
        "categorized_buildings, cat_stats = categorize_buildings(buildings_with_landuse, functional_categories)\n",
        "\n",
        "# Exibir amostra do resultado\n",
        "print(\"\\nAmostra do resultado da categorizaÃ§Ã£o:\")\n",
        "display(categorized_buildings[['categoria_funcional', 'subcategoria_funcional', 'fonte_categoria']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a52498e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Analisar e visualizar os resultados da categorizaÃ§Ã£o\n",
        "def analyze_categorization_results(gdf, cat_stats):\n",
        "    \"\"\"\n",
        "    Analisa e visualiza os resultados da categorizaÃ§Ã£o funcional.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifÃ­cios categorizados\n",
        "        cat_stats: EstatÃ­sticas da categorizaÃ§Ã£o\n",
        "    \"\"\"\n",
        "    # DistribuiÃ§Ã£o de categorias principais\n",
        "    main_categories = gdf['categoria_funcional'].dropna().value_counts()\n",
        "\n",
        "    # GrÃ¡fico de categorias principais\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    main_categories.plot(kind='bar', color='skyblue')\n",
        "    plt.title('DistribuiÃ§Ã£o de Categorias Funcionais Principais')\n",
        "    plt.xlabel('Categoria')\n",
        "    plt.ylabel('NÃºmero de EdifÃ­cios')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # DistribuiÃ§Ã£o de subcategorias\n",
        "    subcategories = gdf.dropna(subset=['subcategoria_funcional'])\n",
        "    subcategory_counts = subcategories.groupby(['categoria_funcional', 'subcategoria_funcional']).size().unstack(fill_value=0)\n",
        "\n",
        "    # GrÃ¡fico de subcategorias (empilhado)\n",
        "    if not subcategory_counts.empty:\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        subcategory_counts.plot(kind='bar', stacked=True, cmap='viridis')\n",
        "        plt.title('DistribuiÃ§Ã£o de Subcategorias Funcionais')\n",
        "        plt.xlabel('Categoria Principal')\n",
        "        plt.ylabel('NÃºmero de EdifÃ­cios')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.legend(title='Subcategoria', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"NÃ£o hÃ¡ dados de subcategorias para visualizaÃ§Ã£o.\")\n",
        "\n",
        "    # DistribuiÃ§Ã£o por fonte de categorizaÃ§Ã£o\n",
        "    source_dist = gdf['fonte_categoria'].value_counts()\n",
        "\n",
        "    # GrÃ¡fico de pizza da fonte de categorizaÃ§Ã£o\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    source_dist.plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('pastel'), startangle=90)\n",
        "    plt.title('Fonte de CategorizaÃ§Ã£o Funcional')\n",
        "    plt.ylabel('')\n",
        "    plt.axis('equal')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # AnÃ¡lise cruzada de categoria x uso do solo\n",
        "    if 'land_category' in gdf.columns:\n",
        "        cross_tab = pd.crosstab(\n",
        "            gdf['categoria_funcional'],\n",
        "            gdf['land_category'],\n",
        "            margins=True,\n",
        "            normalize='index'\n",
        "        )\n",
        "\n",
        "        print(\"AnÃ¡lise cruzada: Categorias funcionais x Uso do solo (normalizado por linha):\")\n",
        "        display(cross_tab)\n",
        "\n",
        "        # Heatmap da relaÃ§Ã£o\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(cross_tab.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "        plt.title('DistribuiÃ§Ã£o de Categorias Funcionais por Uso do Solo')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Analisar os resultados da categorizaÃ§Ã£o\n",
        "analyze_categorization_results(categorized_buildings, cat_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26c4d74f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar os edifÃ­cios categorizados em um mapa\n",
        "def map_categorized_buildings(gdf, figsize=(15, 15), sample_size=1000):\n",
        "    \"\"\"\n",
        "    Cria um mapa dos edifÃ­cios categorizados.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifÃ­cios categorizados\n",
        "        figsize: Tamanho da figura\n",
        "        sample_size: Tamanho da amostra para visualizaÃ§Ã£o\n",
        "    \"\"\"\n",
        "    # Filtrar apenas edifÃ­cios categorizados\n",
        "    categorized = gdf.dropna(subset=['categoria_funcional']).copy()\n",
        "\n",
        "    # Se tiver muitos edifÃ­cios, amostrar para melhor visualizaÃ§Ã£o\n",
        "    if len(categorized) > sample_size:\n",
        "        categorized = categorized.sample(sample_size)\n",
        "\n",
        "    # Criar mapa\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Preparar uma paleta de cores\n",
        "    n_categories = categorized['categoria_funcional'].nunique()\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, n_categories))\n",
        "\n",
        "    # Plotar por categoria\n",
        "    for i, (category, group) in enumerate(categorized.groupby('categoria_funcional')):\n",
        "        color = colors[i % len(colors)]\n",
        "        group.plot(ax=ax, color=color, label=category, alpha=0.7, markersize=20)\n",
        "\n",
        "    # Adicionar mapa base\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=gdf.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar grÃ¡fico\n",
        "    ax.set_title('CategorizaÃ§Ã£o Funcional de EdifÃ­cios', fontsize=16)\n",
        "    ax.legend(title='Categoria Funcional', loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Criar mapa de edifÃ­cios categorizados\n",
        "fig, ax = map_categorized_buildings(categorized_buildings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f708e38e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Adicionar a classificaÃ§Ã£o funcional ao GeoDataFrame original\n",
        "def finalize_categorization(gdf, existing_class_col=None):\n",
        "    \"\"\"\n",
        "    Finaliza a categorizaÃ§Ã£o criando uma coluna de classificaÃ§Ã£o final.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com categorizaÃ§Ã£o preliminar\n",
        "        existing_class_col: Nome da coluna de classificaÃ§Ã£o existente, se houver\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com classificaÃ§Ã£o final\n",
        "    \"\"\"\n",
        "    # Criar cÃ³pia para nÃ£o modificar o original\n",
        "    final_gdf = gdf.copy()\n",
        "\n",
        "    # Criar coluna de classificaÃ§Ã£o final\n",
        "    final_gdf['building_class_enhanced'] = None\n",
        "\n",
        "    # Verificar se jÃ¡ existe uma coluna de classificaÃ§Ã£o\n",
        "    if existing_class_col and existing_class_col in final_gdf.columns:\n",
        "        print(f\"Incorporando classificaÃ§Ã£o existente da coluna '{existing_class_col}'\")\n",
        "        # Copiar classificaÃ§Ã£o existente como base\n",
        "        final_gdf['building_class_enhanced'] = final_gdf[existing_class_col]\n",
        "\n",
        "    # Prioridade: categorizaÃ§Ã£o nova > classificaÃ§Ã£o existente\n",
        "    for idx, row in tqdm(final_gdf.iterrows(), total=len(final_gdf), desc=\"Finalizando categorizaÃ§Ã£o\"):\n",
        "        # Se temos categoria funcional, usÃ¡-la\n",
        "        if pd.notna(row['categoria_funcional']):\n",
        "            # Se temos subcategoria, incluÃ­-la na classificaÃ§Ã£o\n",
        "            if pd.notna(row['subcategoria_funcional']):\n",
        "                classification = f\"{row['categoria_funcional']}_{row['subcategoria_funcional']}\"\n",
        "            else:\n",
        "                classification = row['categoria_funcional']\n",
        "\n",
        "            final_gdf.at[idx, 'building_class_enhanced'] = classification\n",
        "\n",
        "    # Para edifÃ­cios sem classificaÃ§Ã£o final, tentar usar outros atributos\n",
        "    unclassified = final_gdf['building_class_enhanced'].isna()\n",
        "    print(f\"EdifÃ­cios ainda sem classificaÃ§Ã£o: {unclassified.sum()} ({unclassified.sum()/len(final_gdf)*100:.2f}%)\")\n",
        "\n",
        "    if unclassified.any():\n",
        "        # Tentar usar 'building' para os nÃ£o classificados\n",
        "        if 'building' in final_gdf.columns:\n",
        "            for idx in final_gdf[unclassified].index:\n",
        "                if pd.notna(final_gdf.at[idx, 'building']):\n",
        "                    final_gdf.at[idx, 'building_class_enhanced'] = f\"unclassified_{final_gdf.at[idx, 'building']}\"\n",
        "\n",
        "        # Atualizar contagem de nÃ£o classificados\n",
        "        unclassified = final_gdf['building_class_enhanced'].isna()\n",
        "        print(f\"EdifÃ­cios ainda sem classificaÃ§Ã£o apÃ³s uso de 'building': {unclassified.sum()} ({unclassified.sum()/len(final_gdf)*100:.2f}%)\")\n",
        "\n",
        "        # Para os restantes, usar 'other' como classificaÃ§Ã£o\n",
        "        final_gdf.loc[unclassified, 'building_class_enhanced'] = 'other'\n",
        "\n",
        "    # Exibir estatÃ­sticas da classificaÃ§Ã£o final\n",
        "    final_stats = final_gdf['building_class_enhanced'].value_counts().head(10)\n",
        "    print(\"\\nTop 10 classificaÃ§Ãµes finais:\")\n",
        "    for class_name, count in final_stats.items():\n",
        "        print(f\"- {class_name}: {count} ({count/len(final_gdf)*100:.2f}%)\")\n",
        "\n",
        "    return final_gdf\n",
        "\n",
        "# Identificar coluna de classificaÃ§Ã£o existente, se houver\n",
        "existing_class_cols = [col for col in categorized_buildings.columns if 'class' in col.lower() and col != 'categoria_funcional']\n",
        "existing_class_col = existing_class_cols[0] if existing_class_cols else None\n",
        "\n",
        "# Finalizar a categorizaÃ§Ã£o\n",
        "final_categorized_buildings = finalize_categorization(categorized_buildings, existing_class_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf5ca3d9",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Validar a categorizaÃ§Ã£o final\n",
        "def validate_categorization(gdf, validation_sample_size=100):\n",
        "    \"\"\"\n",
        "    ValidaÃ§Ã£o da categorizaÃ§Ã£o funcional.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com a categorizaÃ§Ã£o final\n",
        "        validation_sample_size: Tamanho da amostra para validaÃ§Ã£o manual\n",
        "    \"\"\"\n",
        "    # AnÃ¡lise de consistÃªncia entre categorias e atributos\n",
        "    consistency_metrics = {}\n",
        "\n",
        "    # Verificar consistÃªncia entre building e classificaÃ§Ã£o\n",
        "    if 'building' in gdf.columns:\n",
        "        building_match = []\n",
        "        for idx, row in gdf.iterrows():\n",
        "            if pd.notna(row['building']) and pd.notna(row['building_class_enhanced']):\n",
        "                # Verificar se o tipo de edifÃ­cio estÃ¡ refletido na classificaÃ§Ã£o\n",
        "                building_match.append(str(row['building']).lower() in str(row['building_class_enhanced']).lower())\n",
        "\n",
        "        if building_match:\n",
        "            consistency_metrics['building_match_rate'] = sum(building_match) / len(building_match)\n",
        "\n",
        "    # Verificar consistÃªncia entre uso do solo e classificaÃ§Ã£o\n",
        "    landuse_col = next((col for col in gdf.columns if col in ['landuse', 'land_category']), None)\n",
        "    if landuse_col:\n",
        "        landuse_consistency = []\n",
        "\n",
        "        # Mapeamentos esperados de uso do solo para categoria\n",
        "        expected_matches = {\n",
        "            'residential': ['residencial'],\n",
        "            'commercial': ['comercial'],\n",
        "            'industrial': ['industrial'],\n",
        "            'institutional': ['institucional'],\n",
        "            'mixed': ['residencial_misto', 'misto']\n",
        "        }\n",
        "\n",
        "        for idx, row in gdf.iterrows():\n",
        "            if pd.notna(row[landuse_col]) and pd.notna(row['building_class_enhanced']):\n",
        "                # Verificar se a classificaÃ§Ã£o Ã© compatÃ­vel com o uso do solo\n",
        "                landuse_value = str(row[landuse_col]).lower()\n",
        "                found_match = False\n",
        "\n",
        "                for landuse_key, matching_categories in expected_matches.items():\n",
        "                    if landuse_key in landuse_value:\n",
        "                        found_match = any(match in str(row['building_class_enhanced']).lower() for match in matching_categories)\n",
        "                        if found_match:\n",
        "                            break\n",
        "\n",
        "                landuse_consistency.append(found_match)\n",
        "\n",
        "        if landuse_consistency:\n",
        "            consistency_metrics['landuse_consistency_rate'] = sum(landuse_consistency) / len(landuse_consistency)\n",
        "\n",
        "    # Exibir mÃ©tricas de consistÃªncia\n",
        "    print(\"MÃ©tricas de consistÃªncia da categorizaÃ§Ã£o:\")\n",
        "    for metric, value in consistency_metrics.items():\n",
        "        print(f\"- {metric}: {value:.2f} ({value*100:.2f}%)\")\n",
        "\n",
        "    # Criar amostra para validaÃ§Ã£o manual\n",
        "    validation_sample = gdf.sample(min(validation_sample_size, len(gdf)))\n",
        "\n",
        "    # Exibir amostra com atributos relevantes para validaÃ§Ã£o manual\n",
        "    columns_to_show = ['building_class_enhanced', 'categoria_funcional', 'subcategoria_funcional']\n",
        "    if 'building' in gdf.columns:\n",
        "        columns_to_show.append('building')\n",
        "    if landuse_col:\n",
        "        columns_to_show.append(landuse_col)\n",
        "    if 'amenity' in gdf.columns:\n",
        "        columns_to_show.append('amenity')\n",
        "\n",
        "    print(\"\\nAmostra para validaÃ§Ã£o manual:\")\n",
        "    display(validation_sample[columns_to_show])\n",
        "\n",
        "    return consistency_metrics, validation_sample\n",
        "\n",
        "# Validar a categorizaÃ§Ã£o\n",
        "consistency_metrics, validation_sample = validate_categorization(final_categorized_buildings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d34e9b6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Salvar o resultado final para uso no prÃ³ximo notebook\n",
        "def save_final_categorization(gdf, filename='buildings_categorized.gpkg'):\n",
        "    \"\"\"\n",
        "    Salva a categorizaÃ§Ã£o final para uso posterior.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com a categorizaÃ§Ã£o final\n",
        "        filename: Nome do arquivo para salvamento\n",
        "    \"\"\"\n",
        "    # Criar pasta de resultados se nÃ£o existir\n",
        "    results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Caminho completo para o arquivo\n",
        "    result_path = os.path.join(results_dir, filename)\n",
        "\n",
        "    # Salvar como GeoPackage\n",
        "    gdf.to_file(result_path, driver='GPKG')\n",
        "\n",
        "    # Salvar tambÃ©m como pickle para preservar tipos de dados\n",
        "    pickle_path = os.path.join(results_dir, 'buildings_categorized.pkl')\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(gdf, f)\n",
        "\n",
        "    print(f\"CategorizaÃ§Ã£o final salva em:\\n- {result_path}\\n- {pickle_path}\")\n",
        "\n",
        "    return result_path, pickle_path\n",
        "\n",
        "# Salvar a categorizaÃ§Ã£o final\n",
        "gpkg_path, pickle_path = save_final_categorization(final_categorized_buildings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc52532e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusÃ£o\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA CATEGORIZAÃ‡ÃƒO FUNCIONAL DE EDIFÃCIOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# EstatÃ­sticas gerais\n",
        "total_buildings = len(final_categorized_buildings)\n",
        "categorized_count = final_categorized_buildings['categoria_funcional'].notna().sum()\n",
        "categories_count = final_categorized_buildings['categoria_funcional'].nunique()\n",
        "subcategories_count = final_categorized_buildings['subcategoria_funcional'].nunique()\n",
        "\n",
        "print(f\"Total de edifÃ­cios processados: {total_buildings}\")\n",
        "print(f\"EdifÃ­cios categorizados: {categorized_count} ({categorized_count/total_buildings*100:.2f}%)\")\n",
        "print(f\"NÃºmero de categorias principais: {categories_count}\")\n",
        "print(f\"NÃºmero de subcategorias: {subcategories_count}\")\n",
        "\n",
        "print(\"\\nDistribuiÃ§Ã£o por categoria funcional:\")\n",
        "category_counts = final_categorized_buildings['categoria_funcional'].value_counts()\n",
        "for category, count in category_counts.items():\n",
        "    if pd.notna(category):\n",
        "        print(f\"  - {category}: {count} ({count/categorized_count*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nConsistÃªncia da categorizaÃ§Ã£o:\")\n",
        "for metric, value in consistency_metrics.items():\n",
        "    print(f\"  - {metric}: {value:.2f} ({value*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nMelhorias realizadas:\")\n",
        "print(\"1. CategorizaÃ§Ã£o funcional hierÃ¡rquica (categoria e subcategoria)\")\n",
        "print(\"2. IntegraÃ§Ã£o das informaÃ§Ãµes de uso do solo com os atributos dos edifÃ­cios\")\n",
        "print(\"3. Preenchimento de lacunas na classificaÃ§Ã£o original\")\n",
        "print(\"4. NormalizaÃ§Ã£o da nomenclatura das categorias\")\n",
        "\n",
        "print(\"\\nPrÃ³ximos passos:\")\n",
        "print(\"1. AnÃ¡lise de conformidade entre o uso real e o zoneamento\")\n",
        "print(\"2. IntegraÃ§Ã£o com anÃ¡lises demogrÃ¡ficas\")\n",
        "print(\"3. Mapeamento temÃ¡tico avanÃ§ado por categoria funcional\")\n",
        "\n",
        "print(f\"\\nA categorizaÃ§Ã£o funcional foi salva e estÃ¡ pronta para o prÃ³ximo notebook:\")\n",
        "print(f\"- GeoPackage: {os.path.basename(gpkg_path)}\")\n",
        "print(f\"- Pickle: {os.path.basename(pickle_path)}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ada865"
      },
      "source": [
        "2.3_Analise_Conformidade_Uso.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c811edc",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# AnÃ¡lise de Conformidade de Uso do Solo\n",
        "# Este notebook analisa a conformidade entre o uso real dos edifÃ­cios e o zoneamento\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import contextily as cx\n",
        "from shapely.geometry import box\n",
        "import warnings\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Ignorar avisos especÃ­ficos\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# DefiniÃ§Ã£o dos diretÃ³rios\n",
        "data_dir = '/content/drive/MyDrive/geoprocessamento_gnn/DATA'\n",
        "results_dir = os.path.join(data_dir, 'intermediate_results')\n",
        "buildings_categorized_pkl = os.path.join(results_dir, 'buildings_categorized.pkl')\n",
        "\n",
        "# Verificando se o arquivo existe\n",
        "if not os.path.exists(buildings_categorized_pkl):\n",
        "    raise FileNotFoundError(f\"Arquivo nÃ£o encontrado: {buildings_categorized_pkl}. Execute o notebook 2.2_Categorizacao_Funcional_Edificios.ipynb primeiro.\")\n",
        "\n",
        "# Carregando os dados da etapa anterior\n",
        "with open(buildings_categorized_pkl, 'rb') as f:\n",
        "    buildings_categorized = pickle.load(f)\n",
        "\n",
        "print(f\"Dados carregados: {len(buildings_categorized)} edifÃ­cios categorizados.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9365408",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Explorar os dados de zoneamento disponÃ­veis\n",
        "def explore_landuse_data(gdf):\n",
        "    \"\"\"\n",
        "    Explora os dados de zoneamento disponÃ­veis para anÃ¡lise de conformidade.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifÃ­cios categorizados e informaÃ§Ãµes de uso do solo\n",
        "    \"\"\"\n",
        "    # Identificar colunas relacionadas a uso do solo\n",
        "    landuse_cols = [col for col in gdf.columns if 'land' in col.lower() or 'uso' in col.lower() or 'zon' in col.lower()]\n",
        "\n",
        "    print(f\"Colunas relacionadas a uso do solo: {landuse_cols}\")\n",
        "\n",
        "    # Explorar valores em colunas especÃ­ficas\n",
        "    for col in landuse_cols:\n",
        "        if col in gdf.columns:\n",
        "            value_counts = gdf[col].value_counts()\n",
        "            unique_count = len(value_counts)\n",
        "\n",
        "            print(f\"\\nValores Ãºnicos em '{col}' ({unique_count} valores):\")\n",
        "            if unique_count > 20:\n",
        "                display(value_counts.head(20))\n",
        "                print(\"...\")\n",
        "            else:\n",
        "                display(value_counts)\n",
        "\n",
        "    # Identificar coluna principal de uso do solo (primeiramente explÃ­cita, depois derivada)\n",
        "    primary_landuse_col = None\n",
        "\n",
        "    for col_name in ['land_category', 'landuse', 'land_use', 'zoning']:\n",
        "        if col_name in gdf.columns and gdf[col_name].notna().any():\n",
        "            primary_landuse_col = col_name\n",
        "            break\n",
        "\n",
        "    if primary_landuse_col is None:\n",
        "        for col in landuse_cols:\n",
        "            if gdf[col].notna().any():\n",
        "                primary_landuse_col = col\n",
        "                break\n",
        "\n",
        "    if primary_landuse_col:\n",
        "        print(f\"\\nColuna principal de uso do solo identificada: '{primary_landuse_col}'\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma coluna adequada de uso do solo encontrada.\")\n",
        "\n",
        "    return primary_landuse_col\n",
        "\n",
        "# Explorar os dados de zoneamento\n",
        "primary_landuse_col = explore_landuse_data(buildings_categorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adb00cff",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Definir regras de conformidade para avaliaÃ§Ã£o\n",
        "def define_conformity_rules():\n",
        "    \"\"\"\n",
        "    Define as regras para avaliaÃ§Ã£o de conformidade entre uso real e zoneamento.\n",
        "\n",
        "    Returns:\n",
        "        DicionÃ¡rio com regras de conformidade\n",
        "    \"\"\"\n",
        "    # Matriz de compatibilidade: {categoria de uso do solo: [categorias funcionais permitidas]}\n",
        "    conformity_matrix = {\n",
        "        # Zonas residenciais\n",
        "        'residential': {\n",
        "            'allowed': ['residencial', 'institucional_educacao', 'institucional_religioso'],\n",
        "            'conditional': ['comercial_varejo', 'comercial_escritorios', 'institucional_saude'],\n",
        "            'forbidden': ['industrial', 'infraestrutura']\n",
        "        },\n",
        "\n",
        "        # Zonas comerciais\n",
        "        'commercial': {\n",
        "            'allowed': ['comercial', 'residencial_misto', 'institucional'],\n",
        "            'conditional': ['residencial', 'industrial_armazenamento'],\n",
        "            'forbidden': ['industrial_fabrica', 'infraestrutura_utilidades']\n",
        "        },\n",
        "\n",
        "        # Zonas industriais\n",
        "        'industrial': {\n",
        "            'allowed': ['industrial', 'infraestrutura', 'comercial_escritorios'],\n",
        "            'conditional': ['comercial_varejo', 'comercial_restauracao'],\n",
        "            'forbidden': ['residencial', 'institucional_saude', 'institucional_educacao']\n",
        "        },\n",
        "\n",
        "        # Zonas institucionais\n",
        "        'institutional': {\n",
        "            'allowed': ['institucional', 'infraestrutura_seguranca', 'comercial_escritorios'],\n",
        "            'conditional': ['comercial', 'residencial'],\n",
        "            'forbidden': ['industrial']\n",
        "        },\n",
        "\n",
        "        # Zonas mistas\n",
        "        'mixed': {\n",
        "            'allowed': ['residencial', 'comercial', 'institucional'],\n",
        "            'conditional': ['industrial_armazenamento', 'infraestrutura'],\n",
        "            'forbidden': ['industrial_fabrica']\n",
        "        },\n",
        "\n",
        "        # Zonas verdes/rurais\n",
        "        'green': {\n",
        "            'allowed': ['institucional_cultural', 'infraestrutura_utilidades'],\n",
        "            'conditional': ['comercial_restauracao', 'institucional'],\n",
        "            'forbidden': ['residencial', 'comercial_varejo', 'industrial']\n",
        "        },\n",
        "\n",
        "        # Zonas de conservaÃ§Ã£o\n",
        "        'conservation': {\n",
        "            'allowed': ['institucional_cultural'],\n",
        "            'conditional': ['infraestrutura_utilidades'],\n",
        "            'forbidden': ['residencial', 'comercial', 'industrial', 'institucional_saude']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Lista de sinÃ´nimos para cada categoria (para flexibilizar a correspondÃªncia)\n",
        "    category_synonyms = {\n",
        "        'residential': ['residencial', 'habitacional', 'housing', 'dwelling'],\n",
        "        'commercial': ['comercial', 'retail', 'business', 'service'],\n",
        "        'industrial': ['industrial', 'factory', 'manufacturing', 'plant'],\n",
        "        'institutional': ['institucional', 'public', 'government', 'education', 'health'],\n",
        "        'mixed': ['mixed', 'misto', 'mixed_use', 'multiple'],\n",
        "        'green': ['green', 'park', 'recreation', 'forest', 'rural', 'agriculture'],\n",
        "        'conservation': ['conservation', 'preserve', 'protected', 'environmental']\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'conformity_matrix': conformity_matrix,\n",
        "        'category_synonyms': category_synonyms\n",
        "    }\n",
        "\n",
        "# Definir as regras de conformidade\n",
        "conformity_rules = define_conformity_rules()\n",
        "\n",
        "# Exibir a matriz de conformidade\n",
        "print(\"Matriz de Conformidade de Uso do Solo:\")\n",
        "for zone, rules in conformity_rules['conformity_matrix'].items():\n",
        "    print(f\"\\n{zone.upper()}:\")\n",
        "    print(f\"  Permitido: {', '.join(rules['allowed'])}\")\n",
        "    print(f\"  Condicional: {', '.join(rules['conditional'])}\")\n",
        "    print(f\"  Proibido: {', '.join(rules['forbidden'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2729223",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Analisar a conformidade entre uso real e zoneamento\n",
        "def analyze_conformity(gdf, landuse_col, conformity_rules):\n",
        "    \"\"\"\n",
        "    Analisa a conformidade entre o uso real dos edifÃ­cios e o zoneamento.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com edifÃ­cios categorizados\n",
        "        landuse_col: Coluna principal de uso do solo\n",
        "        conformity_rules: Regras de conformidade definidas\n",
        "\n",
        "    Returns:\n",
        "        GeoDataFrame com anÃ¡lise de conformidade\n",
        "    \"\"\"\n",
        "    # Criar cÃ³pia para nÃ£o modificar o original\n",
        "    conformity_gdf = gdf.copy()\n",
        "\n",
        "    # Inicializar colunas de conformidade\n",
        "    conformity_gdf['conformidade_uso'] = None\n",
        "    conformity_gdf['nivel_conformidade'] = None\n",
        "    conformity_gdf['regra_aplicada'] = None\n",
        "\n",
        "    # Extrair regras e sinÃ´nimos\n",
        "    matrix = conformity_rules['conformity_matrix']\n",
        "    synonyms = conformity_rules['category_synonyms']\n",
        "\n",
        "    # FunÃ§Ã£o para determinar a categoria de zoneamento\n",
        "    def get_zoning_category(landuse_value):\n",
        "        if pd.isna(landuse_value):\n",
        "            return None\n",
        "\n",
        "        landuse_lower = str(landuse_value).lower()\n",
        "\n",
        "        # Verificar correspondÃªncia direta\n",
        "        for category, synonyms_list in synonyms.items():\n",
        "            if any(syn in landuse_lower for syn in synonyms_list):\n",
        "                return category\n",
        "\n",
        "        # Se nÃ£o hÃ¡ correspondÃªncia direta, tentar correspondÃªncia parcial\n",
        "        for category, synonyms_list in synonyms.items():\n",
        "            for syn in synonyms_list:\n",
        "                if syn in landuse_lower or landuse_lower in syn:\n",
        "                    return category\n",
        "\n",
        "        return None\n",
        "\n",
        "    # FunÃ§Ã£o para determinar a conformidade\n",
        "    def evaluate_conformity(zoning_category, functional_category):\n",
        "        if pd.isna(zoning_category) or pd.isna(functional_category):\n",
        "            return None, None, None\n",
        "\n",
        "        if zoning_category not in matrix:\n",
        "            return \"nÃ£o avaliado\", \"desconhecido\", f\"categoria de zoneamento '{zoning_category}' nÃ£o definida na matriz\"\n",
        "\n",
        "        # Verificar se a categoria funcional estÃ¡ nas listas de conformidade\n",
        "        for level, categories in [('permitido', matrix[zoning_category]['allowed']),\n",
        "                                  ('condicional', matrix[zoning_category]['conditional']),\n",
        "                                  ('proibido', matrix[zoning_category]['forbidden'])]:\n",
        "            # Verificar correspondÃªncia direta\n",
        "            if any(functional_category.startswith(cat) for cat in categories):\n",
        "                conformity = \"conforme\" if level != \"proibido\" else \"nÃ£o conforme\"\n",
        "                return conformity, level, f\"categoria funcional '{functional_category}' Ã© {level} em zona '{zoning_category}'\"\n",
        "\n",
        "            # Verificar correspondÃªncia por subcategoria (se categoria_subcategoria)\n",
        "            if '_' in functional_category:\n",
        "                main_cat = functional_category.split('_')[0]\n",
        "                if any(main_cat.startswith(cat) for cat in categories):\n",
        "                    conformity = \"conforme\" if level != \"proibido\" else \"nÃ£o conforme\"\n",
        "                    return conformity, level, f\"categoria funcional '{main_cat}' Ã© {level} em zona '{zoning_category}'\"\n",
        "\n",
        "        # Se nÃ£o encontrou em nenhuma lista, considerar como nÃ£o avaliado\n",
        "        return \"nÃ£o avaliado\", \"desconhecido\", \"sem regra aplicÃ¡vel definida\"\n",
        "\n",
        "    # Aplicar anÃ¡lise de conformidade\n",
        "    for idx, row in tqdm(conformity_gdf.iterrows(), total=len(conformity_gdf), desc=\"Analisando conformidade\"):\n",
        "        # Obter categoria de zoneamento\n",
        "        if pd.notna(row[landuse_col]):\n",
        "            zoning_category = get_zoning_category(row[landuse_col])\n",
        "        else:\n",
        "            zoning_category = None\n",
        "\n",
        "        # Obter categoria funcional\n",
        "        functional_category = row['building_class_enhanced'] if pd.notna(row['building_class_enhanced']) else None\n",
        "\n",
        "        # Avaliar conformidade\n",
        "        if zoning_category and functional_category:\n",
        "            conformity, level, rule = evaluate_conformity(zoning_category, functional_category)\n",
        "\n",
        "            conformity_gdf.at[idx, 'conformidade_uso'] = conformity\n",
        "            conformity_gdf.at[idx, 'nivel_conformidade'] = level\n",
        "            conformity_gdf.at[idx, 'regra_aplicada'] = rule\n",
        "\n",
        "    # EstatÃ­sticas de conformidade\n",
        "    conformity_stats = conformity_gdf['conformidade_uso'].value_counts()\n",
        "\n",
        "    print(\"\\nEstatÃ­sticas de conformidade:\")\n",
        "    for status, count in conformity_stats.items():\n",
        "        if pd.notna(status):\n",
        "            print(f\"- {status}: {count} ({count/len(conformity_gdf)*100:.2f}%)\")\n",
        "\n",
        "    # EstatÃ­sticas por nÃ­vel\n",
        "    level_stats = conformity_gdf['nivel_conformidade'].value_counts()\n",
        "\n",
        "    print(\"\\nEstatÃ­sticas por nÃ­vel de conformidade:\")\n",
        "    for level, count in level_stats.items():\n",
        "        if pd.notna(level):\n",
        "            print(f\"- {level}: {count} ({count/len(conformity_gdf)*100:.2f}%)\")\n",
        "\n",
        "    return conformity_gdf, conformity_stats, level_stats\n",
        "\n",
        "# Analisar a conformidade\n",
        "conformity_gdf, conformity_stats, level_stats = analyze_conformity(buildings_categorized, primary_landuse_col, conformity_rules)\n",
        "\n",
        "# Exibir amostra do resultado\n",
        "print(\"\\nAmostra do resultado da anÃ¡lise de conformidade:\")\n",
        "display(conformity_gdf[['building_class_enhanced', primary_landuse_col, 'conformidade_uso', 'nivel_conformidade']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "293436b1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualizar a conformidade de uso em mapa\n",
        "def map_conformity(gdf, sample_size=1000, figsize=(15, 15)):\n",
        "    \"\"\"\n",
        "    Cria um mapa temÃ¡tico da conformidade de uso do solo.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com anÃ¡lise de conformidade\n",
        "        sample_size: Tamanho da amostra para visualizaÃ§Ã£o\n",
        "        figsize: Tamanho da figura\n",
        "    \"\"\"\n",
        "    # Filtrar apenas edifÃ­cios com conformidade avaliada\n",
        "    conformity_map = gdf.dropna(subset=['conformidade_uso']).copy()\n",
        "\n",
        "    # Se tiver muitos edifÃ­cios, amostrar para melhor visualizaÃ§Ã£o\n",
        "    if len(conformity_map) > sample_size:\n",
        "        conformity_map = conformity_map.sample(sample_size)\n",
        "\n",
        "    # Definir cores para os diferentes status de conformidade\n",
        "    color_dict = {\n",
        "        'conforme': '#1b9e77',  # Verde\n",
        "        'nÃ£o conforme': '#d95f02',  # Laranja/Vermelho\n",
        "        'nÃ£o avaliado': '#7570b3'  # Azul/Roxo\n",
        "    }\n",
        "\n",
        "    # Criar mapa\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Plotar por status de conformidade\n",
        "    for status, group in conformity_map.groupby('conformidade_uso'):\n",
        "        if pd.notna(status) and status in color_dict:\n",
        "            color = color_dict[status]\n",
        "            group.plot(ax=ax, color=color, label=status, alpha=0.7, markersize=20)\n",
        "\n",
        "    # Adicionar mapa base\n",
        "    try:\n",
        "        cx.add_basemap(ax, crs=gdf.crs)\n",
        "    except Exception as e:\n",
        "        print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "    # Configurar grÃ¡fico\n",
        "    ax.set_title('Conformidade de Uso do Solo', fontsize=16)\n",
        "    ax.legend(title='Status de Conformidade', loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "# Criar mapa de conformidade\n",
        "fig, ax = map_conformity(conformity_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8048b809",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Analisar a conformidade por zona e categoria\n",
        "def analyze_conformity_patterns(gdf, landuse_col):\n",
        "    \"\"\"\n",
        "    Analisa padrÃµes de conformidade por zona e categoria funcional.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com anÃ¡lise de conformidade\n",
        "        landuse_col: Coluna principal de uso do solo\n",
        "    \"\"\"\n",
        "    # Criar tabela cruzada de conformidade por zona\n",
        "    if landuse_col in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        cross_zone = pd.crosstab(\n",
        "            gdf[landuse_col],\n",
        "            gdf['conformidade_uso'],\n",
        "            normalize='index',\n",
        "            margins=True\n",
        "        )\n",
        "\n",
        "        print(\"AnÃ¡lise de conformidade por zona (normalizado por linha):\")\n",
        "        display(cross_zone)\n",
        "\n",
        "        # Visualizar com heatmap\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        if not cross_zone.empty and cross_zone.shape[0] > 1 and cross_zone.shape[1] > 1:\n",
        "            sns.heatmap(cross_zone.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "            plt.title('Conformidade por Zona de Uso do Solo')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # Criar tabela cruzada de conformidade por categoria funcional\n",
        "    if 'categoria_funcional' in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        cross_category = pd.crosstab(\n",
        "            gdf['categoria_funcional'],\n",
        "            gdf['conformidade_uso'],\n",
        "            normalize='index',\n",
        "            margins=True\n",
        "        )\n",
        "\n",
        "        print(\"\\nAnÃ¡lise de conformidade por categoria funcional (normalizado por linha):\")\n",
        "        display(cross_category)\n",
        "\n",
        "        # Visualizar com heatmap\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        if not cross_category.empty and cross_category.shape[0] > 1 and cross_category.shape[1] > 1:\n",
        "            sns.heatmap(cross_category.iloc[:-1, :-1], annot=True, cmap='YlGnBu', fmt='.2f')\n",
        "            plt.title('Conformidade por Categoria Funcional')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # AnÃ¡lise de hotspots de nÃ£o conformidade\n",
        "    if 'conformidade_uso' in gdf.columns:\n",
        "        nonconforming = gdf[gdf['conformidade_uso'] == 'nÃ£o conforme'].copy()\n",
        "\n",
        "        if len(nonconforming) > 0:\n",
        "            print(f\"\\nHotspots de nÃ£o conformidade ({len(nonconforming)} edifÃ­cios):\")\n",
        "\n",
        "            # Agrupar por zona e categoria funcional\n",
        "            hotspots = nonconforming.groupby([landuse_col, 'categoria_funcional']).size().reset_index()\n",
        "            hotspots.columns = [landuse_col, 'categoria_funcional', 'count']\n",
        "            hotspots = hotspots.sort_values('count', ascending=False)\n",
        "\n",
        "            display(hotspots.head(10))\n",
        "\n",
        "            # Visualizar hotspots em mapa\n",
        "            plt.figure(figsize=(15, 10))\n",
        "\n",
        "            # Densidade de Kernel\n",
        "            try:\n",
        "                # Se tiver muitos pontos, usar densidade de Kernel\n",
        "                if len(nonconforming) > 50:\n",
        "                    nonconforming_projected = nonconforming.to_crs(epsg=3857)  # Projetar para Mercator para melhor visualizaÃ§Ã£o\n",
        "                    ax = nonconforming_projected.plot(color='red', alpha=0.1, markersize=5)\n",
        "\n",
        "                    from scipy.stats import gaussian_kde\n",
        "                    x = nonconforming_projected.geometry.x\n",
        "                    y = nonconforming_projected.geometry.y\n",
        "\n",
        "                    # Calcular densidade de pontos\n",
        "                    xy = np.vstack([x, y])\n",
        "                    z = gaussian_kde(xy)(xy)\n",
        "\n",
        "                    # Ordenar os pontos pela densidade\n",
        "                    idx = z.argsort()\n",
        "                    x, y, z = x.iloc[idx], y.iloc[idx], z[idx]\n",
        "\n",
        "                    plt.scatter(x, y, c=z, s=50, alpha=0.5, cmap='Reds')\n",
        "                    plt.colorbar(label='Densidade de NÃ£o Conformidade')\n",
        "\n",
        "                    try:\n",
        "                        cx.add_basemap(ax, crs=nonconforming_projected.crs)\n",
        "                    except Exception as e:\n",
        "                        print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "                    plt.title('Hotspots de NÃ£o Conformidade de Uso do Solo')\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                else:\n",
        "                    # Se tiver poucos pontos, mostrar apenas os pontos\n",
        "                    ax = nonconforming.plot(color='red', alpha=0.7, markersize=30)\n",
        "\n",
        "                    try:\n",
        "                        cx.add_basemap(ax, crs=nonconforming.crs)\n",
        "                    except Exception as e:\n",
        "                        print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "                    plt.title('EdifÃ­cios com Uso NÃ£o Conforme')\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"NÃ£o foi possÃ­vel criar o mapa de hotspots: {e}\")\n",
        "\n",
        "# Analisar padrÃµes de conformidade\n",
        "analyze_conformity_patterns(conformity_gdf, primary_landuse_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77844410",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Calcular Ã­ndices de conformidade\n",
        "def calculate_conformity_indices(gdf):\n",
        "    \"\"\"\n",
        "    Calcula Ã­ndices de conformidade para anÃ¡lise quantitativa.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com anÃ¡lise de conformidade\n",
        "    \"\"\"\n",
        "    # Inicializar dicionÃ¡rio de Ã­ndices\n",
        "    indices = {}\n",
        "\n",
        "    # Ãndice geral de conformidade (% de edifÃ­cios conformes)\n",
        "    if 'conformidade_uso' in gdf.columns:\n",
        "        conforming = gdf['conformidade_uso'] == 'conforme'\n",
        "        non_conforming = gdf['conformidade_uso'] == 'nÃ£o conforme'\n",
        "        assessed = gdf['conformidade_uso'].notna()\n",
        "\n",
        "        if assessed.any():\n",
        "            indices['indice_geral'] = conforming.sum() / assessed.sum()\n",
        "\n",
        "        # Ãndice de nÃ£o conformidade\n",
        "        if assessed.any():\n",
        "            indices['indice_nao_conformidade'] = non_conforming.sum() / assessed.sum()\n",
        "\n",
        "        # Cobertura da avaliaÃ§Ã£o (% de edifÃ­cios avaliados)\n",
        "        indices['cobertura_avaliacao'] = assessed.sum() / len(gdf)\n",
        "\n",
        "    # Ãndices por categoria funcional\n",
        "    if 'categoria_funcional' in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        category_indices = {}\n",
        "        for category in gdf['categoria_funcional'].dropna().unique():\n",
        "            category_mask = gdf['categoria_funcional'] == category\n",
        "            category_assessed = category_mask & gdf['conformidade_uso'].notna()\n",
        "            category_conforming = category_mask & (gdf['conformidade_uso'] == 'conforme')\n",
        "\n",
        "            if category_assessed.any():\n",
        "                category_indices[category] = category_conforming.sum() / category_assessed.sum()\n",
        "\n",
        "        indices['indices_por_categoria'] = category_indices\n",
        "\n",
        "    # Ãndices por zona\n",
        "    if primary_landuse_col in gdf.columns and 'conformidade_uso' in gdf.columns:\n",
        "        zone_indices = {}\n",
        "        for zone in gdf[primary_landuse_col].dropna().unique():\n",
        "            zone_mask = gdf[primary_landuse_col] == zone\n",
        "            zone_assessed = zone_mask & gdf['conformidade_uso'].notna()\n",
        "            zone_conforming = zone_mask & (gdf['conformidade_uso'] == 'conforme')\n",
        "\n",
        "            if zone_assessed.any():\n",
        "                zone_indices[zone] = zone_conforming.sum() / zone_assessed.sum()\n",
        "\n",
        "        indices['indices_por_zona'] = zone_indices\n",
        "\n",
        "    # Exibir Ã­ndices calculados\n",
        "    print(\"Ãndices de Conformidade de Uso do Solo:\")\n",
        "\n",
        "    if 'indice_geral' in indices:\n",
        "        print(f\"- Ãndice Geral de Conformidade: {indices['indice_geral']:.4f} ({indices['indice_geral']*100:.2f}%)\")\n",
        "\n",
        "    if 'indice_nao_conformidade' in indices:\n",
        "        print(f\"- Ãndice de NÃ£o Conformidade: {indices['indice_nao_conformidade']:.4f} ({indices['indice_nao_conformidade']*100:.2f}%)\")\n",
        "\n",
        "    if 'cobertura_avaliacao' in indices:\n",
        "        print(f\"- Cobertura da AvaliaÃ§Ã£o: {indices['cobertura_avaliacao']:.4f} ({indices['cobertura_avaliacao']*100:.2f}%)\")\n",
        "\n",
        "    # Visualizar Ã­ndices por categoria\n",
        "    if 'indices_por_categoria' in indices:\n",
        "        print(\"\\nÃndices de Conformidade por Categoria Funcional:\")\n",
        "        category_df = pd.DataFrame(list(indices['indices_por_categoria'].items()),\n",
        "                                  columns=['Categoria', 'Ãndice'])\n",
        "        category_df = category_df.sort_values('Ãndice', ascending=False)\n",
        "\n",
        "        # Exibir Ã­ndices\n",
        "        for _, row in category_df.iterrows():\n",
        "            print(f\"- {row['Categoria']}: {row['Ãndice']:.4f} ({row['Ãndice']*100:.2f}%)\")\n",
        "\n",
        "        # Visualizar grÃ¡fico\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Ãndice', y='Categoria', data=category_df, palette='viridis')\n",
        "        plt.title('Ãndices de Conformidade por Categoria Funcional')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Visualizar Ã­ndices por zona\n",
        "    if 'indices_por_zona' in indices:\n",
        "        print(\"\\nÃndices de Conformidade por Zona:\")\n",
        "        zone_df = pd.DataFrame(list(indices['indices_por_zona'].items()),\n",
        "                              columns=['Zona', 'Ãndice'])\n",
        "        zone_df = zone_df.sort_values('Ãndice', ascending=False)\n",
        "\n",
        "        # Exibir Ã­ndices\n",
        "        for _, row in zone_df.iterrows():\n",
        "            print(f\"- {row['Zona']}: {row['Ãndice']:.4f} ({row['Ãndice']*100:.2f}%)\")\n",
        "\n",
        "        # Visualizar grÃ¡fico\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Ãndice', y='Zona', data=zone_df, palette='viridis')\n",
        "        plt.title('Ãndices de Conformidade por Zona')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return indices\n",
        "\n",
        "# Calcular Ã­ndices de conformidade\n",
        "conformity_indices = calculate_conformity_indices(conformity_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ab708f6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Identificar anomalias e padrÃµes espaciais\n",
        "def identify_anomalies(gdf, landuse_col):\n",
        "    \"\"\"\n",
        "    Identifica anomalias e padrÃµes espaciais de nÃ£o conformidade.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com anÃ¡lise de conformidade\n",
        "        landuse_col: Coluna principal de uso do solo\n",
        "    \"\"\"\n",
        "    # Identificar Ã¡reas com alta concentraÃ§Ã£o de nÃ£o conformidade\n",
        "    if 'conformidade_uso' in gdf.columns:\n",
        "        nonconforming = gdf[gdf['conformidade_uso'] == 'nÃ£o conforme'].copy()\n",
        "\n",
        "        if len(nonconforming) > 0:\n",
        "            print(f\"AnÃ¡lise de anomalias em {len(nonconforming)} edifÃ­cios nÃ£o conformes:\")\n",
        "\n",
        "            # Calcular proporÃ§Ã£o de nÃ£o conformidade por zona\n",
        "            zone_stats = pd.crosstab(\n",
        "                gdf[landuse_col],\n",
        "                gdf['conformidade_uso'],\n",
        "                normalize='index'\n",
        "            )\n",
        "\n",
        "            # Ordenar zonas por taxa de nÃ£o conformidade\n",
        "            if 'nÃ£o conforme' in zone_stats.columns:\n",
        "                non_conform_rates = zone_stats['nÃ£o conforme'].sort_values(ascending=False)\n",
        "\n",
        "                print(\"\\nZonas com maior taxa de nÃ£o conformidade:\")\n",
        "                for zone, rate in non_conform_rates.head(5).items():\n",
        "                    print(f\"- {zone}: {rate:.4f} ({rate*100:.2f}%)\")\n",
        "\n",
        "            # AnÃ¡lise de conflitos tÃ­picos\n",
        "            print(\"\\nConflitos tÃ­picos (combinaÃ§Ãµes zona x categoria funcional nÃ£o conformes):\")\n",
        "            conflicts = nonconforming.groupby([landuse_col, 'categoria_funcional']).size()\n",
        "            conflicts = conflicts.reset_index().rename(columns={0: 'count'})\n",
        "            conflicts = conflicts.sort_values('count', ascending=False)\n",
        "\n",
        "            for _, row in conflicts.head(5).iterrows():\n",
        "                print(f\"- {row[landuse_col]} x {row['categoria_funcional']}: {row['count']} ocorrÃªncias\")\n",
        "\n",
        "            # AnÃ¡lise de proximidade entre edifÃ­cios nÃ£o conformes\n",
        "            if len(nonconforming) > 1:\n",
        "                try:\n",
        "                    # Criar buffer ao redor de edifÃ­cios nÃ£o conformes\n",
        "                    buffer_distance = 100  # Metros\n",
        "                    nonconforming_proj = nonconforming.to_crs(epsg=3857)  # Projetar para calcular em metros\n",
        "                    nonconforming_buffers = nonconforming_proj.buffer(buffer_distance)\n",
        "\n",
        "                    # Unir os buffers sobrepostos\n",
        "                    from shapely.ops import unary_union\n",
        "                    unified_buffers = unary_union(nonconforming_buffers)\n",
        "\n",
        "                    # Converter para GeoDataFrame\n",
        "                    if hasattr(unified_buffers, '__iter__'):\n",
        "                        # Se for uma coleÃ§Ã£o de geometrias\n",
        "                        clusters = gpd.GeoDataFrame(geometry=list(unified_buffers), crs=nonconforming_proj.crs)\n",
        "                    else:\n",
        "                        # Se for uma Ãºnica geometria\n",
        "                        clusters = gpd.GeoDataFrame(geometry=[unified_buffers], crs=nonconforming_proj.crs)\n",
        "\n",
        "                    # Contar edifÃ­cios em cada cluster\n",
        "                    clusters['n_edificios'] = 0\n",
        "                    for i, cluster in enumerate(clusters.geometry):\n",
        "                        count = sum(nonconforming_proj.geometry.intersects(cluster))\n",
        "                        clusters.at[i, 'n_edificios'] = count\n",
        "\n",
        "                    # Ordenar clusters por nÃºmero de edifÃ­cios\n",
        "                    clusters = clusters.sort_values('n_edificios', ascending=False)\n",
        "\n",
        "                    print(f\"\\nIdentificados {len(clusters)} clusters de nÃ£o conformidade (buffer de {buffer_distance}m):\")\n",
        "                    for i, (_, cluster) in enumerate(clusters.head(5).iterrows()):\n",
        "                        print(f\"- Cluster {i+1}: {cluster['n_edificios']} edifÃ­cios nÃ£o conformes\")\n",
        "\n",
        "                    # Visualizar clusters\n",
        "                    if len(clusters) > 0:\n",
        "                        # Projetar de volta para CRS original\n",
        "                        clusters = clusters.to_crs(gdf.crs)\n",
        "\n",
        "                        fig, ax = plt.subplots(figsize=(15, 15))\n",
        "\n",
        "                        # Plotar todos os edifÃ­cios como contexto\n",
        "                        gdf.plot(ax=ax, color='lightgray', alpha=0.3, markersize=5)\n",
        "\n",
        "                        # Plotar edifÃ­cios nÃ£o conformes\n",
        "                        nonconforming.plot(ax=ax, color='red', alpha=0.7, markersize=30)\n",
        "\n",
        "                        # Plotar clusters de nÃ£o conformidade\n",
        "                        clusters.plot(ax=ax, color='blue', alpha=0.2, edgecolor='blue')\n",
        "\n",
        "                        # Adicionar mapa base\n",
        "                        try:\n",
        "                            cx.add_basemap(ax, crs=gdf.crs)\n",
        "                        except Exception as e:\n",
        "                            print(f\"NÃ£o foi possÃ­vel adicionar o mapa base: {e}\")\n",
        "\n",
        "                        # Configurar grÃ¡fico\n",
        "                        ax.set_title('Clusters de NÃ£o Conformidade de Uso do Solo', fontsize=16)\n",
        "                        plt.tight_layout()\n",
        "                        plt.show()\n",
        "                except Exception as e:\n",
        "                    print(f\"NÃ£o foi possÃ­vel realizar a anÃ¡lise de clusters: {e}\")\n",
        "        else:\n",
        "            print(\"Nenhum edifÃ­cio nÃ£o conforme encontrado para anÃ¡lise de anomalias.\")\n",
        "\n",
        "# Identificar anomalias e padrÃµes\n",
        "identify_anomalies(conformity_gdf, primary_landuse_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b8e4f4c",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Salvar o resultado final com a anÃ¡lise de conformidade\n",
        "def save_conformity_analysis(gdf, filename='buildings_conformity.gpkg'):\n",
        "    \"\"\"\n",
        "    Salva a anÃ¡lise de conformidade para uso posterior.\n",
        "\n",
        "    Args:\n",
        "        gdf: GeoDataFrame com anÃ¡lise de conformidade\n",
        "        filename: Nome do arquivo para salvamento\n",
        "    \"\"\"\n",
        "    # Criar pasta de resultados se nÃ£o existir\n",
        "    results_dir = os.path.join(data_dir, 'results')\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Caminho completo para o arquivo\n",
        "    result_path = os.path.join(results_dir, filename)\n",
        "\n",
        "    # Salvar como GeoPackage\n",
        "    gdf.to_file(result_path, driver='GPKG')\n",
        "\n",
        "    # Salvar tambÃ©m como pickle para preservar tipos de dados\n",
        "    pickle_path = os.path.join(results_dir, 'buildings_conformity.pkl')\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(gdf, f)\n",
        "\n",
        "    # Salvar Ã­ndices de conformidade\n",
        "    indices_path = os.path.join(results_dir, 'conformity_indices.json')\n",
        "    pd.Series(conformity_indices).to_json(indices_path)\n",
        "\n",
        "    print(f\"AnÃ¡lise de conformidade salva em:\\n- {result_path}\\n- {pickle_path}\")\n",
        "    print(f\"Ãndices de conformidade salvos em: {indices_path}\")\n",
        "\n",
        "    return result_path, pickle_path, indices_path\n",
        "\n",
        "# Salvar a anÃ¡lise de conformidade\n",
        "gpkg_path, pickle_path, indices_path = save_conformity_analysis(conformity_gdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b45dcf8",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Resumo e conclusÃ£o\n",
        "print(\"=\"*80)\n",
        "print(\"RESUMO DA ANÃLISE DE CONFORMIDADE DE USO DO SOLO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# EstatÃ­sticas gerais\n",
        "total_buildings = len(conformity_gdf)\n",
        "assessed_count = conformity_gdf['conformidade_uso'].notna().sum()\n",
        "conforming_count = (conformity_gdf['conformidade_uso'] == 'conforme').sum()\n",
        "non_conforming_count = (conformity_gdf['conformidade_uso'] == 'nÃ£o conforme').sum()\n",
        "\n",
        "print(f\"Total de edifÃ­cios analisados: {total_buildings}\")\n",
        "print(f\"EdifÃ­cios com conformidade avaliada: {assessed_count} ({assessed_count/total_buildings*100:.2f}%)\")\n",
        "print(f\"EdifÃ­cios conformes: {conforming_count} ({conforming_count/assessed_count*100:.2f}% dos avaliados)\")\n",
        "print(f\"EdifÃ­cios nÃ£o conformes: {non_conforming_count} ({non_conforming_count/assessed_count*100:.2f}% dos avaliados)\")\n",
        "\n",
        "# Principais conflitos\n",
        "if non_conforming_count > 0:\n",
        "    print(\"\\nPrincipais conflitos identificados:\")\n",
        "    conflicts = conformity_gdf[conformity_gdf['conformidade_uso'] == 'nÃ£o conforme'].groupby([primary_landuse_col, 'categoria_funcional']).size()\n",
        "    conflicts = conflicts.reset_index().rename(columns={0: 'count'})\n",
        "    conflicts = conflicts.sort_values('count', ascending=False)\n",
        "\n",
        "    for _, row in conflicts.head(5).iterrows():\n",
        "        print(f\"- {row[primary_landuse_col]} x {row['categoria_funcional']}: {row['count']} ocorrÃªncias ({row['count']/non_conforming_count*100:.2f}% dos nÃ£o conformes)\")\n",
        "\n",
        "# RecomendaÃ§Ãµes\n",
        "print(\"\\nRecomendaÃ§Ãµes para planejamento urbano:\")\n",
        "print(\"1. Revisar zoneamento em Ã¡reas com alta concentraÃ§Ã£o de nÃ£o conformidade\")\n",
        "print(\"2. Considerar ajustes nas regras de uso permitido para zonas com baixa conformidade\")\n",
        "print(\"3. Implementar zonas de transiÃ§Ã£o em Ã¡reas com conflitos frequentes\")\n",
        "print(\"4. Monitorar evoluÃ§Ã£o da conformidade ao longo do tempo\")\n",
        "\n",
        "print(\"\\nPrÃ³ximos passos:\")\n",
        "print(\"1. IntegraÃ§Ã£o com anÃ¡lises demogrÃ¡ficas para avaliar impacto populacional\")\n",
        "print(\"2. AnÃ¡lise de tendÃªncias temporais de conformidade (se dados histÃ³ricos disponÃ­veis)\")\n",
        "print(\"3. Modelagem de cenÃ¡rios de alteraÃ§Ã£o de zoneamento\")\n",
        "\n",
        "print(f\"\\nA anÃ¡lise de conformidade foi salva e estÃ¡ pronta para uso em outras anÃ¡lises:\")\n",
        "print(f\"- GeoPackage: {os.path.basename(gpkg_path)}\")\n",
        "print(f\"- Pickle: {os.path.basename(pickle_path)}\")\n",
        "print(f\"- Ãndices: {os.path.basename(indices_path)}\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17188148bd854eb89e0f61acf242d7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cfa2fb3c5983469bb1fbf54ae9b033b9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d60ee9a724284044a90fff3b1f158d41",
            "tabbable": null,
            "tooltip": null,
            "value": "â€‡1/9â€‡[00:01&lt;00:08,â€‡â€‡1.09s/it]"
          }
        },
        "19db4ff634f54c39bb1ce3b1155cbf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b2254247fbf4fad903828370d9f2fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2c76f7f484374f7683e5af25ccf4eb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4093e2ad6186493ba9290c878eab1758",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19db4ff634f54c39bb1ce3b1155cbf8a",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "4093e2ad6186493ba9290c878eab1758": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522231ed2fe14bfea5356b522cf08375": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54234ad943de4155987bb7994692e1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_522231ed2fe14bfea5356b522cf08375",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1b2254247fbf4fad903828370d9f2fca",
            "tabbable": null,
            "tooltip": null,
            "value": "â€‡1/1â€‡[00:01&lt;00:00,â€‡â€‡1.07s/it]"
          }
        },
        "655cf9cd39d64c46b46148f4a8bf7fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9952b233b734b459546a4cc82c79440",
              "IPY_MODEL_2c76f7f484374f7683e5af25ccf4eb07",
              "IPY_MODEL_54234ad943de4155987bb7994692e1b6"
            ],
            "layout": "IPY_MODEL_fe0a3275e4b3400590d860bbb3f99f33",
            "tabbable": null,
            "tooltip": null
          }
        },
        "8b066468064f4cd4a668528cfaf1fd4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b78089f74154151a2b7589978d14963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73455c14a1244888389dfa9c0b8dfe1",
              "IPY_MODEL_a113fff2f6114caa9e8221ffddaeb12c",
              "IPY_MODEL_17188148bd854eb89e0f61acf242d7bb"
            ],
            "layout": "IPY_MODEL_8e6e321e23ab4d5f8028f6e2a9d66ca2",
            "tabbable": null,
            "tooltip": null
          }
        },
        "8e6e321e23ab4d5f8028f6e2a9d66ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2269378cc04fc0b865c11a738f1cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a113fff2f6114caa9e8221ffddaeb12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cc833ad3e9e54ec6adbce3033fd839e7",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4a7c0f07888431e97d8c6c275c5e662",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "a73455c14a1244888389dfa9c0b8dfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8b066468064f4cd4a668528cfaf1fd4f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fc8efe577f5a4ce4b919037badd406cf",
            "tabbable": null,
            "tooltip": null,
            "value": "Carregandoâ€‡arquivosâ€‡GPKG:â€‡â€‡11%"
          }
        },
        "ad2422bb71b84313b81380767388d2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "cc833ad3e9e54ec6adbce3033fd839e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa2fb3c5983469bb1fbf54ae9b033b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60ee9a724284044a90fff3b1f158d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f4a7c0f07888431e97d8c6c275c5e662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9952b233b734b459546a4cc82c79440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9f2269378cc04fc0b865c11a738f1cc8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ad2422bb71b84313b81380767388d2e3",
            "tabbable": null,
            "tooltip": null,
            "value": "Camadasâ€‡emâ€‡inmet_processed.gpkg:â€‡100%"
          }
        },
        "fc8efe577f5a4ce4b919037badd406cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fe0a3275e4b3400590d860bbb3f99f33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
